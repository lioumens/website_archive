---
title: "Experimental Design"
date: "2/4/2022"
author: "Michael Liou"
execute:
  cache: true
---

```{r setup, include=FALSE}
#| code-summary: Libraries
#| message: false
library(tidyverse)
library(lme4)
library(emmeans)
library(lmerTest)
library(hasseDiagram)

# For diagrams
library(tibble)
library(kableExtra)
```

# Introduction

## Definitions

Types of units in Design and Analysis of Experiments (DOE)

- **Experimental Unit (EU)** - the smallest unit to which a treatment is applied. Experiments can have more than one experimental unit when studying more than one treatment factor. This results in split-plot designs.
- **Sampling Unit** - A unit that makes up the population to be modeled. Sampling units are used to make observations. 
- **Observational Unit** - The unit from which an observation is made.

Types of factors in DOE

- **Treatment** - normally a factor of interest to the experimentor.
- **Blocking** - also regarded as a factor, but a known source of variation. This differs from treatment factor in that it CHANGES THE RANDOMIZATION of the experiement.

A note on the word replication, I try to avoid this word, as it is *heavily* abused and vague. Sometimes clients mean subsamples, sometimes they mean a blocking factor, sometimes they mean experimental units. "I replicated this experiment 3 times". If they replicated it over years, this would imply blocking in time. "I have 3 replicates of data", implies they may have 3 data points from the same experimental unit.

Another note on "blocking": Blocking is a design mechanism of efficiency that stems from the REAL WORLD, not mathematics. Clients often come with "blocked" experiments because they believe that just including block will make the design more efficient. "Why did you block on this variable?" "blocking is more efficient and I had extra samples". If you don't block on anything useful, it will actually make the design less efficient, and you're better off with a CRD.

### Examples for definitions

* Students in classroom
  - Suppose we're studying methods of teaching (treatment factor) on student achievement. The experimental unit is a classroom, because the teaching method is applied to the whole classroom. A sampling unit is a student from that classroom, and the observational unit is some test score of the student, or some measured response from the student.
* Plants in a field
  - When we study a fertilizer (treatment factor) on the health of a plant, we are likely not just planting 1 plant, but many in a row for which fertilizer is applied. The row is the experimental unit, a plant is the sampling unit, and the observational unit is making some measurement like root length on that plant.

## Fischer Principles of Design

1. Randomization - necessary for validity of error variance estimates.
2. Replication - allows for an estimate of variance.
3. Blocking (stratification) - allows for efficient experimentation


# Hasse Diagrams

1. start with M term on top, stands for grand mean
2. next row is all factors not nested in any term, all lines up to M.
3. nested factors go directly below what it's nested in
4. draw nodes for all interaction terms from above

# Two Way Anova

$$
\begin{aligned}
Y_{ijk} = \alpha_i + \beta_j + \varepsilon_{ijk}
\end{aligned}
$$

## Fitted values and Group Means

The purpose of this section was an experiement following doing a Finley-Wilkenson regression for a client, in which I was considering calculating multiple ways of calculating the "environmental index". The point here is a little subtle: **The fitted values from a two-way anova model are not the same as the raw calculated grouped means**. The upshot of this statement is that (ignoring the replication) $\hat\alpha_1 + \hat\beta_1 = \bar{y}_{1.} + \bar{y}_{.1} \neq y_{11}$. (The statement is somewhat adhoc, without defining contrasts estimate, but this is the cell means encoding).

After looking at this, it's obvious, but the fact that in simple linear regression models, the fitted line goes through the mean, and even in one way anova models, the fitted values are directly the cell means. I just forgot the fact that this changes with two way models.

Imagine the following ways we could slice this problem

- calculating the raw means by group. 
- calculating the fitted values by two way anova w/o interaction
- calculating the fitted values by one way anova w/ interaction
- fitting several one-way linear models subsetting the data into groups over the other level


```{r warning = FALSE, message = FALSE}
data("oats", package = "MASS")
# calculate raw means
raw_mean <- oats %>% group_by(V, N) %>% 
  summarize(mean_Y = mean(Y)) %>% arrange(V, N)

# additive
mod <- lm(Y ~ V + N, data = oats)
emm <- emmeans(mod, specs = c("V", "N"))
additive_mean <- emm %>% 
  as.data.frame() %>% 
  select(V, N, emmean) %>% 
  arrange(V, N)

# additive with interaction
mod2 <- lm(Y ~ V + N + V:N, data = oats)
emm2 <- emmeans(mod, specs = c("V", "N"))

inter_mean <- emm2 %>% as.data.frame() %>% select(V,N,emmean) %>% arrange(V,N)

# several one-way linear models
mod_list <- lmList(Y~ N | V, data = oats)
new_dat <- oats %>% distinct(V, N) %>% arrange(V, N)
list_mean <- new_dat %>% 
  add_column(fitted = predict(mod_list, newdata = new_dat))

# Manual construction of fitted from marginal means
N_means <- oats %>% group_by(N) %>% summarize(N_mean = mean(Y)) %>% as.data.frame()
V_means <- oats %>% group_by(V) %>% summarize(V_mean = mean(Y)) %>% as.data.frame()
overall_mean <- oats %>% pull(Y) %>% mean()
# calculate y_i. + y_.j - y_.. for all ij
manual_mean <- N_means %>% 
  crossing(V_means) %>% 
  mutate(fitted = N_mean + V_mean - overall_mean) %>% 
  arrange(V, N)

bind_cols(new_dat,
          tibble(raw = raw_mean$mean_Y,
                 additive = additive_mean$emmean,
                 interaction = inter_mean$emmean,
                 subset_oneway = list_mean$fitted,
                 manual_fitted = manual_mean$fitted))
```

Looking at the output, additive and interaction models don't change the estimated marginal means. The one-way with subset matches the raw mean values by group because those one way models will go through the mean, and thus, fitting them seperately will those results. The Manual way of fitting calculated marginal means by Variety and Nitrogen separately, and then adds them in an "outer" type fashion.


# Blocking Designs

At its core, one should understand the features of a two way anova in order to understand what blocking does to the covariate.

## Randomized Complete Block Design (RCBD)

Summary

- RCBD's assume that the blocking factor is *additive*. That might be a wrong assumption.

$$
\begin{aligned}
Y_{ij} = \alpha_i + b_j + \varepsilon_{i(j)}
\end{aligned}
$$


- $Y_ij$ - is observation at $i$th treatment level
- $\alpha_i$ - is treatment effect for level $i$
- $b_j$ - is block effect of $j$
- $\varepsilon_{i(j)}$ - is surrogate error term, assuming $\varepsilon_{i(j)} \sim N(0, \sigma^2)$

<div style="display:flex;justify-content:center">
<img style="width:70%" src="assets/img/RCBD.png"/>
<img style="width:25%" src="assets/img/rcbd_table.png"/>
</div>


```{r eval = FALSE, echo = FALSE}
# skeleton RCBD DF table
tribble(~Source, ~DF,
        "Block", "b - 1",
        "Treatment", "a - 1",
        "Residual", "(b-1)(a-1)",
        "Total", "ab-1") %>% 
  kbl(format = "latex", booktabs=TRUE) %>% 
  row_spec(3, hline_after = T) %>% 
  as_image(width = 5, height = 3, file = "assets/img/rcbd_table.png", bs_theme = "lumen")
```




## Generalized Randomized Block Design (GRBD)

$$
\begin{aligned}
Y_{ij} = \alpha_i + b_j + \alpha b_{ij} + \varepsilon_{k(ij)}
\end{aligned}
$$

* $Y_ij$ - is observation at $i$th treatment level, 
* $\alpha_i$ - is treatment effect for level $i$, $i = 1 \dots a$
* $b_j$ - is block effect of $j$, $j = 1 \dots b$
* $\alpha b_{ij}$ - is interaction effect of treatment and block.
* $\varepsilon_{k(ij)}$ - is error term, assuming $\varepsilon_{k(ij)} \sim N(0, \sigma^2)$


<div style="display:flex;justify-content:center;align-items:start">
<img style="width:70%" src="assets/img/GRBD.png"/>
<img style="width:25%" src="assets/img/grbd_table.png"/>
</div>


```{r eval=FALSE, echo = FALSE}
# skeleton RCBD DF table
tribble(~Source, ~DF,
        "Block", "b - 1",
        "Treatment", "a - 1",
        "Block$\\times$Treatment", "(b-1)(a-1)",
        "Residual", "ab(r-1)",
        "Total", "abr-1") %>% 
  kbl(format = "latex", booktabs=TRUE, escape = F) %>% 
  row_spec(4, hline_after = T) %>% 
  as_image(width = 5, height = 3, file = "assets/img/grbd_table.png")
```

Within a single block, there is a replicate of the treatment. As opposed to a RCBD in which each level of the treatment has 1 experimental unit.

## Blocking Resources

- [Gary Lecture Notes](http://users.stat.umn.edu/~gary/classes/5303/lectures/Blocking.pdf)

# Split Plot Designs

The classic split plot design presented in most textbooks is one in which the whole plot experimental units (wpeu) treated by factor $A$ (with $a$ levels)  have $r$ replications (either in the form of block replicates or identical replicates), and the sub-plot experimental units (speu) is completely randomized _within_ the whole plot.

The defining feature of split plot designs is that there are multiple sizes of experimental units.

<img style="width:70%" src="assets/img/split_plot_table.png"/>

```{r eval=FALSE, echo = FALSE}
tribble(~Source, ~df, ~SS, ~MS, ~`E(MS)`,
      "A", "a-1", "SSA",  "MSA", "$\\sigma^2_{\\delta}+b\\sigma^2_{\\epsilon}+\\frac{rb\\sum_{i}\\alpha_i^2}{a-1}$",
      "WP Error ", "a(r-1)",  "SSWPErr"  , "MSWPErr" , "$\\sigma^2_{\\delta}+b\\sigma^2_{\\epsilon}$",
      "B", "b-1", "SSC", "MSC", "$\\sigma^2_{\\delta}+\\frac{ar\\sum_{k}\\tau_k^2}{b-1}$",
      "AB", "(a-1)(b-1)", "SSAC", "MSAC" , "$\\sigma^2_{\\delta}+\\frac{r\\sum_i\\sum_k(\\alpha\\tau)^2_{ik}}{(a-1)(b-1)}$",
      "SP Error", "a(r-1)(b-1)", "SSSPErr" , "MSSPErr",  "$\\sigma^2_{\\delta}$",
      "Total", "abr-1","SSTot", "","") %>% 
  kbl(format = "latex", booktabs = TRUE, escape = F) %>% 
  row_spec(6, hline_after = T) %>% 
  as_image(width = 5, file = "assets/img/split_plot_table.png")
```


<img style="width:70%" src="assets/img/split_plot_block_table.png"/>

```{r eval=FALSE, echo=FALSE}
tribble(~Source, ~df, ~SS, ~MS, ~`E(MS)`,
      "Block", "r-1", "SSBlk",  "MSBlk" , "$\\sigma^2_{\\delta}+b\\sigma^2_{\\epsilon}+\\frac{ar\\sum_{j}\\beta_j^2}{r-1}$",
      "A", "a-1", "SSA",  "MSA", "$\\sigma^2_{\\delta}+b\\sigma^2_{\\epsilon}+\\frac{rb\\sum_{i}\\alpha_i^2}{a-1}$",
      "WP Error (A x Block)", "(a-1)(r-1)",  "SSWPErr"  , "MSWPErr" , "$\\sigma^2_{\\delta}+b\\sigma^2_{\\epsilon}$",
      "B", "b-1", "SSC", "MSC", "$\\sigma^2_{\\delta}+\\frac{ar\\sum_{k}\\tau_k^2}{b-1}$",
      "AB", "(a-1)(b-1)", "SSAC", "MSAC" , "$\\sigma^2_{\\delta}+\\frac{r\\sum_i\\sum_k(\\alpha\\tau)^2_{ik}}{(a-1)(b-1)}$",
      "SP Error (A x B x Block + B x Block)", "a(r-1)(b-1)", "SSSPErr" , "MSSPErr",  "$\\sigma^2_{\\delta}$",
      "Total", "abr-1","SSTot", "","") %>% 
  kbl(format = "latex", booktabs = TRUE, escape = F) %>% 
  row_spec(6, hline_after = T) %>% 
  as_image(width = 5, file = "assets/img/split_plot_block_table.png")
```

## Oats Example 

This is normally analyzed as 1 factor RCBD in whole plot, 1 factor RCD in subplot. We will use this example in two ways, the simple way in which we ignore the blocking factor, and the natural way with the blocking factor.

- `B` - Blocks (6 whole plots)
- `V` - Varieties (3 levels, whole plot factor)
- `N` - Nitrogen (4 levels, sub plot factor)
- `Y` - Yields in 1/4 acre (from subplot)

<center>
<img style="width:70%" src="assets/img/oats.png"/>
<figcaption> Figure: This image shows 2 out of the 6 blocks (as rows) of the experiment. </figcaption>
</br>
</center>


```{r echo = FALSE}
data("oats", package = "MASS")
oats <- oats %>% 
  transmute(yield = Y,
            variety = V,
            nitrogen = ordered(N),
            block = B,
            field123 = factor(rep(1:3, each = 4, times = 6)), # repeat 1, 2, 3, 1, 2, 3 (this is just another way of encoding variety)
            field = factor(rep(1:18, each = 4))) # label fields 1-18
```

```{r rows.print=5, rownames.print=FALSE, echo = FALSE}
oats         
```

```{r fig.align="center", echo = FALSE}
oats %>% ggplot(aes(x = nitrogen, y = yield, color = variety, group = variety)) +
  geom_line() + 
  facet_wrap(.~block) +
  labs(
    x = "Nitrogen",
    y = "Yield",
    color = "Variety")
```


### Without blocking {.tabset}

Here we ignore the blocking factor. Suppose we just replicated the whole plot experimental unit a few more times. This means that we have 6 replication units for whole plot treatments, and theoretically get a better estimate for "Variety"

[Professor Ane Factorial and Split Plot](https://pages.stat.wisc.edu/~ane/st572/notes/lec25.pdf)


The model for the simplest split plot design is:

$$
\begin{aligned}
Y_{ijk} = \alpha_i &+ \eta_{k(i)} + \\
&\beta_j + (\alpha\beta)_{ij} +  \varepsilon_{ijk}
\end{aligned}
$$
where:

- $\alpha$ is whole plot factor (variety)
- $\eta_{k(i)}$ is the whole plot error k replicates nested inside the whole plot factor
- $\beta_j$ - subplot factor (nitrogen)
- $(\alpha\beta)_{ij}$ - interaction of whole plot factor and subplot factor
- $\varepsilon_{ijk}$ - split-plot level random error


#### lm (wrong)

```{r}
# anova table for factors for sum squares. These give identical tables.
# oats_lm <- lm(yield~nitrogen*variety + block:variety, data = oats) # same table, different way of specifying whole plot labels
oats_lm <- lm(yield ~ nitrogen*variety + field, data = oats)
anova(oats_lm)
```

Note in this table, variety is tested over the wrong denominator. It should be tested wrt to the whole plot error term.


#### aov

```{r}
# aov specifying whole plot error term
# oats_aov <- aov(yield~ nitrogen*variety + Error(block:variety), data = oats) # gives warning, but correct
oats_aov <- aov(yield ~ nitrogen*variety + Error(field), data = oats)
summary(oats_aov)
```
Notice that variety has a very different p-value here when tested over the correct denominator, in contrast to the earlier `lm` table.

#### aov (wrong)

```{r}
# Incorrect labeling of field
oats_aov <- aov(yield~nitrogen*variety + Error(field123), data = oats)
summary(oats_aov)
```

This above table is incorrect, since we're not labeling our fields differently. We don't have appropriate replicates for variety, and thus we can't estimate the error term as we have specified.

#### lmer {.active}

```{r}
# lmer way for split plot
# oats_lmer <- lmer(yield ~ nitrogen*variety + (1|block:variety))
# oats_lmer <- lmer(yield ~ nitrogen*variety + (1|block:field123))
oats_lmer <- lmer(yield ~ nitrogen*variety + (1|field), data = oats)

summary(oats_lmer)
```


```{r}
# Type III tests, here it's an exact test, so no ambiguity
# anova(oats_lmer, ddf = "Kenward-Roger")
# Anova(oats_lmer, type = "III", test.statistic = "F")
anova(oats_lmer, ddf = "Satterthwaite")
```

We note that this gives identical results as `aov`.

### {- .unlisted}

Since the interaction doesn't seem to be significant, we'd probably drop that term from the model and we would have the additive model as our final model for this data.

```{r}
oats_lmer <- lmer(yield ~ nitrogen + variety + (1|field), data = oats)
# summary(oats_lmer)
```


### With blocking {.tabset}

Now that we consider blocking, the whole plot experimental unit no longer has replication. Thus, we cannot test the interaction of block and variety. Instead, we use the interaction term as the surrotate error term for whole plots. You might ask, what if I wanted to analyze the whole plot experimental error? 

The Hasse diagram with blocking looks like

```{r echo = FALSE}
# M, B, V, N, WPE, VN, SPE
splitblock <- matrix(as.logical(c(0, 1, 1, 1, 1, 1, 1,
                       0, 0, 0, 0, 1, 0, 1,
                       0, 0, 0, 0, 1, 1, 1,
                       0, 0, 0, 0, 0, 1, 1,
                       0, 0, 0, 0, 0, 0, 1,
                       0, 0, 0, 0, 0, 0, 1,
                       0, 0, 0, 0, 0, 0, 0)), ncol = 7, byrow = TRUE)

hasse(data = splitblock, labels = c("M 1_1", "block 6_5", "Variety 3_2", "Nitrogen 4_3", "(WPE) 18_10", "VN 12_6", "(SPE) 72_45"))
```


The model for this is

$$
\begin{aligned}
Y_{ijkl} = \alpha_i + b_{k} &+ (\alpha b)_{l(ik)}\\
&\beta_j + \alpha\beta_{ij} +  \varepsilon_{l(ijk)}
\end{aligned}
$$
where:

- $\alpha$ is whole plot factor (variety) ($i = 1 \dots 3$)
- $b_k$ is blocking ($k = 1 \dots 6$)
- $(\alpha b)_{k(i)}$ is the whole plot error k replicates nested inside the whole plot factor
- $\beta_j$ - subplot factor (Nitrogen) ($j = 1 \dots 4$)
- $(\alpha\beta)_{ij}$ - interaction of whole plot factor and subplot factor
- $\varepsilon_{ijk}$ - split-plot level random error


#### lm (wrong)


```{r}
# Sum of Squres and MSE
oats_lm <- lm(yield~ block + variety*nitrogen + block:variety, data = oats)
anova(oats_lm)
```

Again, the analysis here ignores that there is a different replication for the whole plots, and so block and variety are tested with the wrong denominator. Nonetheless, it is still useful to have the mean squared errors. We drop the interaction


#### aov 

```{r}
# Fixed block effect
# oats_aov_block_fixed <- aov(yield~ block + variety*nitrogen + Error(block:variety), data = oats) # singular error, but correct
# oats_aov_block_fixed <- aov(yield~ block + variety*nitrogen + Error(block:field123), data = oats) # singular error, but correct
oats_aov_block_fixed <- aov(yield~ block + variety*nitrogen + Error(field), data = oats) # need to number each whole plot separately
summary(oats_aov_block_fixed)
```


```{r}
# Random block effects
# oats_aov_block_random <- aov(yield~ block + variety*nitrogen + Error(block)+ Error(block:variety), data = oats) # the below is technically short for this, but aov only allows 1 `Error` term, so you must specify like that.
# oats_aov_block_random <- aov(yield~ block + variety*nitrogen + Error(block/field), data = oats)  # gives singular error, but correct.
# oats_aov_block_random <- aov(yield~ block + variety*nitrogen + Error(block/field123), data = oats)  # aov prefers numbered 123 across the blocks
oats_aov_block_random <- aov(yield~ block + variety*nitrogen + Error(block/variety), data = oats)
summary(oats_aov_block_random)
```

Note that we don't get a p-value for the random block now, since block gets its own error term. we also get the same results from when we treated block as fixed.

Since there's no interaction between variety and nitrogen, we can drop that from the model and get this as the final model.

```{r}
# No interaction
oats_aov_block_fixed_additive <- aov(yield~ block + nitrogen + variety + Error(block/variety), data = oats)
summary(oats_aov_block_fixed_additive)
```

#### lmer


```{r}
# Mixed model approach, fixed block 
# oats_lmer_block_fixed <- lmer(yield~ block + variety*nitrogen + (1 | block:variety), data = oats)
oats_lmer_block_fixed <- lmer(yield~ block + variety*nitrogen + (1 | field), data = oats)
anova(oats_lmer_block_fixed)

# block random
# oats_lmer_block_random <- lmer(yield~ variety*nitrogen + (1 | block) + (1|block:variety), data = oats)
# oats_lmer_block_random <- lmer(yield~ variety*nitrogen + (1 | block/field123), data = oats) # shorthand
# oats_lmer_block_random <- lmer(yield~ variety*nitrogen + (1 | block/field), data = oats) # as long as block:field reduces to a unique 18 terms
# oats_lmer_block_random <- lmer(yield~ variety*nitrogen + (1 | block) + (1|field), data = oats) # as long as block:field reduces to a unique 18 terms, we can specify random error however.
oats_lmer_block_random <- lmer(yield~ variety*nitrogen + (1 | block/variety), data = oats) # shorthand
anova(oats_lmer_block_random)
```


Since interaction is non significant, and treating block as random doesn't change the analysis, we drop interaction from model for the final model.

```{r}
# dropping non-significant interaction term, fixed block
oats_lmer_block_fixed_additive <- lmer(yield~ block + variety + nitrogen + (1 | field), data = oats) # shorthand

# dropping non-significant interaction term, random block
oats_lmer_block_random_additive <- lmer(yield~ variety + nitrogen + (1 | block/variety), data = oats) # shorthand
```

```{r}
summary(oats_lmer_block_fixed_additive)
```


#### emmeans (manual calculation)

If we want to average across the random whole plots, and have an estimate for the variability of nitrogen, we are now considering two sources of variability, the subplot error (residual) and whole plot error. Thus, this is loosely a linear combination of chi-square distributions, thus we need a df approximation.

```{r}
# the manual calculation of the satterthwaite approximation
oats_lmer_block_fixed_additive_emm <- emmeans(oats_lmer_block_fixed_additive, specs = "nitrogen", lmer.df = "satterthwaite")
oats_lmer_block_fixed_additive_emm
```


When we treat block as random, we have even more uncertainty over the average levels because we're incorporating more variability from block.

```{r}
oats_lmer_block_random_additive_emm <- emmeans(oats_lmer_block_random_additive, specs = "nitrogen", lmer.df = "satterthwaite")
oats_lmer_block_random_additive_emm
```

In the output, we note a partial degree of freedom. How do we use satterthwaite formula to get this df approximation? (and subsequently, the standard error used to calculate the confidence limits). Nitrogen is indexed by $j$, so we are ultimately interested in $\overline{Y_{\cdot j \cdot}}$, this is the "emmean" estimate for average nitrogen, in which we average over variety and block.

$$
\begin{aligned}
SE(\overline{Y_{\cdot j \cdot}}) &= \sqrt{\hat{\operatorname{Var}}(\overline{Y_{\cdot j \cdot}})} \\
\operatorname{Var}(\overline{Y_{\cdot j \cdot}}) &= \operatorname{Var}\left(\frac{\sum_{i=1}^3\sum_{k=1}^6Y_{ijk}}{(3)(6)}\right) \\
&= \frac{1}{18} (\sigma_W^2 + \sigma^2)
\end{aligned}
$$

From the expected mean squares, a moment estimator of the variances are

$$
\begin{aligned}
\hat\sigma^2 &= SPMSE \\
\hat \sigma^2_W &= \frac{1}{4}(WPMSE - SPMSE)
\end{aligned}
$$
$$
\begin{aligned}
\hat{\operatorname{Var}}(\overline{Y_{\cdot j \cdot}}) &= \frac{1}{72}WPMSE + \frac{3}{72}SPMSE
\end{aligned}
$$

Now we also know that the mean squared errors have chi-squared distributions (because the are quadratic forms). This is where satterwaithe formula comes in. Now we just need to plug in the squared errors

$$
\begin{aligned}
\nu \approx \frac{(\sum k_is_i^2)^2}{\sum_i\frac{(k_is^2_i)^2}{\nu_i}}
\end{aligned}
$$

```{r}
oats_lm_block_additive <- lm(yield~ block + variety + nitrogen + block:variety, data = oats)
anova(oats_lm_block_additive)
```

```{r}
# with variance estimates
sperr <- 162.6 # subplot error
wperr <- (601.3 - 162.6) / 4 # whole plot variance estimate
avg_nitro_se <- sqrt(1/18*(wperr + sperr))
avg_nitro_se
```


```{r}
# with mean squared values
wpmse <- 601.3 # Whole plot Mean Square
wpdf <- 10 # Whole plot degrees of freedom
spmse <- 162.6 # sub plot mean squared
spdf <- 51 # sub plot degrees of freedom

# satterwaithe approximation
approx_df <- (1/72*wpmse + 3/72*spmse)^2 / ((1/72*wpmse)^2 / wpdf + (3/72*spmse)^2 / spdf)
approx_df
```

```{r}
# lower confidence limit
nitro1_est <- oats %>% filter(nitrogen == "0.0cwt") %>% 
  pull(yield) %>% mean()

nitro1_est + avg_nitro_se * qt(.025, approx_df) # Lower
nitro1_est + avg_nitro_se * qt(.975, approx_df) # Upper
```

We can see now all the values match up with emmeans!

#### emmeans plot (misleading)

This is a criticism from [Should blocks be random or fixed?](https://newprairiepress.org/cgi/viewcontent.cgi?referer=&httpsredir=1&article=1474&context=agstatconference) for when we treat blocks as random. He concludes by stating his preference for fixed blocks.

The following graphic is a useful summarization for showing levels of nitrogen change, and often would like to show error bars around those mean estimates. However, when we treat blocks as random (field), we are adding an additional source of variation to the standard error estimates of the mean. When we plot it, the error bars thus look huge, compared to the fixed effects case. Whereas the significance for the difference between the two groups are the same. Even though they overlap, the difference can still be significant.

```{r}
pairs(oats_lmer_block_random_additive_emm)
```

```{r}
plot(oats_lmer_block_random_additive_emm)
```

```{r}
pairs(oats_lmer_block_fixed_additive_emm)
```

```{r}
plot(oats_lmer_block_fixed_additive_emm)
```


## Steel Example {.tabset}

Based on (Box et. al 2005) Experiment designed to study the corrosion resistance of steel bars treated with 4 coatings, $C_1, C_2, C_3, C_4$ at three furnace temperatures $360^{\circ}C, 370^{\circ}C,380^{\circ}C$. Furnace temperature is considered a hard to change factor because of the time it takes to reset the furnace and reach equilibriu temperature. Once the equilibrium temperature is reached, 4 steel bars with randomly assigned coating are randomly positioned in the furnace and heated. The first three temperatures were run on day 1, and the second three temperatures were run on day 2.

```{r echo = FALSE}
steel <- data.frame(y=c(73, 83, 67, 89, 
                        65, 87, 86, 91,
                        147, 155, 127, 212,
                        153, 90, 100, 108,
                        150, 140, 121, 142,
                        33, 54, 8, 46),
                    coating=factor(c(2, 3, 1, 4,
                                     1, 3, 4, 2,
                                     3, 1, 2, 4,
                                     4, 3, 2, 1,
                                     4, 1, 3, 2,
                                     1, 4, 2, 3)),
                    temp=c(rep(c("360", "370", "380"), each=4),
                           rep(c("380", "370", "360"), each=4)),
                    day=factor(rep(1:2, each= 12)))
```

```{r echo = FALSE}
steel
```

```{r echo = FALSE}
# steel %>% ggplot(aes(x = coating, y = y, color = day, group = day)) +
#   geom_line() +
#   facet_wrap(~temp)
# 
# steel %>% ggplot(aes(x = day, y = y, color = coating, group = coating)) +
#   geom_line() +
#   facet_wrap(~temp)
# 
# 
# steel %>% ggplot(aes(x = coating, y = y, color = temp, group = temp)) +
#   geom_line() +
#   facet_wrap(~day)
steel %>% ggplot(aes(x = temp, y = y, color = coating, group = coating)) +
  geom_line() +
  facet_wrap(~day)
```

If we pretend that the randomization was not done with day as a blocking factor, then we have a split plot with CRD in whole plots and CRD in subplots.

### with day block

```{r}
# just get df table, and mean squares
# wrong denominator for temp effect
steel_lm_block <- lm(y ~ day + coating*temp + day:temp, data = steel)
anova(steel_lm_block)

# correct split plot analysis
steel_aov_block <- aov(y ~ day + coating*temp + Error(day:temp), data = steel)
summary(steel_aov_block)

# correct split plot analysis
steel_lmer_block <- lmer(y~ day + coating*temp + (1|temp:day), data = steel)
anova(steel_lmer_block)
```

### without day block

```{r}
# without blocking
steel_lmer <- lmer(y~coating*temp + (1|temp:day), data = steel)
anova(steel_lmer)
```

```{r echo = FALSE}
steel %>% add_column(y_pred = predict(steel_lmer)) %>% 
  ggplot(aes(x = temp, y = y, color = coating, group = coating)) +
  geom_line(aes(linetype = "solid"), alpha = .3) +
  geom_line(aes(temp, y_pred, linetype = "dashed")) +
  # scale_linetype_manual(values = c(1, 2), labels = c("predicted", "raw data")) +
  facet_wrap(~day) + 
  scale_linetype_identity(name = "response",
                          breaks = c("solid", "dashed"),
                          labels = c("predicted", "raw data"),
                          guide = "legend")
```


### with block:treatment

We just check the model seperating the block x sp-treatment out from the residual term.

```{r}
steel_lmer_block_interact <- lmer(y ~ day + coating*temp + day:coating + (1|temp:day), data = steel)
anova(steel_lmer_block_interact)
```


### fake data

Here I try to simulate data

```{r}
fake_y <- function(day, coating, temp){
  temp <- scale(as.numeric(temp), scale = F)
  day <- as.numeric(day)
  coating <- as.numeric(coating)
  n <- length(day)
  2 * day + 2 * temp + (day*temp)*rnorm(n, mean = 2) + .2*coating + 20*day*coating + rnorm(n)
}

fake_steel <- steel %>% add_column(fake_y = fake_y(steel$day, steel$coating, steel$temp)) 
```


```{r echo = FALSE}
fake_steel %>% ggplot(aes(x = temp, y = fake_y, color = coating, group = coating)) +
  geom_line() +
  facet_wrap(~day)

# fake_steel %>% ggplot(aes(x = coating, y = fake_y, color = day, group = day)) +
#   geom_line() +
#   facet_wrap(~temp)
# 
# fake_steel %>% ggplot(aes(x = day, y = fake_y, color = coating, group = coating)) +
#   geom_line() +
#   facet_wrap(~temp)
```

```{r}
fake_steel_aov <- aov(fake_y ~ (day + coating + temp)^2 - day:temp + Error(day:temp), data = fake_steel)
fake_steel_aov
summary(fake_steel_aov)
```

# Nested Variable labeling

When working with a client, it seems that the labeling of nested variables is quite the headache, so this section is to work out the differences in the estimation in linear models. and where the differences in ANOVA appear.

```{r}
# Simulate the data for a nested block environment
set.seed(1)
simulate_data <- function(environ, block, treat) {
  environ_effect <- c(2, 3)
  block_effect <- runif(6)
  treat_effect <- runif(2)
  y <- environ_effect[as.numeric(environ)] + 
    block_effect[as.numeric(block)] + 
    treat_effect[as.numeric(treat)] +
    rnorm(length(environ))
  y
}

dat <- tibble(environ = gl(2, 6),
              block123 = factor(rep(1:3, 4)),
              block = factor(c(rep(1:3, times = 2), 
                               rep(4:6, times = 2))),
              treat = factor(rep(letters[1:2], each = 3, times = 2))) %>% 
  mutate(y = simulate_data(environ, block, treat))

dat %>% head(n=10)
```

The numbering in this dataset is such that the block numbering goes across the environments. consider the following two models and their anova tables

```{r}
# Note the sum squares are all the same!
mod <- lm(y~environ + environ:block123 + treat + treat:environ, data = dat)
mod2 <- lm(y ~ environ + block + treat + treat:environ, data = dat)
```


```{r echo = FALSE}
anova(mod) %>% 
  kbl(caption = "Numbered within Environments") %>% 
  kable_styling(full_width = FALSE, position = "float_left")

anova(mod2) %>% 
  kbl(caption = "Numbered across Environments") %>% 
  kable_styling(full_width = FALSE, position = "left")
```

Substituting `environ:block123` with `block` when the numbering is the same gives the same ANOVA table.

The difference between these two models is that the nesting is more explicitly stated when the blocks are labeled within each environment and that there is no "aliasing" of effects either. It might not be clear from the second model that even though "block" has 6 levels, why the df = 4 in the anova table when it should intuitively be 5. It's because there is aliasing with the environment variable, so environment takes 1 df away, and thus one of the estimates of the block is singular. This can be seen in the output of `summary(mod)`:

```{r}
summary(mod2) # 1 coefficient is aliased
```

Short aside - R knows the difference between nested and crossed data based on whether the main effect is included or not. Notice the difference between these examples, even though `environ:block123` is included in both models, it doesn't have the same degrees of freedom.

```{r echo = FALSE}
tbl_nested <- tribble(~source, ~df,
        "Environ", "a - 1 = 1",
        "Environ:block123", "a(b -1) = 4")
  
tbl_crossed <- tribble(~source, ~df,
        "Environ", "a - 1 = 1",
        "block123", "b - 1 = 2", 
        "Environ:block123", "(a-1)(b -1) = 2")

tbl_nested %>% kbl(caption = "Nested Factor ANOVA") %>% kable_styling(full_width = FALSE, position = "float_left")
tbl_crossed %>% kbl(caption = "Crossed Factor ANOVA") %>% kable_styling(full_width = FALSE, position = "left")
```


```{r}
# nest vs crossing df
mod_nest <- lm(y ~ environ + environ:block123, data = dat)
mod_cross <- lm(y ~ environ + block123 + environ:block123, data = dat)

anova(mod_nest)
anova(mod_cross)
```




