---
title: "Categorical Data Analysis"
author: "Michael Liou"
date: "`r Sys.Date()`"
execute:
  cache: true
---

```{r}
#| code-summary: Libraries
#| message: false
library(tidyverse)
library(AMR)
library(DescTools)
library(kableExtra)
library(VGAM)
library(nnet)
```

## Overview

This is a very broad area, but I feel like it's also super confusing because it's all very confouded in terms of all the chisq tests that are scattered throughout the place. I'm trying to organize everything for myself here.

- CMH test
- score test for table
- Pearson
- Yates (continuity correction of Pearson)
- Barnard test (based on fixing 1 margin)
- fisher exact (based on fixing all margins)
- McNemar Test
- Generalized CMH test



## 2x2 sampling mechanisms

The many different sampling mechanisms arise from different study designs, and are critical to the assumptions of the population you are studying.

In an epidemiological context, the data is given as

|             | disease | no disease |    |
|-------------+:---------+:------------+----|
| exposure    | a       | b          | n1 |
| no exposure | c       | d          | n0 |
|             | m1      | m0         | N  |


* Poisson (nothing fixed)
* Multinomial (N) total is fixed
  - "Cross Sectional" studies
* Two-sample Binomial (1 margin fixed)
  - "Cohort Study" = n1, n0 fixed
  - "Case Control Study" = m1, m0 fixed
    - a type of "retrospective" study.
* Hypergeometric (2 margins fixed)
  - very rarely the case in real experiments, but unfortunately many methods are based on this assumption for the 2x2 table.

::: {.panel-tabset}

### Poisson

```{r class.source = "fold-hide"}
# Independent Poisson

#' When specifying the mean, they can be specified cellwise, or by table, grouped by the nrow*ncol, in order of the columns
#'
#' @param mean means of the cells. If 1 number, all cells will have same 
#'
#' @return
#' @export
#'
#' @examples
rpoisson_table <- function(num_tables = 1, mean = 5, nrow = 2,  ncol = 2) {
  cells <- rpois(ncol * nrow * num_tables, lambda = mean)
  vec_table <- split(cells, gl(num_tables, ncol*nrow))
  vapply(vec_table, matrix, nrow = nrow, ncol = ncol, byrow = FALSE, FUN.VALUE = matrix(1:(ncol*nrow), nrow = nrow))
}

# 2x2 examples
poisson_table_examples <- rpoisson_table(5, mean = 5, nrow = 2, ncol = 2)
apply(poisson_table_examples,
      MARGIN = 3,
      FUN = addmargins,
      simplify = FALSE)
```

### Multinomial

```{r}
# grand total fixed
rmultinom_table <- function(num_tables = 1, N = 20, nrow = 2, ncol = 2, p = c(1, 1, 1, 1)) {
  stopifnot(length(p) == nrow * ncol)
  # p is internally standardized by rmultinom
  cells <- rmultinom(num_tables, N, p)
  dim(cells) <- c(nrow, ncol, num_tables)
  cells
}
```

```{r}
# examples
multinom_table_examples <- rmultinom_table(5, N = 20, nrow = 2, ncol = 2, p = c(1, 1, 1, 1))
apply(multinom_table_examples,
      MARGIN = 3,
      FUN = addmargins,
      simplify = FALSE)
```


### Binomial

```{r}
# Sample a 2x2 table
rbinom_table <- function(num_tables = 1, row_n = c(10, 10), p = c(.5, .5)) {
  vapply(1:num_tables, 
       FUN = function(x) {
         a <- rbinom(length(row_n), row_n, p) # fix margins
         binom_table <- cbind(a, b = row_n-a) # make other column by subtraction and combine
         colnames(binom_table) <- NULL
         binom_table}, 
       FUN.VALUE = matrix(rep(1.1, 4), nrow =2)) # expected 2x2 table
}

binom_table_examples <- rbinom_table(5, row_n = c(10, 10), p = c(.5, .5))
apply(binom_table_examples,
      MARGIN = 3,
      FUN = addmargins,
      simplify = FALSE)
```


### Hypergeometric

```{r}
# Fixed margins
# one hypergeometrical deviate will determine the entire table.
# only doing 2x2 tables with sampling method

rhyper_table <- function(num_tables, row_n = c(10, 10), col_n = c(10, 10))  {
  a <- rhyper(num_tables, row_n[1], row_n[2], col_n[1])
  vapply(a, 
       FUN = function(x) {
         col1 <- c(x, col_n[1] - x)
         col2 <- row_n - col1
         contingency_table <- cbind(col1, col2)
         colnames(contingency_table) <- NULL # get rid of column names
         contingency_table
       },
       FUN.VALUE = matrix(c(0, 0, 0, 1.1), nrow = 2))}

# examples
hyper_table_examples <- rhyper_table(num_tables = 5, row_n = c(10, 10), col_n = c(10, 10))
apply(hyper_table_examples,
      MARGIN = 3,
      FUN = addmargins,
      simplify = FALSE)
```

:::

## Measures of Association

Given tables, it's important to distinguish the properties of how to make comparisons, and summarize the information given. When dealing with percentages and ratios, it's sometimes difficult to have an intuitive understanding of meaning on the percentage scale. The example Professor Guanhua Chen gives to stimulate you for this thinking is from [cartalk](https://www.cartalk.com/radio/puzzler/porch-potatoes):

> RAY: Potatoes are 99 percent water and one percent what? Potato. So say you take a bunch of potatoes, like 100 pounds of potatoes and you set them out on your back porch to dry out.
TOM: Yeah, when they are dry they should weigh about a pound.
RAY: Well, we’re not drying out completely. And as the potatoes dry out the water begins to evaporate. And after a while, enough water has evaporated so that they are now 98 percent water. If you were to weigh those potatoes at that moment...
TOM: They'd be lighter.
RAY: Yes, how much lighter? That's the question. Now you can solve this puzzler algebraically, and if you don't solve it algebraically, you are going to get the wrong answer.
TOM: Really?
RAY: Really.What's your answer, off the top of your head?
TOM: 99 pounds.
RAY: You are wrong.
> Answer: 
RAY: Now, unencumbered by the thought process as usual, my brother guessed 99 pounds.
TOM: Yeah.
RAY: Now, when I guessed, off the top of my head, I guessed about 90 pounds.
TOM: 'Cause it just feels right.
RAY: But if you do the math, 1 percent of 100 --which is what the potato is-- is one pound. As we told you, that's 1 percent. So 2 percent, when it’s 98 percent water, two percent of the new weight of the mass is still going to be equal to that one pound, and 2 percent of 50 pounds is a pound. So the potato weight is now 50 pounds, not 100.

* Risk Ratio: 
  - not symmetric
* Odds Ratio
  - symmetric, exposure gives information about disease and vice versa

## Testing

```{r}
tribble(~test, ~parameter, ~sampling, ~pvalue, ~hypothesis,
        "pearson", "parameter","two sample z proportion", "approximate", "association",
        "cochran", "cell", "unconditional two sample", "approximate", "association")
```


A list of tests:

- Cochran summary test
- (Cochran)-Mantel-Haenszel summary test
- Generalized CMH Test
- Cochran's Q test
- Pearson Chi Squared
- Cochran-Armitrage Trend Test
- Mann-Whitney U test (Wilcoxon Rank Sum)
- Wilcoson Signed Rank Test (paired samples)
- Krustkal Wallis

Exact tests

- Fisher Exact Test
- Barnard Exact Test

Dependent "Matched pairs" tests

- McNemar Test

### Pearson

Given the following table,

```{r}
tribble(~"", ~"Disease", ~"No Disease", ~"",
        "Exposed", "a", "b", "\\$n_1\\$",
        "Not Exposed" , "c", "d", "\\$n_2\\$",
        "", "\\$m_1\\$", "\\$m_2\\$", "N") %>% 
  kable("html")
```


Assume two sample proportional sampling model: A derivation from 2 sample proportion (pooled) z-test:

$$
\begin{aligned}
z^2 &= \frac{(\hat p_1 - \hat p_2)^2}{\hat p(1 - \hat p)(\frac{1}{n_1} + \frac{1}{n_2})} 
&=
\end{aligned}
$$


$$
\begin{aligned}
X^2 = \sum_i^c \frac{|O_i - E_i|}{E_i} \sim \chi^2_{c-1}
\end{aligned}
$$

Resources:
- [Pearson as Score Test](https://projecteuclid.org/download/pdf_1/euclid.lnms/1215091138)
- [7 proofs of independence test](https://arxiv.org/pdf/1808.09171.pdf)


### Barnard Exact Test

Barnard is considered an "unconditional" approach to exact testing. contrast to Fisher exact test which is a "conditional" approach to testing the p-value

Barnard is effectively a 2 stage test, given some observed table X, a "p-value" is the probability of observing a table more extreme than the observed. 

The two stages are thus:

1. determine which tables are more "extreme"
2. calculated probability of those tables

Thus, the "exactness" part of the description refers to how a probability is calculated.

Many methods have been proposed for stage 1

- Suissa and Shuster (1985) use pooled and unpooled z statistic for two proportions.
- Booschloo (1970) used the p-value from fisher's exact test to determine extremeness...
- Santner Snell - difference in proportion


```{r}
X <- matrix(c(3, 0, 0, 3), nrow = 2)
# row is fixed
BarnardTest(X, method = "z-pooled")
# z-pooled observed is...
1 / sqrt(.25 * (1/3 + 1/3)) # observed test statistic

# how to calculate p-value from this test statistic, sum of binomial products from extreme tables,
# the null is that pi_1 = pi_2 = pi, since we don't know the actual value of pi, we take the supremum of these values

true_pi <- seq(0, 1, .01)

possible_p <- dbinom(3, 3, prob = true_pi) * dbinom(0, 3, prob = true_pi) + dbinom(0, 3, prob = true_pi) * dbinom(3, 3, prob = true_pi)


# maximum occurs at .5
true_pi[which.max(possible_p)]

# thus, overall p-value is
max(possible_p) # .03125


```

Now we compare the methods for choosing "extremeness" with the assumed sampling mechanism.

```{r}
set.seed(1)
foo <- rbinom_table(1000, row_n = c(10, 10), p = c(.5, .5)) # null is no association

# z pooled (score)
barnard_pooled <- apply(foo, MARGIN = 3,
                        FUN = function (x) {BarnardTest(x, method = "z-pooled")$p.value})

barnard_unpooled <- apply(foo, MARGIN = 3,
                        FUN = function (x) {BarnardTest(x, method = "z-unpooled")$p.value})

barnard_boschloo <- apply(foo, 
                          MARGIN = 3,
                          FUN = function (x) {BarnardTest(x, method = "boschloo")$p.value})


barnard_csm <- apply(foo, 
                          MARGIN = 3,
                          FUN = function (x) {BarnardTest(x, method = "csm")$p.value})

barnard_santner_snell <- apply(foo, 
                               MARGIN = 3,
                               FUN = function (x) {BarnardTest(x, method = "santner and snell")$p.value})

# for reference
fisher_exact <-  apply(foo, 
                               MARGIN = 3,
                               FUN = function (x) {fisher.test(x)$p.value})



# comment out any that you don't want to appear in the plot
barnard <- bind_cols(pooled = barnard_pooled,
                     unpooled = barnard_unpooled,
                     boschloo = barnard_boschloo,
                     csm = barnard_csm,
                     santner_snell = barnard_santner_snell,
                     fisher_exact = fisher_exact) %>% 
  pivot_longer(everything(), names_to = "type", values_to = "p")

# there's some overplotting happening, dodge doesn't seem to work well for ecdf's
barnard %>% ggplot(aes(x = p, color = type)) +
  stat_ecdf()  +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = 2, alpha = .4) +
  labs(title = "Barnard extremeness method comparison")
```

For accuracy of the size of the test, it seems that csm is the most accurate, but also the most computationally intensive. We not that all the tests have more approriate "size" than the fisher_exact test.

Resources

- [Explanation of difference between unconditional and conditional](https://www.researchgate.net/publication/242179503_Conditional_versus_Unconditional_Exact_Tests_for_Comparing_Two_Binomials)
- [Exact Test Package Documentation](https://cran.r-project.org/web/packages/Exact/Exact.pdf) - `exact.test` function documentation has more information about barnard implmenetation.

### McNemar

McNemar tests are used when there is some "dichotomous trait", for matched pairs. This means that the responses are statistically dependent. This is common for some longitudinal studies in which a single individual is asked two questions, and their answers are coded as locations in the table. Thus, the grand total, should be the number of pairs of data, not the total number of observations.

For example, suppose a person is asked if they voted democrat 

```{r}
tribble(~"", ~"2008 democrat", ~"2008 republican",
        "2004 democrat", 175, 16,
        "2004 republican", 54, 188) %>% 
  kbl()
```

McNemar tests "Marginal Homogeneity", meaning that the probabilities of the margins are the same. $p_a + p_b = p_a + p_c$ and $p_c + p_d = p_b + p_d$. Thus, this means that we are testing $H_0: p_b = p_c$, $H_A: p_b \neq p_c$. The score statistic is:

$$
\begin{aligned}
z_0^2 = \frac{(b-c)^2}{b+c} \sim \chi^2_1
\end{aligned}
$$


<!-- This section needs clarification... -->

Variance is

$$
\begin{aligned}
\hat\sigma_0 (d) = \frac{b + c}{N^2}
\end{aligned}
$$

```{r}
# Presidential election, dependent table
pres <- matrix(c(175, 16,
                      54, 188),
                    ncol = 2,
                    byrow = TRUE)
pres_mcnemar <- mcnemar.test(pres, correct = FALSE)
# (54 - 16)^2 / (54 + 16) # 20.629
pres_mcnemar
```


Notes

- only the off diagonal matters for significance, where as the main diagonal 

A good reference is 11.1 in Categorical Data Analysis, 3rd edition by Agresti

### Breslow-Day Test

a test of homogeneity.

### CMH testing

The CMH testing is technically supposed to be done on tables in strata. the data type is an I X J X K, in which we have K strata and an I X J contingency table in each.

- you are not penalized for adding tables with sparse data with the CMH test statistic
- this reduces to the N-1 adjusted pearson chisquared statistic for 1 strata
- the test assumes that there is a common odds ratio to estimate, but in order to test the hypothesis we can use a Breslow-Day Test of Homogeneity
- Conditional logistic regression gives a similar answer, `clogit` in package `survival` because similar to cox model as well.

 

#### CMH - McNemar Equivalence

If you express the "population averaged" table and run McNemar, you will get the same statistic as expressing the data as a "subject specific" table for an individual per stratum.

```{r}
test <- matrix(c(5, 7, 3, 4), ncol = 2)
chisq.test(test, correct = FALSE)

0.0025703 / 19 * 18 # the "N-1" chisq statistic in a 2 x 2

foo <- array(c(5, 7, 3, 4,
               0, 0, 1, 1), dim = c(2, 2, 2))
mantelhaen.test(foo, correct = FALSE)

bar <- array(c(5, 7, 3, 4,
               0, 0, 1, 1,
               1, 6, 0, 0), dim = c(2, 2, 3))
mantelhaen.test(bar, correct = FALSE)

mantelhaen_2by2 <-  function(x) {
  mantelhaen.test(array(c(x, 0, 0, 1, 1), dim = c(2, 2, 2)), correct = FALSE)
}
```


### 2x2 tables Comparison {.tabset}

#### Poisson Sampling

```{r class.source = "fold-hide", warning = FALSE}
# random poisson
foo <- rpoisson_table(num_tables = 1000, mean = 5, nrow = 2, ncol = 2)

# pearson uncorrected
pearson_uncorrected_p <- 
  apply(foo, 
      MARGIN = 3,
      function(x) {
        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})

# pearson corrected
pearson_corrected_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})

fisher_exact_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(fisher.test(x))$p.value})

# Pearson N-1 correction equivalent
cmh_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          mantelhaen_2by2(x)$p.value
        })

# G-test (LRT)
lrt_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(g.test(x))$p.value
        })


contingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,
          corrected = pearson_corrected_p,
          exact = fisher_exact_p,
          cmh = cmh_p,
          lrt = lrt_p)

contingency_p %>% 
  pivot_longer(everything(), names_to = "test", values_to = "p") %>% 
  ggplot(aes(p, color = test)) +
  stat_ecdf(geom = "step") +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = 2, alpha = .4) + 
  labs(title = "Tests of association") #+
  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in
```

#### Binomial Sampling

```{r class.source = "fold-hide", warning = FALSE}
foo <- rbinom_table(num_tables = 9000)

# pearson uncorrected
pearson_uncorrected_p <- 
  apply(foo, 
      MARGIN = 3,
      function(x) {
        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})

# pearson corrected
pearson_corrected_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})

fisher_exact_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(fisher.test(x))$p.value})

# Pearson N-1 correction equivalent
cmh_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          mantelhaen_2by2(x)$p.value
        })

# G-test (LRT)
lrt_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(g.test(x))$p.value
        })


contingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,
          corrected = pearson_corrected_p,
          exact = fisher_exact_p,
          cmh = cmh_p,
          lrt = lrt_p)

contingency_p %>% 
  pivot_longer(everything(), names_to = "test", values_to = "p") %>% 
  ggplot(aes(p, color = test)) +
  stat_ecdf(geom = "step") +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = 2, alpha = .4) #+
  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in
```

#### Multinomial Sampling

```{r class.source = "fold-hide", warning = FALSE}
foo <- rmultinom_table(num_tables = 1000)

# pearson uncorrected
pearson_uncorrected_p <- 
  apply(foo, 
      MARGIN = 3,
      function(x) {
        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})

# pearson corrected
pearson_corrected_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})

fisher_exact_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(fisher.test(x))$p.value})

# Pearson N-1 correction equivalent
cmh_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          mantelhaen_2by2(x)$p.value
        })

# G-test (LRT)
lrt_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(g.test(x))$p.value
        })


contingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,
          corrected = pearson_corrected_p,
          exact = fisher_exact_p,
          cmh = cmh_p,
          lrt = lrt_p)

contingency_p %>% 
  pivot_longer(everything(), names_to = "test", values_to = "p") %>% 
  ggplot(aes(p, color = test)) +
  stat_ecdf(geom = "step") +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = 2, alpha = .4) #+
  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in
```

#### Hypergeometric Sampling

```{r class.source = "fold-hide", warning = FALSE}
foo <- rhyper_table(num_tables = 1000)

# pearson uncorrected
pearson_uncorrected_p <- 
  apply(foo, 
      MARGIN = 3,
      function(x) {
        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})

# pearson corrected
pearson_corrected_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})

fisher_exact_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(fisher.test(x))$p.value})

# Pearson N-1 correction equivalent
cmh_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          mantelhaen_2by2(x)$p.value
        })

# G-test (LRT)
lrt_p <- 
  apply(foo,
        MARGIN = 3,
        function(x) {
          suppressWarnings(g.test(x))$p.value
        })


contingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,
          corrected = pearson_corrected_p,
          exact = fisher_exact_p,
          cmh = cmh_p,
          lrt = lrt_p)

contingency_p %>% 
  pivot_longer(everything(), names_to = "test", values_to = "p") %>% 
  ggplot(aes(p, color = test)) +
  stat_ecdf(geom = "step") +
  geom_abline(slope = 1, intercept = 0, color = "black", linetype = 2, alpha = .4) #+
  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in
```


## More than two categories

This section starts to get into 2 x I tables, and even more dimensions like, I X J X K tables, and how we analyze those tables. We'll start with an overview of the multinomial theory, which is fundamental in extending the binomial (2 categories) into multiple categories. The binomial is a special case of the multinomial distribution

- `nnet::multinom`
- `VGAM::vglm(family = multinom)`
- `mlogit::mlogit`


A common example we see in this exposition is housing data from library `MASS`

```{r}
library(MASS)
data(housing)

# The array version
housing_arr <- xtabs(Freq~Sat + Infl + Type + Cont, data = housing)
```



### Poisson GLM Modeling

```{r}
# simple glm model (satisfaction independent of Infl, Type, Cont)
house_glm <- glm(Freq ~ Infl*Type*Cont + Sat, data = housing, family = poisson)
summary(house_glm) # high residual deviance
```

Clearly there's probably some correlation between satisfaction and the other variables, let's check them out individually.

```{r}
# addterm will check each term individually, and test marginality
addterm(house_glm, ~. + Sat:(Infl+Type+Cont), test = "Chisq")
```

Influence seems to have the largest impact, so we add this to the model, and type probably has a large

```{r}
house_glm1 <- update(house_glm, .~. + Sat:(Infl + Type + Cont))
summary(house_glm1)
# sum(residuals(house_glm1, type = "pearson")^2) / house_glm1$df.residual # dispersion estimate
house_glm1$df.residual # nrow(housing) - length(coef(house_glm1))
# sum(residuals(house_glm1, type = "deviance")^2) / house_glm1$df.residual
# 1 - pchisq(deviance(house_glm1), house_glm1$df.residual) # .267? what's the test here...
```

See 202 for rescaling the predictions from this model to the probability scale (by the margin of satisfaction)
```{r}
hnames <- lapply(housing[, -5], levels) # 
house_pm <- predict(house_glm1, expand.grid(hnames), type = "response") # poisson means exp(\eta)
house_pm <- matrix(house_pm, ncol = 3, byrow = T, dimnames = list(NULL, hnames[[1]])) # list the predictions into matrix form, columns being satisfaction
cbind(expand.grid(hnames[-1]), house_pm / rowSums(house_pm)) # normalize by row, and attach the name
```

### Log Linear Models

log linear models with iterative proportional scaling is done with function `loglm`.

```{r}
loglm(Freq ~ Infl*Type*Cont + Sat*(Infl + Type + Cont), data = housing)
```

### Multinomial Models

The example data we'll is use party affiliation:

```{r}
# array version of data
party <- array(c(132, 42, 176, 6, 127, 12,
                 172, 56, 129, 4, 130, 15), 
               dim = c(2, 3, 2),
               dimnames = list(race = c("white", "black"),
                               party = c("democrat", "independent", "republican"),
                               gender = c("male", "female")))
party_df <- as.data.frame.table(party) # data frame version of data

# Marginal Tables
race_party <- margin.table(party, margin = 1:2)
gender_party <- margin.table(party, margin = c(3, 2))
race_gender <- margin.table(party, margin = c(1, 3))
```

#### nnet

```{r}
party_mod <- multinom(party ~ race + gender, weights = Freq, party_df) # democrat is the "reference"
summary(party_mod)
```

Hypothesis testing with nnet

#### VGAM

```{r}
# VGAM
# needs version in which "stimulus factors" are separated from "response" factors.
housing_wide <- housing %>% pivot_wider(names_from = "Sat", values_from = "Freq")
```


Our saturated dataset is one in which every cell is estimated with a parameter.

```{r}
# saturated model
housing_vglm0 <- vglm(cbind(Low, Medium, High) ~ Infl*Type*Cont, data = housing_wide, family = multinomial)

deviance(housing_vglm0)
```

In the saturated model, we see that our deviance is equal to 0 because it fits the data perfectly.

```{r}
# full two way interaction model
housing_vglm <- vglm(cbind(Low, Medium, High) ~ (Infl + Type + Cont)^2, data = housing_wide, family = multinomial)
summary(housing_vglm)
deviance(housing_vglm)


# Lack of fit tests
1 - pchisq(deviance(housing_vglm), df.residual(housing_vglm)) # deviance
1 - pchisq(sum(residuals(housing_vglm, type = "pearson")^2), df.residual(housing_vglm)) # pearson
```

The null hypothesis here is that the model is specified correctly. High p-values mean we fail to reject that the model is correct. In general, lack of fit tests are pretty bad tests for telling us any information. We would prefer to do some manual model searching.

```{r}
drop1(housing_vglm, test = "LRT")
```

The results here say that we could probably drop `Infl:Cont` and `Type:Cont`. In fact, dropping `Infl:Cont`, we would get the biggest drop in AIC, indicating better model fit for number of parameters we estimate.

```{r}
housing_vglm1 <- update(housing_vglm, .~. - Infl:Cont)
drop1(housing_vglm1, test = "LRT")
```

Doing it again shows we could again get lower AIC by dropping either parameter.... an automated way of doing this can be done through `step4vglm`

```{r}
# Forward-Backward Step selection on 2-way interaction model
housing_vglm_step <- step4vglm(housing_vglm, direction = "both")
housing_vglm_step@post$anova # shows the steps that the algorithm took
```

The steps the algorithm is saved in the slot `@post$anova`. We can see that the additive model was selected, dropping all the interactions.


```{r}
# additive model
housing_vglm2 <- vglm(cbind(Low, Medium, High) ~ Infl + Type + Cont, data = housing_wide, family = multinomial)

anova(housing_vglm2, housing_vglm, type = 1)
```

there's weak evidence that those dropped coefficients were not zero... so in favor of the more parsimonious and interpretable model, we choose the additive model. Now we do some diagnostics, show the mosaic plot of the pearson chisq values.

```{r}
sum(residuals(housing_vglm2, "pearson")^2) # asymptotically the same
deviance(housing_vglm2) # pretty darn close

# grab standardized residuals... I think theses are on the raw scale, need to derive
housing_vglm2_stdres <- housing_wide %>% 
  dplyr::select(Infl,Type, Cont) %>% 
  bind_cols(residuals(housing_vglm2, "stdres")) %>% 
  pivot_longer(Low:High, names_to = "Sat", values_to = "stdres")

foo <- xtabs(stdres~Sat + Infl + Type, data=housing_vglm2_stdres)

foo
mosaicplot(foo)
```

```{r}
housing_wide_matrix <- housing_wide %>% dplyr::select(Low:High) %>% 
  data.matrix()
sat_margin <- housing_wide_matrix %>% rowSums()

housing_vglm2_predicted <- fitted(housing_vglm2) * sat_margin
(housing_wide_matrix - housing_vglm2_predicted) / sqrt(housing_vglm2_predicted)
residuals(housing_vglm2, type = "response") + fitted(housing_vglm2)

obs_p <- housing_wide_matrix / sat_margin
fit_p <- fitted(housing_vglm2)

residuals(housing_vglm2, type = "response")

# varfun <- object@family@charfun
# vfun <- varfun(x = NULL, eta = predict(object), 
#                   extra = object@extra, varfun = TRUE)
#                 ans <- (y - E1)/sqrt(vfun * (1 - c(hatvalues(object))))
# 
# 1 - hatvalues(housing_vglm2)
# 
# varfun <- housing_vglm2@family@charfun
# vfun <- varfun(x = NULL, eta = predict(housing_vglm2), extra = housing_vglm2@extra, varfun = TRUE)
# 
# housing_vglm2@family@vfamily
# 
# w <- weights(object, type = "prior")
#                 x <- y * c(w)
#                 E1 <- E1 * c(w)
#                 if (any(x < 0) || anyNA(x)) stop("all entries of 'x' must be nonnegative and finite")
#                 if ((n <- sum(x)) == 0) stop("at least one entry of 'x' must be positive")
#                 if (length(dim(x)) > 2L) stop("invalid 'x'")
#                 if (length(x) == 1L) stop("'x' must at least have 2 elements")
#                 sr <- rowSums(x)
#                 sc <- colSums(x)
#                 E <- outer(sr, sc, "*")/n
#                 v <- function(r, c, n) c * r * (n - r) * (n - 
#                   c)/n^3
#                 V <- outer(sr, sc, v, n)
#                 dimnames(E) <- dimnames(x)
#                 ans <- stdres <- (x - E)/sqrt(V)
# rowSums(fitted)
# 
# 
# housing_vglm2@y # observed
plot(housing_vglm2)
coef(housing_vglm2, matrix = TRUE)
```


```{r}
# the predicted probabilities by each of the covariates.
bind_cols(housing_wide %>% dplyr::select(Infl, Type, Cont),
          fitted(housing_vglm2))
```


```{r}
anova(housing_vglm1, housing_vglm, type = 1) # score tests not available in VGAM currently

deviance(housing_vglm)
dropterm(housing_vglm, test = "Chisq")

```
