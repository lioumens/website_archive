{
  "hash": "c0a37186b80babe57997c2fd8d748849",
  "result": {
    "markdown": "---\ntitle: \"Mixed Models\"\nauthor: \"Michael Liou\"\ndate: \"7/2/2019\"\nexecute: \n  cache: true\n---\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-1_7614b21fecb5683990e2ac5fcc6473b2'}\n\n```{.r .cell-code  code-summary=\"Libraries\"}\nlibrary(lattice)\nlibrary(lme4)\nlibrary(nlme)\nlibrary(glmmTMB) # template model builder, designed as improved glmmADMB\nlibrary(tidyverse)\nlibrary(emmeans)\nlibrary(broom.mixed) # clean mixed model outputs\nlibrary(sommer) # asREML replacement\nlibrary(sjPlot) # for plottinge effects\nlibrary(kableExtra) # for tables\nlibrary(afex) # easy anova\nlibrary(reshape2) # for melt function\n```\n:::\n\n\n# Introduction to Mixed Models\n\n## Mixed Model Ecosystem\n\nMixed model software is widely available for most use case scenarios in most commonly used statistical software. Although there are some implementational differences between the software (optimizers, defaults, design philosophy).\n\n### R Package Overview\n\n* **lme4**\n* **nlme**\n\n### SAS Overview\n\n## Example Datasets {.tabset}\n\n* Oats from `nlme` package (balanced split plot design)\n  \n* sleepstudy from `lme4` package\n\n### Oats\n\n* Oats is a good example of a balanced split-plot design, from the **nlme** package.\n* We will remove some data observations to make it incomplete, like they do in [emmeans documentation](https://cran.r-project.org/web/packages/emmeans/vignettes/sophisticated.html)\n\nOats has 3 factors, `yield ~ nitro | block/variety`\n\n* yield (continuous)\n* nitro (4 levels)\n  - 0.0\n  - 0.2\n  - 0.4\n  - 0.6\n* Variety (3 levels)\n  - Victory\n  - Golden Rain\n  - Marvellous\n* Blocks (6 levels)\n\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-2_85fd3c81997b4dfbe4e64a040562b048'}\n\n```{.r .cell-code}\n# intentionally removing some observations\noats_miss <- Oats[-c(1, 2, 3, 5, 8, 13, 21, 34, 55),]\n```\n:::\n\n\n### Sleepstudy\n\n* sleepstudy is a good example of random intercept and coefficient with subject random effect.\n* sleep study is accessible from **lme4** package with `sleepstudy`\n* most examples for lme4 will feature this dataset.\n\n## Resources\n\n* [Ben's Introduction to Mixed Models](https://bbolker.github.io/morelia_2018/notes/mixedlab.html) - basic lab with examples of how to approach mixed models by a prominant mixed models expert.\n\n# Basic Theory\n\nFor a model that shows this \\textit{per subject},\n\n\\begin{equation}\n         Y_i = X_i\\beta + Zu_i + e_i\n\\end{equation}\n\nwith assumptions,\n\n 1. $u_i\\sim MVN(0, D)$\n 2. $e_i\\sim MVN(0, R)$\n 3. $Cov(u, e) = 0$  (Violation of this results in parameter confounding.)\n\n# REML Theory\n\nA step-by-step proof of the mixed model equations can be found on [Kevin Liu's Website: Linear Mixed Model Equations](https://rh8liuqy.github.io/Linear_mixed_model_equations.html).\n\n- [Introduction to REML equations](https://www.stats.net.au/Maths_REML_manual.pdf)\n\n# Software {.tabset}\n\n## nlme\n\nThis section we use the \"Oxide\" example p167 in Mixed-Effects Models in S and S-PLUS.\n\nnlme introduces the class \"groupedData\", for which has a natural methods for which we can use\n\nlme also has a LOT of variance classes that can fit R variances of individuals according to covariates as well! See ?varClasses for the documentation of this and see [MLM Heterogenous Variance](https://quantdev.ssri.psu.edu/sites/qdev/files/ILD_Ch06_2017_MLMwithHeterogeneousVariance.html) for an example.\n\nMany methods that apply to class `lme` objects,\n\n* `intervals(lmod)` - confidence intervals around parameters\n  * \"using a normal approximation to the distribution of the (restricted) maximum likelihood estimators (the estimators are assumed to have a normal distribution centered at the true parameter values and with covariance matrix equal to the negative inverse Hessian matrix of the (restricted) log-likelihood evaluated at the estimated parameters).\" ~ from documentation\n* `augPred` - produces preditions of the response for each group, and produces plot of predicted lines for each subject superposed on the original data.\n* `plot(compareFits(coef(mod), coef(mod2)))` - plot estimates of two models, (like REML vs ML) estimates.\n* `getVarCov` - gives marginal and conditional covariance matrices, very useful!\n* `VarCorr` - instead of covariances, list the correlations\n\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-3_01599a5187fa825506b4f1a909172941'}\n\n```{.r .cell-code}\n# random defaults to the rhs of grouped Data\nformula(Oxide) # shows that it has a grouping structure\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThickness ~ 1 | Lot/Wafer\n```\n:::\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-4_2e7d929f25925c8a6f62577cb14413df'}\n\n```{.r .cell-code}\n# The example of how to create a new grouped object\nOrth.new <-  # create a new copy of the groupedData object\n  groupedData(distance ~ age | Subject,\n              data = as.data.frame( Orthodont ),\n              FUN = mean,\n              outer = ~ Sex,\n              labels = list( x = \"Age\",\n                y = \"Distance from pituitary to pterygomaxillary fissure\" ),\n              units = list( x = \"(yr)\", y = \"(mm)\") )\n# formula(Orth.new)\n# plot(Orth.new)\n# gsummary(Orth.new)\north_lmod <- lme(Orth.new)\n# orth_vario <- Variogram(orth_lmod) # doesn't quite look right....\n```\n:::\n\n\n## lme4\n\nSome common accessor functions for working with mixed models and what they return:\n\n- `summary()` - all the important information\n- `fixef()` - the $\\beta$ part of the equation\n- `ranef()` - the $u$ part of the equation\n- `getME()` - Get very specific components of an object of class `merMod`. See the help function for full list\n  - `X` - fixed-effects model matrix\n  - `Z` - random-effects model matrix\n  - `mu` - conditional mean of response\n  - `b` - conditional mode of random effects variable\n  - `theta` - just the parameters in the covariance matrix $G$\n  - `sigma` - relative variance factor\n  - `Lambda` - squareroot of random effect covariance,  $G = \\sigma^2LL'$\n- `predict(mod, re.form = \"NA | NULL | ~subject\")` - predictions with different levels of random effect structures\n\n## lmeInfo\n\nGives expected information and variance components from information matrices of \"lme\" models. Useful because lme doesn't report the standard errors from the objects \n\n## sommer\n\n## glmmTMB\n\n# Basics of Mixed Models in R\n \n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-5_ccdc460d909d4962b94a4dda4b101916'}\n\n```{.r .cell-code}\n# Oats Model\noats_mod <- lme4::lmer(yield~Variety + factor(nitro) + (1|Block/Variety), data = oats_miss, REML = TRUE)\nsleep_mod <- lmer(Reaction ~ Days + (Days | Subject), data=sleepstudy)\n```\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-6_f25451391444160343b3947acb3748d4'}\n\n```{.r .cell-code}\nsummary(oats_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: yield ~ Variety + factor(nitro) + (1 | Block/Variety)\n   Data: oats_miss\n\nREML criterion at convergence: 495.9\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.77507 -0.69966 -0.06888  0.55169  1.64128 \n\nRandom effects:\n Groups        Name        Variance Std.Dev.\n Variety:Block (Intercept)  76.28    8.734  \n Block         (Intercept) 209.44   14.472  \n Residual                  180.49   13.435  \nNumber of obs: 63, groups:  Variety:Block, 18; Block, 6\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)         80.585      8.180   9.851\nVarietyMarvellous    3.229      6.545   0.493\nVarietyVictory      -8.306      6.674  -1.245\nfactor(nitro)0.2    18.142      5.005   3.625\nfactor(nitro)0.4    35.306      5.004   7.055\nfactor(nitro)0.6    45.176      4.925   9.172\n\nCorrelation of Fixed Effects:\n            (Intr) VrtyMr VrtyVc f()0.2 f()0.4\nVartyMrvlls -0.405                            \nVarityVctry -0.383  0.495                     \nfctr(nt)0.2 -0.338  0.024 -0.002              \nfctr(nt)0.4 -0.323 -0.014 -0.021  0.543       \nfctr(nt)0.6 -0.320 -0.016 -0.055  0.544  0.545\n```\n:::\n\n```{.r .cell-code}\nsummary(sleep_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: Reaction ~ Days + (Days | Subject)\n   Data: sleepstudy\n\nREML criterion at convergence: 1743.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-3.9536 -0.4634  0.0231  0.4634  5.1793 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr\n Subject  (Intercept) 612.10   24.741       \n          Days         35.07    5.922   0.07\n Residual             654.94   25.592       \nNumber of obs: 180, groups:  Subject, 18\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)  251.405      6.825  17.000  36.838  < 2e-16 ***\nDays          10.467      1.546  17.000   6.771 3.26e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n     (Intr)\nDays -0.138\n```\n:::\n:::\n\n\n\n## Fixed Effects\n\nThe reported fixed effects from `fixef(mod)` is really just the average of all across all the individual fits that were created\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-7_81943c8bf6cd9e6d052497c0a6129c18'}\n\n```{.r .cell-code}\n# These are the same! \nfixef(sleep_mod) # %>% as.data.frame() # makes it nicer to work with\n## (Intercept)        Days \n##   251.40510    10.46729\ncolMeans(coef(sleep_mod)$Subject)\n## (Intercept)        Days \n##   251.40510    10.46729\n```\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-8_a5b33c1516917a59258c5ec73ce3d349'}\n\n```{.r .cell-code}\n# Results aren't shown, but this is how to get them.\nsummary(oats_mod)\nranef(oats_mod) # %>% as.data.frame() # makes it nicer to work with\nfixef(oats_mod) # %>% as.data.frame() # makes it nicer to work with\n\n# Something to do with subject level standard errors\nattr(ranef(oats_mod, condVar = TRUE, drop = TRUE)$`Variety:Block`, \"postVar\")\n\n# Standard errors for random effects\nprint(vc <- VarCorr(oats_mod), comp = c(\"Variance\", \"Std.Dev.\")) %>%\n  as.data.frame(order = \"lower.tri\")\n```\n:::\n\n\n\n## Random Effects\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-9_0dd405ebd72090dace8027f84b8a1382'}\n\n```{.r .cell-code}\n# From the help on ranef\nstr(ranef(sleep_mod))\nas.data.frame(ranef(sleep_mod))\nrr <- ranef(sleep_mod)\ndd <- as.data.frame(rr)\ndotplot(rr,scales = list(x = list(relation = 'free')))[[\"Subject\"]] # This just allows the x access to be different between the two objects\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-10_0164544e9e8224fe9f73d9ed7736eced'}\n\n```{.r .cell-code}\n# How to replicate dotplot in ggplot!\n# The \"free_x\" is allowing different value scales...\nggplot(dd, aes(y=grp,x=condval)) +\n  geom_point() + facet_wrap(~term,scales=\"free_x\") +\n  geom_errorbarh(aes(xmin=condval -2*condsd,\n                     xmax=condval +2*condsd), height=0)\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n### Random Effect Variance\n\nMore specifically, these are the variances of the conditional modes\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-11_58d2a0799c0275a72e8d975533a12138'}\n\n```{.r .cell-code}\ncov_mat <- VarCorr(sleep_mod)[[\"Subject\"]]\ncov_mat # shows the correlation between random effects as well\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            (Intercept)      Days\n(Intercept)  612.100158  9.604409\nDays           9.604409 35.071714\nattr(,\"stddev\")\n(Intercept)        Days \n  24.740658    5.922138 \nattr(,\"correlation\")\n            (Intercept)       Days\n(Intercept)  1.00000000 0.06555124\nDays         0.06555124 1.00000000\n```\n:::\n\n```{.r .cell-code}\nprint(VarCorr(sleep_mod), comp=c(\"Variance\")) # extract the variance estimates of random effects (shown in summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Groups   Name        Variance Corr \n Subject  (Intercept) 612.100       \n          Days         35.072  0.066\n Residual             654.940       \n```\n:::\n:::\n\n\nSimilarly, the conditional variance-covariance matrix of the random effects can be extracted by the following. These variances are conditional on the data and \n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-12_39454a4eb0e745ef92afcab72fac8e99'}\n\n```{.r .cell-code}\nattr(ranef(sleep_mod)$Subject, \"postVar\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, , 1\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 2\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 3\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 4\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 5\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 6\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 7\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 8\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 9\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 10\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 11\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 12\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 13\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 14\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 15\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 16\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 17\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n\n, , 18\n\n         [,1]       [,2]\n[1,] 145.7056 -21.444504\n[2,] -21.4445   5.312283\n```\n:::\n\n```{.r .cell-code}\n# ?ranef\n```\n:::\n\n\nA cleaner data frame version of the above with standard deviations, (no correlation)\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-13_0beca154c8af5b18162920d25cd917af'}\n\n```{.r .cell-code}\nas.data.frame(ranef(sleep_mod))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    grpvar        term grp     condval    condsd\n1  Subject (Intercept) 308   2.2585509 12.070857\n2  Subject (Intercept) 309 -40.3987381 12.070857\n3  Subject (Intercept) 310 -38.9604090 12.070857\n4  Subject (Intercept) 330  23.6906196 12.070857\n5  Subject (Intercept) 331  22.2603126 12.070857\n6  Subject (Intercept) 332   9.0395679 12.070857\n7  Subject (Intercept) 333  16.8405086 12.070857\n8  Subject (Intercept) 334  -7.2326151 12.070857\n9  Subject (Intercept) 335  -0.3336684 12.070857\n10 Subject (Intercept) 337  34.8904868 12.070857\n11 Subject (Intercept) 349 -25.2102286 12.070857\n12 Subject (Intercept) 350 -13.0700342 12.070857\n13 Subject (Intercept) 351   4.5778642 12.070857\n14 Subject (Intercept) 352  20.8636782 12.070857\n15 Subject (Intercept) 369   3.2754656 12.070857\n16 Subject (Intercept) 370 -25.6129993 12.070857\n17 Subject (Intercept) 371   0.8070461 12.070857\n18 Subject (Intercept) 372  12.3145921 12.070857\n19 Subject        Days 308   9.1989758  2.304839\n20 Subject        Days 309  -8.6196806  2.304839\n21 Subject        Days 310  -5.4488565  2.304839\n22 Subject        Days 330  -4.8143503  2.304839\n23 Subject        Days 331  -3.0699116  2.304839\n24 Subject        Days 332  -0.2721770  2.304839\n25 Subject        Days 333  -0.2236361  2.304839\n26 Subject        Days 334   1.0745816  2.304839\n27 Subject        Days 335 -10.7521652  2.304839\n28 Subject        Days 337   8.6282652  2.304839\n29 Subject        Days 349   1.1734322  2.304839\n30 Subject        Days 350   6.6142178  2.304839\n31 Subject        Days 351  -3.0152621  2.304839\n32 Subject        Days 352   3.5360011  2.304839\n33 Subject        Days 369   0.8722149  2.304839\n34 Subject        Days 370   4.8224850  2.304839\n35 Subject        Days 371  -0.9881562  2.304839\n36 Subject        Days 372   1.2840221  2.304839\n```\n:::\n\n```{.r .cell-code}\n# broom.mixed alternative, with same output\nbroom.mixed::tidy(sleep_mod, effects = \"ran_vals\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 36 × 6\n   effect   group   level term        estimate std.error\n   <chr>    <chr>   <chr> <chr>          <dbl>     <dbl>\n 1 ran_vals Subject 308   (Intercept)    2.26       12.1\n 2 ran_vals Subject 309   (Intercept)  -40.4        12.1\n 3 ran_vals Subject 310   (Intercept)  -39.0        12.1\n 4 ran_vals Subject 330   (Intercept)   23.7        12.1\n 5 ran_vals Subject 331   (Intercept)   22.3        12.1\n 6 ran_vals Subject 332   (Intercept)    9.04       12.1\n 7 ran_vals Subject 333   (Intercept)   16.8        12.1\n 8 ran_vals Subject 334   (Intercept)   -7.23       12.1\n 9 ran_vals Subject 335   (Intercept)   -0.334      12.1\n10 ran_vals Subject 337   (Intercept)   34.9        12.1\n# … with 26 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\n## Plotting Effects\n\nThere are a few packages that automate the effect plotting\n\n- \"effects\"\n- \"ggeffects\"\n- [\"sjPlot\"](https://cran.r-project.org/web/packages/sjPlot/vignettes/plot_model_estimates.html)\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-14_751722bfdefd5ae155eca3b1e006b95d'}\n\n```{.r .cell-code}\n# sjPLot\nplot_model(oats_mod,\n           show.values = TRUE,  # show overlay\n           value.offset = .3) # offset above\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\nsome useful options\n\n- `terms = c(\"factor(nitro)0.2\", \"factor(nitro)0.4\"`\n\n\n# Inference in Mixed Models\n\nA wonderful resource for discussing inference in mixed models is given by [Faraway's Inferential Methods for Linear Mixed Models](https://people.bath.ac.uk/jjf23/mixchange/index.html#worked-examples)\n\n# Correlation structures\n\n\n\n## varFunc variance functions\n\nvarfunc is for modeling variance with covariate, for heterogeneity\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-15_2e597165a5293d0caaf085c97224d4dd'}\n\n```{.r .cell-code}\nDialyzer$QB\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200\n [19] 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200\n [37] 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200\n [55] 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 200 300 300\n [73] 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300\n [91] 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300\n[109] 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300\n[127] 300 300 300 300 300 300 300 300 300 300 300 300 300 300\nLevels: 200 300\n```\n:::\n\n```{.r .cell-code}\nDialyzer %>% ggplot(aes(pressure, rate, group = Subject)) + \n  geom_point() +\n  geom_line() + \n  facet_wrap(~QB)\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# relevel so 300 is first\nDialyzer$QB <- factor(Dialyzer$QB, levels = c(300, 200))\ncontrasts(Dialyzer$QB) <- contr.sum(levels(Dialyzer$QB))\n\ndial_lme <- lme(rate ~ pressure*QB + I(pressure^2)*QB + I(pressure^3)*QB + I(pressure^4)*QB,\n                data =  Dialyzer,\n                random = ~pressure + pressure^2)\n\nsummary(dial_lme)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: Dialyzer \n       AIC      BIC    logLik\n  705.0693 745.2148 -338.5347\n\nRandom effects:\n Formula: ~pressure + pressure^2 | Subject\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev   Corr  \n(Intercept) 2.334516 (Intr)\npressure    1.546108 -0.398\nResidual    2.188620       \n\nFixed effects:  rate ~ pressure * QB + I(pressure^2) * QB + I(pressure^3) * QB +      I(pressure^4) * QB \n                      Value Std.Error  DF   t-value p-value\n(Intercept)       -16.70523  1.723312 112 -9.693679  0.0000\npressure           89.12680  6.790445 112 13.125327  0.0000\nQB1                -1.02095  1.723312  18 -0.592433  0.5609\nI(pressure^2)     -43.31114  8.110964 112 -5.339827  0.0000\nI(pressure^3)       9.49376  3.669924 112  2.586910  0.0110\nI(pressure^4)      -0.81949  0.556104 112 -1.473624  0.1434\npressure:QB1        1.84205  6.790445 112  0.271271  0.7867\nQB1:I(pressure^2)  -0.16107  8.110964 112 -0.019859  0.9842\nQB1:I(pressure^3)   0.80053  3.669924 112  0.218133  0.8277\nQB1:I(pressure^4)  -0.19529  0.556104 112 -0.351169  0.7261\n Correlation: \n                  (Intr) pressr QB1    I(p^2) I(p^3) I(p^4) pr:QB1 QB1:I(^2\npressure          -0.923                                                   \nQB1                0.098 -0.087                                            \nI(pressure^2)      0.872 -0.984  0.077                                     \nI(pressure^3)     -0.828  0.955 -0.070 -0.992                              \nI(pressure^4)      0.789 -0.923  0.064  0.974 -0.995                       \npressure:QB1      -0.087  0.076 -0.923 -0.066  0.058 -0.053                \nQB1:I(pressure^2)  0.077 -0.066  0.872  0.056 -0.049  0.044 -0.984         \nQB1:I(pressure^3) -0.070  0.058 -0.828 -0.049  0.043 -0.038  0.955 -0.992  \nQB1:I(pressure^4)  0.064 -0.053  0.789  0.044 -0.038  0.034 -0.923  0.974  \n                  QB1:I(^3\npressure                  \nQB1                       \nI(pressure^2)             \nI(pressure^3)             \nI(pressure^4)             \npressure:QB1              \nQB1:I(pressure^2)         \nQB1:I(pressure^3)         \nQB1:I(pressure^4) -0.995  \n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-2.4923834 -0.5199016 -0.0168656  0.4604300  2.6001042 \n\nNumber of Observations: 140\nNumber of Groups: 20 \n```\n:::\n\n```{.r .cell-code}\nplot(dial_lme, resid(., type = \"pearson\")~pressure, abline = 0)\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-15-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# update the weights by pressure\ndial_lme2 <- update(dial_lme,\n       weights = varPower(form = ~pressure))\n\nsummary(dial_lme2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: Dialyzer \n       AIC      BIC    logLik\n  681.9085 724.9216 -325.9543\n\nRandom effects:\n Formula: ~pressure + pressure^2 | Subject\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev   Corr  \n(Intercept) 1.899460 (Intr)\npressure    1.679911 -0.344\nResidual    1.712085       \n\nVariance function:\n Structure: Power of variance covariate\n Formula: ~pressure \n Parameter estimates:\n    power \n0.6416526 \nFixed effects:  rate ~ pressure * QB + I(pressure^2) * QB + I(pressure^3) * QB +      I(pressure^4) * QB \n                      Value Std.Error  DF    t-value p-value\n(Intercept)       -17.54492  0.964974 112 -18.181745  0.0000\npressure           93.06697  4.242482 112  21.936918  0.0000\nQB1                -1.07348  0.964974  18  -1.112445  0.2806\nI(pressure^2)     -48.35597  5.761060 112  -8.393588  0.0000\nI(pressure^3)      11.85545  2.886244 112   4.107570  0.0001\nI(pressure^4)      -1.18275  0.472928 112  -2.500914  0.0138\npressure:QB1        1.97424  4.242482 112   0.465350  0.6426\nQB1:I(pressure^2)  -0.26514  5.761060 112  -0.046023  0.9634\nQB1:I(pressure^3)   0.83421  2.886244 112   0.289030  0.7731\nQB1:I(pressure^4)  -0.19923  0.472928 112  -0.421260  0.6744\n Correlation: \n                  (Intr) pressr QB1    I(p^2) I(p^3) I(p^4) pr:QB1 QB1:I(^2\npressure          -0.886                                                   \nQB1                0.115 -0.100                                            \nI(pressure^2)      0.831 -0.977  0.084                                     \nI(pressure^3)     -0.783  0.939 -0.072 -0.989                              \nI(pressure^4)      0.738 -0.898  0.064  0.965 -0.993                       \npressure:QB1      -0.100  0.084 -0.886 -0.068  0.057 -0.050                \nQB1:I(pressure^2)  0.084 -0.068  0.831  0.054 -0.045  0.039 -0.977         \nQB1:I(pressure^3) -0.072  0.057 -0.783 -0.045  0.037 -0.032  0.939 -0.989  \nQB1:I(pressure^4)  0.064 -0.050  0.738  0.039 -0.032  0.027 -0.898  0.965  \n                  QB1:I(^3\npressure                  \nQB1                       \nI(pressure^2)             \nI(pressure^3)             \nI(pressure^4)             \npressure:QB1              \nQB1:I(pressure^2)         \nQB1:I(pressure^3)         \nQB1:I(pressure^4) -0.993  \n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.08149251 -0.57786661 -0.04607249  0.47502441  2.58366062 \n\nNumber of Observations: 140\nNumber of Groups: 20 \n```\n:::\n\n```{.r .cell-code}\ncbind(AIC(dial_lme),\n      AIC(dial_lme2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         [,1]     [,2]\n[1,] 705.0693 681.9085\n```\n:::\n\n```{.r .cell-code}\nplot(dial_lme2, \n     resid(., type = \"pearson\")~pressure,\n     abline = 0)\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-15-3.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(dial_lme2,\n     resid(., type = \"pearson\")~pressure | QB,\n           abline =0) # increasing heterogeneity in both \n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-15-4.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(dial_lme,\n     resid(., type = \"pearson\")~pressure | QB,\n           abline =0) # increasing heterogeneity in both \n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-15-5.png){width=672}\n:::\n\n```{.r .cell-code}\ngetVarCov(dial_lme2, type = \"marginal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSubject 1 \nMarginal variance covariance matrix\n       1      2      3       4       5       6       7\n1 3.7128 3.1317 2.9254  2.7190  2.4938  2.2938  2.0937\n2 3.1317 4.4381 3.3784  3.5385  3.7134  3.8686  4.0238\n3 2.9254 3.3784 7.1286  5.0538  5.9685  6.7805  7.5926\n4 2.7190 3.5385 5.0538 11.4380  8.2236  9.6925 11.1610\n5 2.4938 3.7134 5.9685  8.2236 17.9120 12.8720 15.0580\n6 2.2938 3.8686 6.7805  9.6925 12.8720 25.1700 18.5170\n7 2.0937 4.0238 7.5926 11.1610 15.0580 18.5170 33.8280\n  Standard Deviations: 1.9269 2.1067 2.6699 3.382 4.2323 5.017 5.8162 \n```\n:::\n\n```{.r .cell-code}\ndist(Dialyzer$pressure[Dialyzer$Subject == 1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      1     2     3     4     5     6\n2 0.265                              \n3 0.755 0.490                        \n4 1.245 0.980 0.490                  \n5 1.780 1.515 1.025 0.535            \n6 2.255 1.990 1.500 1.010 0.475      \n7 2.730 2.465 1.975 1.485 0.950 0.475\n```\n:::\n:::\n\n\n## lme corstruct\n\ncorstructs are for modeling with \"distances\"\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-16_d9a62e1d0a3df9a62454fc7e42b7546d'}\n\n```{.r .cell-code}\nspatDat <- data.frame(x = c(0, .25, .5, .75, 1), y = c(0, .25, .5, .75, 1))\nexample_cormat <- Initialize(corExp(c(1,.2),\n                                    form = ~x + y, # specifies the position vector and | grouping variable\n                                    nugget = TRUE), spatDat)\n\ncorMatrix(example_cormat)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          [,1]      [,2]      [,3]      [,4]      [,5]\n[1,] 1.0000000 0.5617508 0.3944550 0.2769817 0.1944934\n[2,] 0.5617508 1.0000000 0.5617508 0.3944550 0.2769817\n[3,] 0.3944550 0.5617508 1.0000000 0.5617508 0.3944550\n[4,] 0.2769817 0.3944550 0.5617508 1.0000000 0.5617508\n[5,] 0.1944934 0.2769817 0.3944550 0.5617508 1.0000000\n```\n:::\n\n```{.r .cell-code}\nplot(Variogram(example_cormat, distance = seq(0, 3, .1)))\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n## Variograms\n\n(semi) variogram are a way of plotting and visualizing correlations over time/space\n\n$$\n\\begin{aligned}\n\\gamma[d(\\varepsilon_x, \\varepsilon_y), \\mathbf{\\lambda}] &= \\frac{1}{2}\\operatorname{Var}(\\varepsilon_x - \\varepsilon_y) \\\\\n&= \\frac{1}{2}E[\\varepsilon_x - \\varepsilon_y]^2\n\\end{aligned}\n$$\n\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-17_cc3de7041326594fd07fd25526b260a6'}\n\n```{.r .cell-code}\n# calculating the variogram manually\nplot(Variogram(c(1, 3, -1, 5), # time points\n               c(1, .3, .5, 2, 7, .2))) # values at time points\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\npseudoinverse used at 0.166\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nneighborhood radius 0.334\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nreciprocal condition number 0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nThere are other near singularities as well. 36.409\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\npseudoinverse used at 0.166\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nneighborhood radius 0.334\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nreciprocal condition number 0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nThere are other near singularities as well. 36.409\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\npseudoinverse used at 0.166\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nneighborhood radius 0.334\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nreciprocal condition number 0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = FALSE, :\nThere are other near singularities as well. 36.409\n```\n:::\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n```{.r .cell-code}\nval <- outer(c(1, 3, -1, 5), c(1, 3, -1, 5), function(x, y) (y - x)^2 / 2)\nval <- val[lower.tri(val)]\nval # the variogram values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1]  2  2  8  8  2 18\n```\n:::\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-18_e0d93dc147a269eb1e6e973ee96fd793'}\n\n```{.r .cell-code}\nn <- 20 # 20 obs\nN <- 100 # nodes\n\nrandomwalk <- function(N) {\n  cumsum(rnorm(N))\n}\nset.seed(1)\nrw_mat <- replicate(1000,\n          randomwalk(6))\n```\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-19_ff6ff53ce4a639f12c031cc5da898435'}\n\n```{.r .cell-code}\nrw_dat <- rw_mat %>% melt(c(\"node\",\"obs\"))\n\nrw_mat %>% t() %>% cov() # sample covariance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         [,1]     [,2]     [,3]     [,4]     [,5]     [,6]\n[1,] 1.065027 1.069246 1.083659 1.067816 1.093611 1.149804\n[2,] 1.069246 2.068872 2.093093 2.113653 2.145208 2.199581\n[3,] 1.083659 2.093093 3.211379 3.242694 3.287997 3.324031\n[4,] 1.067816 2.113653 3.242694 4.286559 4.353058 4.374326\n[5,] 1.093611 2.145208 3.287997 4.353058 5.426274 5.461257\n[6,] 1.149804 2.199581 3.324031 4.374326 5.461257 6.552920\n```\n:::\n\n```{.r .cell-code}\nrw_dat %>% ggplot(aes(node, value)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\nrw_gls <- gls(value~1,  data = rw_dat,\n          correlation = corSymm(form = ~1|obs),\n          weights = varIdent(form = ~1 | node))\n\n\ngetVarCov(rw_gls)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMarginal variance covariance matrix\n       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]\n[1,] 1.0650 1.0692 1.0836 1.0677 1.0935 1.1497\n[2,] 1.0692 2.0679 2.0919 2.1127 2.1440 2.1983\n[3,] 1.0836 2.0919 3.2093 3.2401 3.2857 3.3218\n[4,] 1.0677 2.1127 3.2401 4.2836 4.3496 4.3707\n[5,] 1.0935 2.1440 3.2857 4.3496 5.4218 5.4567\n[6,] 1.1497 2.1983 3.3218 4.3707 5.4567 6.5473\n  Standard Deviations: 1.032 1.438 1.7915 2.0697 2.3285 2.5588 \n```\n:::\n\n```{.r .cell-code}\ngetVarCov(rw_gls, individual = 4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMarginal variance covariance matrix\n       [,1]   [,2]   [,3]   [,4]   [,5]   [,6]\n[1,] 1.0650 1.0692 1.0836 1.0677 1.0935 1.1497\n[2,] 1.0692 2.0679 2.0919 2.1127 2.1440 2.1983\n[3,] 1.0836 2.0919 3.2093 3.2401 3.2857 3.3218\n[4,] 1.0677 2.1127 3.2401 4.2836 4.3496 4.3707\n[5,] 1.0935 2.1440 3.2857 4.3496 5.4218 5.4567\n[6,] 1.1497 2.1983 3.3218 4.3707 5.4567 6.5473\n  Standard Deviations: 1.032 1.438 1.7915 2.0697 2.3285 2.5588 \n```\n:::\n\n```{.r .cell-code}\nrw_cs_cov <- corMatrix(Initialize(corCompSymm(value = .3, form = ~1 | obs), rw_dat))\n\nrw_cs_cov %>% length()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1000\n```\n:::\n:::\n\n\n\n## Example: BodyWeight\n\nbody weight of rats measured over 64 days and 3 different diets\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-20_74e1f19cf4e1497f4869a593d9322b60'}\n\n```{.r .cell-code}\nBodyWeight %>% ggplot(aes(Time, weight, group = Rat)) +\n  geom_line() +\n  facet_wrap(~Diet)\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Residuals\nbw_lme <- lme(weight ~ Time * Diet, BodyWeight,\n    random = ~Time | Rat)\n\n\n\n# model with varPower\nbw_lme2 <- update(bw_lme, weights = varPower())\nplot(bw_lme, resid(., type = \"p\") ~ Time) # Residual plot\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(bw_lme2, resid(., type = \"p\")~Time) # such a subtle difference... how much effect does it really have. yet it's strongly statistically significant\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-20-3.png){width=672}\n:::\n\n```{.r .cell-code}\nanova(bw_lme, bw_lme2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        Model df      AIC      BIC    logLik   Test  L.Ratio p-value\nbw_lme      1 10 1171.720 1203.078 -575.8599                        \nbw_lme2     2 11 1163.921 1198.415 -570.9607 1 vs 2 9.798326  0.0017\n```\n:::\n:::\n\n\nThe anova gives a significant result, meaning that the covariance with heterogenous modeling is better, but if you look summary of the results, the standard errors are really not that different, maybe a difference of about 10%.\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-21_532eb5b5d21af96a92b29d4a70895ac4'}\n\n```{.r .cell-code}\nsummary(bw_lme)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: BodyWeight \n      AIC      BIC    logLik\n  1171.72 1203.078 -575.8599\n\nRandom effects:\n Formula: ~Time | Rat\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev     Corr  \n(Intercept) 36.9390723 (Intr)\nTime         0.2484113 -0.149\nResidual     4.4436052       \n\nFixed effects:  weight ~ Time * Diet \n                Value Std.Error  DF   t-value p-value\n(Intercept) 251.65165 13.094025 157 19.218816  0.0000\nTime          0.35964  0.091140 157  3.946019  0.0001\nDiet2       200.66549 22.679516  13  8.847873  0.0000\nDiet3       252.07168 22.679516  13 11.114509  0.0000\nTime:Diet2    0.60584  0.157859 157  3.837858  0.0002\nTime:Diet3    0.29834  0.157859 157  1.889903  0.0606\n Correlation: \n           (Intr) Time   Diet2  Diet3  Tm:Dt2\nTime       -0.160                            \nDiet2      -0.577  0.092                     \nDiet3      -0.577  0.092  0.333              \nTime:Diet2  0.092 -0.577 -0.160 -0.053       \nTime:Diet3  0.092 -0.577 -0.053 -0.160  0.333\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-3.25558796 -0.42196874  0.08229384  0.59933559  2.78994477 \n\nNumber of Observations: 176\nNumber of Groups: 16 \n```\n:::\n\n```{.r .cell-code}\nsummary(bw_lme2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed-effects model fit by REML\n  Data: BodyWeight \n       AIC      BIC    logLik\n  1163.921 1198.415 -570.9607\n\nRandom effects:\n Formula: ~Time | Rat\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev     Corr  \n(Intercept) 36.8980214 (Intr)\nTime         0.2436518 -0.145\nResidual     0.1751704       \n\nVariance function:\n Structure: Power of variance covariate\n Formula: ~fitted(.) \n Parameter estimates:\n    power \n0.5428447 \nFixed effects:  weight ~ Time * Diet \n                Value Std.Error  DF   t-value p-value\n(Intercept) 251.60215 13.067335 157 19.254281  0.0000\nTime          0.36109  0.088378 157  4.085720  0.0001\nDiet2       200.77697 22.656249  13  8.861881  0.0000\nDiet3       252.17017 22.661603  13 11.127640  0.0000\nTime:Diet2    0.60183  0.155424 157  3.872180  0.0002\nTime:Diet3    0.29524  0.155892 157  1.893847  0.0601\n Correlation: \n           (Intr) Time   Diet2  Diet3  Tm:Dt2\nTime       -0.152                            \nDiet2      -0.577  0.088                     \nDiet3      -0.577  0.088  0.333              \nTime:Diet2  0.087 -0.569 -0.157 -0.050       \nTime:Diet3  0.086 -0.567 -0.050 -0.158  0.322\n\nStandardized Within-Group Residuals:\n        Min          Q1         Med          Q3         Max \n-2.93736805 -0.44386633  0.07986351  0.58084818  2.26489822 \n\nNumber of Observations: 176\nNumber of Groups: 16 \n```\n:::\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-22_487ed451cff476a479910f8fa3cee9d3'}\n\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-23_ee235ff7cf4db7bd2585ba8fabd4461c'}\n\n```{.r .cell-code}\n# variogram seems to increase at 20 days, so model with exponential spatial\nplot(Variogram(bw_lme, form = ~Time, maxDist = 42)) # loess smoother\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\nbw_lme3 <- update(bw_lme, corr = corExp(form = ~Time))\n\nplot(Variogram(bw_lme3, maxDist = 42, form = ~Time, \n               resType = \"normalized\",\n               robust = T), ylim = c(0, 1.4)) # fit with time variogram\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-23-2.png){width=672}\n:::\n:::\n\n\nUse the normalized residuals and robust\n\n\n\n\n\n\n\n# Computational Notes\n\n* For large models, with crossed and partially crossed factors, you should consider adding `gradient = FALSE, niterEM = 0)`, because the gradient calculation and EMCE iteration both require a calculation that needs to invert a cholesky factor of crossproduct matrix. It's a slow process and can slow down the optimization. Bates said maybe it could be default when there are multiple, non-nested grouping factors. See [thread](https://stat.ethz.ch/pipermail/r-help/2006-October/115572.html) for more details.\n\n\n# Cookbook\n\n## Using covariate as both random and fixed effect\n\nThere is a blog post with this phenomena\n\n## Plot of Shrinkage (sleepstudy)\n\nThis stuff is from this blog post: https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/\n\nLooking at the shrinkage stuff though, there's also from [Bates](http://lme4.r-forge.r-project.org/slides/2011-03-16-Amsterdam/2Longitudinal.pdf)\n\n\n::: {.cell hash='mixed_cache/html/Initialization_ba643c925d4490c4a04f4fc48a56596b'}\n\n```{.r .cell-code}\nsleepstudy <- sleepstudy %>% as_tibble() %>% mutate(Subject = as.character(Subject))\nsleepstudy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 180 × 3\n   Reaction  Days Subject\n      <dbl> <dbl> <chr>  \n 1     250.     0 308    \n 2     259.     1 308    \n 3     251.     2 308    \n 4     321.     3 308    \n 5     357.     4 308    \n 6     415.     5 308    \n 7     382.     6 308    \n 8     290.     7 308    \n 9     431.     8 308    \n10     466.     9 308    \n# … with 170 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n\n```{.r .cell-code}\n# Adding two participants to illustrate partial pooling\ndf_sleep <- bind_rows(\n  sleepstudy,\n  tibble(Reaction = c(286, 288), Days = 0:1, Subject = \"374\"),\n  tibble(Reaction = 245, Days = 0, Subject = \"373\"))\n```\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-24_17f766743b4bc4ff30d854b3559316bd'}\n\n```{.r .cell-code}\nggplot(df_sleep, aes(Days, Reaction)) + \n  facet_wrap(~Subject) +\n  geom_point() +\n  geom_smooth(method=lm, se=FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nFitting all the linear models all at once, `lme4` provides a convenience function for that with s3 methods defined as well: coef, confint, fitted, fixef, formula, logLik, pairs, plot, predict, print, qqnorm, ranef, residuals, sigma, summary, and update\n\n### No Pooling\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-25_2faf0c6d2653f02671462843cf410b9a'}\n\n```{.r .cell-code}\n# Creating the no pooling model\n# This is basically an ANCOVA lm(Reaction ~ Days + Subject)\n\ndf_no_pooling <- lmList(Reaction ~ Days | Subject, data=df_sleep) %>% \n  coef() %>%\n  rownames_to_column(\"Subject\") %>%\n  rename(Intercept = `(Intercept)`, Slope_Days = Days) %>% \n  add_column(Model = \"No Pooling\") %>% \n  filter(Subject != \"373\")\n# ?lmList # Creates a linear model for each one.\n```\n:::\n\n\n\n\n### Pooled\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-26_805dd0edd375e5cc18687ba2b0923f5d'}\n\n```{.r .cell-code}\n# Creating pooled model\nm_pooled <- lm(Reaction ~ Days, df_sleep)\ndf_pooled <- tibble(\n  Model = \"Complete pooling\",\n  Subject = unique(df_sleep$Subject),\n  Intercept = coef(m_pooled)[1], \n  Slope_Days = coef(m_pooled)[2])\n```\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-27_a19f66141989ccd5e54f9d6b01552a58'}\n\n```{.r .cell-code}\n# combine the two models\ndf_models <- bind_rows(df_pooled, df_no_pooling) %>%\n  left_join(df_sleep, by = \"Subject\")\ndf_models\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 365 × 6\n   Model            Subject Intercept Slope_Days Reaction  Days\n   <chr>            <chr>       <dbl>      <dbl>    <dbl> <dbl>\n 1 Complete pooling 308          252.       10.3     250.     0\n 2 Complete pooling 308          252.       10.3     259.     1\n 3 Complete pooling 308          252.       10.3     251.     2\n 4 Complete pooling 308          252.       10.3     321.     3\n 5 Complete pooling 308          252.       10.3     357.     4\n 6 Complete pooling 308          252.       10.3     415.     5\n 7 Complete pooling 308          252.       10.3     382.     6\n 8 Complete pooling 308          252.       10.3     290.     7\n 9 Complete pooling 308          252.       10.3     431.     8\n10 Complete pooling 308          252.       10.3     466.     9\n# … with 355 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n\n\n### Partial Pooling\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-28_243ce08c57183b23797a0f215a16ef3c'}\n\n```{.r .cell-code}\nlmm <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject), df_sleep)\n\n# Make a dataframe with the fitted effects\ndf_partial_pooling <- coef(lmm)[[\"Subject\"]] %>% \n  rownames_to_column(\"Subject\") %>% \n  as_tibble() %>% \n  rename(Intercept = `(Intercept)`, Slope_Days = Days) %>% \n  add_column(Model = \"Partial pooling\")\n\ndf_models <- bind_rows(df_pooled, df_no_pooling, df_partial_pooling) %>% \n  left_join(df_sleep, by = \"Subject\")\n```\n:::\n\n\n\n### Plot comparing all versions\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-29_0170f6e9a3281c188da6cf8dcf9a2201'}\n\n```{.r .cell-code}\n# Create initial base plot without partial pooling lines\np_model_comparison <- ggplot(df_models) + \n  aes(x = Days, y = Reaction) + \n  # Set the color mapping in this layer so the points don't get a color\n  geom_abline(aes(intercept = Intercept, slope = Slope_Days, color = Model),\n              size = .75) +\n  geom_point() + \n  facet_wrap(~Subject) +\n  scale_x_continuous(breaks = 0:4 * 2) + \n  labs(x = \"Days of Sleep Deprivation\", y = \"Average Reaction Time\") +\n  scale_color_brewer(palette = \"Dark2\") + \n  theme(legend.position = \"top\")\n# p_model_comparison # to view without partial pooling\n\np_model_comparison\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-29-1.png){width=672}\n:::\n:::\n\n\n### Linear Model Version Estimates\n\nThe fixed version of this is the same as the no pooling case. The plot completely overlaps with the no pooling\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-30_1e622455f9f10f3a3f6f20838f8259cc'}\n\n```{.r .cell-code}\nm <- lm(formula = Reaction ~ Days*Subject, data = df_sleep)\ncoef(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    (Intercept)            Days      Subject309      Subject310      Subject330 \n    244.1926691      21.7647024     -39.1377236     -40.7084436      45.4924236 \n     Subject331      Subject332      Subject333      Subject334      Subject335 \n     41.5462964      20.0589455      30.8264364      -4.0297545      18.8420236 \n     Subject337      Subject349      Subject350      Subject351      Subject352 \n     45.9114582     -29.0808964     -18.3580655      16.9543418      32.1794000 \n     Subject369      Subject370      Subject371      Subject372      Subject373 \n     10.7754800     -33.7435782       9.4433691      22.8521309       0.8073309 \n     Subject374 Days:Subject309 Days:Subject310 Days:Subject330 Days:Subject331 \n     41.8073309     -19.5029170     -15.6498036     -18.7566297     -16.4986836 \nDays:Subject332 Days:Subject333 Days:Subject334 Days:Subject335 Days:Subject337 \n    -12.1979345     -12.6226570      -9.5115612     -24.6457364      -2.7387285 \nDays:Subject349 Days:Subject350 Days:Subject351 Days:Subject352 Days:Subject369 \n     -8.2707697      -2.2606855     -15.3312048      -8.1981533     -10.4165933 \nDays:Subject370 Days:Subject371 Days:Subject372 Days:Subject373 Days:Subject374 \n     -3.7085515     -12.5762576     -10.4666291              NA     -19.7647024 \n```\n:::\n\n```{.r .cell-code}\n# In this information, there is really a line for each subject, need to create that matrix\n\nmcoef <- tibble(Subject = \"308\", Intercept = coef(m)[1], Slope_Days = coef(m)[2])\nmcoef <- rbind(mcoef, \n               tibble(\n                 Subject = substr(names(coef(m)[3:21]), 8,10),\n                 Intercept = coef(m)[3:21] + coef(m)[1],\n                 Slope_Days = coef(m)[22:40] + coef(m)[2]))\nmcoef$Model <- \"Linear Model\"\ndf_ancova <- mcoef\n\ndf_models <- bind_rows(df_pooled, df_no_pooling, df_partial_pooling, df_ancova) %>% \n  left_join(df_sleep, by = \"Subject\")\n\n# Oh it's the same as no pooling\ndf_models %>% filter((Model == \"Linear Model\" | Model == \"No Pooling\") & Subject == \"370\" & Days == 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  Model        Subject Intercept Slope_Days Reaction  Days\n  <chr>        <chr>       <dbl>      <dbl>    <dbl> <dbl>\n1 No Pooling   370          210.       18.1     225.     0\n2 Linear Model 370          210.       18.1     225.     0\n```\n:::\n:::\n\n\nEffectively, this is the same as filtering the data and running a linear regression on each subset. That is what is meant by \"no pooling\"\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-31_97fd7ad043c073e0628dc95b0713c76c'}\n\n```{.r .cell-code}\nmf <- lm(Reaction ~ Days, subset(df_sleep, Subject == \"308\"))\ncoef(mf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        Days \n   244.1927     21.7647 \n```\n:::\n\n```{.r .cell-code}\ncoef(m)[1:2]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        Days \n   244.1927     21.7647 \n```\n:::\n\n```{.r .cell-code}\nfixef(lmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        Days \n  252.54256    10.45212 \n```\n:::\n\n```{.r .cell-code}\ncoef(lmm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$Subject\n    (Intercept)       Days\n308    253.9478 19.6264337\n309    211.7331  1.7319161\n310    213.1582  4.9061511\n330    275.1425  5.6436007\n331    273.7286  7.3862730\n332    260.6504 10.1632571\n333    268.3683 10.2246059\n334    244.5524 11.4837802\n335    251.3702 -0.3355788\n337    286.2319 19.1090424\n349    226.7663 11.5531844\n350    238.7807 17.0156827\n351    256.2344  7.4119456\n352    272.3511 13.9920878\n369    254.9484 11.2985770\n370    226.3701 15.2027877\n371    252.5051  9.4335409\n372    263.8916 11.7253429\n373    248.9753 10.3915288\n374    271.1450 11.0782516\n\nattr(,\"class\")\n[1] \"coef.mer\"\n```\n:::\n:::\n\n\nThe standard errors is where it matters... let's look at that... say I'm interested in saying something about the subject 308. How would I go about that? The answer is that it's difficult without making some egregarious assumptions.\n\nhttps://stackoverflow.com/questions/26198958/extracting-coefficients-and-their-standard-error-from-lme\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-32_78cf8bcb3fc7995def6d01377f49fb82'}\n\n```{.r .cell-code}\n# filtered model for patient 308\ncoef(summary(mf))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Estimate Std. Error  t value     Pr(>|t|)\n(Intercept) 244.1927   28.08269 8.695486 2.385022e-05\nDays         21.7647    5.26037 4.137485 3.264657e-03\n```\n:::\n\n```{.r .cell-code}\n# Coef of blocked model\ncoef(summary(m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                   Estimate Std. Error     t value     Pr(>|t|)\n(Intercept)     244.1926691  15.041687 16.23439348 2.419368e-34\nDays             21.7647024   2.817566  7.72464642 1.741840e-12\nSubject309      -39.1377236  21.272158 -1.83985675 6.784831e-02\nSubject310      -40.7084436  21.272158 -1.91369599 5.764319e-02\nSubject330       45.4924236  21.272158  2.13858996 3.415609e-02\nSubject331       41.5462964  21.272158  1.95308328 5.274863e-02\nSubject332       20.0589455  21.272158  0.94296711 3.472771e-01\nSubject333       30.8264364  21.272158  1.44914476 1.494714e-01\nSubject334       -4.0297545  21.272158 -0.18943797 8.500163e-01\nSubject335       18.8420236  21.272158  0.88575985 3.772237e-01\nSubject337       45.9114582  21.272158  2.15828869 3.256308e-02\nSubject349      -29.0808964  21.272158 -1.36708726 1.737283e-01\nSubject350      -18.3580655  21.272158 -0.86300907 3.895675e-01\nSubject351       16.9543418  21.272158  0.79702030 4.267514e-01\nSubject352       32.1794000  21.272158  1.51274731 1.325355e-01\nSubject369       10.7754800  21.272158  0.50655321 6.132431e-01\nSubject370      -33.7435782  21.272158 -1.58627902 1.148695e-01\nSubject371        9.4433691  21.272158  0.44393094 6.577589e-01\nSubject372       22.8521309  21.272158  1.07427421 2.844966e-01\nSubject373        0.8073309  29.684902  0.02719668 9.783405e-01\nSubject374       41.8073309  29.684902  1.40837020 1.611769e-01\nDays:Subject309 -19.5029170   3.984640 -4.89452386 2.609126e-06\nDays:Subject310 -15.6498036   3.984640 -3.92753235 1.326622e-04\nDays:Subject330 -18.7566297   3.984640 -4.70723286 5.841112e-06\nDays:Subject331 -16.4986836   3.984640 -4.14057040 5.875009e-05\nDays:Subject332 -12.1979345   3.984640 -3.06123857 2.630447e-03\nDays:Subject333 -12.6226570   3.984640 -3.16782847 1.875589e-03\nDays:Subject334  -9.5115612   3.984640 -2.38705643 1.828240e-02\nDays:Subject335 -24.6457364   3.984640 -6.18518475 6.072281e-09\nDays:Subject337  -2.7387285   3.984640 -0.68732139 4.929857e-01\nDays:Subject349  -8.2707697   3.984640 -2.07566282 3.970366e-02\nDays:Subject350  -2.2606855   3.984640 -0.56734995 5.713599e-01\nDays:Subject351 -15.3312048   3.984640 -3.84757562 1.786891e-04\nDays:Subject352  -8.1981533   3.984640 -2.05743875 4.144801e-02\nDays:Subject369 -10.4165933   3.984640 -2.61418662 9.894962e-03\nDays:Subject370  -3.7085515   3.984640 -0.93071174 3.535604e-01\nDays:Subject371 -12.5762576   3.984640 -3.15618391 1.946990e-03\nDays:Subject372 -10.4666291   3.984640 -2.62674378 9.553514e-03\nDays:Subject374 -19.7647024  36.301801 -0.54445515 5.869704e-01\n```\n:::\n\n```{.r .cell-code}\n# CAUTION: Ignoring Covariances, and directly adding the variances for Conditional Variance and fixed eff variance\nsqrt(diag(vcov(lmm)) + diag(attr(ranef(lmm)$Subject, \"postVar\")[,,1]))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Intercept)        Days \n  13.575606    2.758914 \n```\n:::\n:::\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-33_3cf9ee0e431c3c292fb62746997beb72'}\n\n```{.r .cell-code}\ndf_fixef <- tibble(\n  Model = \"Partial pooling (average)\",\n  Intercept = fixef(lmm)[1],\n  Slope_Days = fixef(lmm)[2])\n\n# Complete pooling / fixed effects are center of gravity in the plot\ndf_gravity <- df_pooled %>% \n  distinct(Model, Intercept, Slope_Days) %>% \n  bind_rows(df_fixef)\ndf_gravity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  Model                     Intercept Slope_Days\n  <chr>                         <dbl>      <dbl>\n1 Complete pooling               252.       10.3\n2 Partial pooling (average)      253.       10.5\n```\n:::\n\n```{.r .cell-code}\ndf_pulled <-  bind_rows(df_no_pooling, df_partial_pooling)\nhead(df_pulled)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Subject Intercept Slope_Days      Model\n1     308  244.1927  21.764702 No Pooling\n2     309  205.0549   2.261785 No Pooling\n3     310  203.4842   6.114899 No Pooling\n4     330  289.6851   3.008073 No Pooling\n5     331  285.7390   5.266019 No Pooling\n6     332  264.2516   9.566768 No Pooling\n```\n:::\n\n```{.r .cell-code}\nggplot(df_pulled, aes(Intercept, Slope_Days, color=Model)) + \n  geom_point() +\n  geom_point(data=df_gravity, size=4) +\n  geom_path(aes(group=Subject), arrow=arrow(length=unit(.02, \"npc\"))) +\n  geom_text(aes(label=Subject), data=df_no_pooling, nudge_y = .8)\n```\n\n::: {.cell-output-display}\n![](mixed_files/figure-html/unnamed-chunk-33-1.png){width=672}\n:::\n:::\n\n\n\n\n## Getting Subject level standard errors\n\nComplicated Issue, according to [Ben Bolker](https://stackoverflow.com/questions/26198958/extracting-coefficients-and-their-standard-error-from-lme)\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-34_68318441b50b70f0c4e81a3b6180a0d5'}\n\n```{.r .cell-code}\nfixed_vars <- diag(vcov(mod))\nattributes(ranef(mod, condVar=TRUE, drop=TRUE)$Subject)\n\nattributes(ranef(mod)$Subject)\nattr(ranef(mod)$Subject, \"postVar\")\ncmode_vars <- t(apply(attr(ranef(mod)$Subject, \"postVar\"), 3, diag)) # columns of intercept variance and day variance\n\nsqrt(sweep(cmode_vars, 2, fixed_vars, \"+\")) # Standard errors  (basically add fixed_vars to respective columns)\n```\n:::\n\n\n## Emmeans with Mixed Models (oats)\n\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-35_50402e7ad738b4a5b28e4ead57546bbc'}\n\n```{.r .cell-code}\noats_emm <- emmeans(oats_mod, c(\"Variety\", \"nitro\"), lmer.df = \"satterthwaite\") # Also affects the SE slightly\noats_emm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n Variety     nitro emmean   SE    df lower.CL upper.CL\n Golden Rain   0.0   80.6 8.18 10.54     62.5     98.7\n Marvellous    0.0   83.8 8.15 10.40     65.8    101.9\n Victory       0.0   72.3 8.34 11.26     54.0     90.6\n Golden Rain   0.2   98.7 8.02  9.76     80.8    116.6\n Marvellous    0.2  102.0 8.08 10.07     84.0    119.9\n Victory       0.2   90.4 8.17 10.39     72.3    108.5\n Golden Rain   0.4  115.9 8.09 10.14     97.9    133.9\n Marvellous    0.4  119.1 8.00  9.69    101.2    137.0\n Victory       0.4  107.6 8.17 10.39     89.5    125.7\n Golden Rain   0.6  125.8 8.09 10.07    107.8    143.8\n Marvellous    0.6  129.0 7.99  9.61    111.1    146.9\n Victory       0.6  117.5 8.03  9.79     99.5    135.4\n\nDegrees-of-freedom method: satterthwaite \nConfidence level used: 0.95 \n```\n:::\n:::\n\n\n### Manual calculation of emmeans and SE\n\nEmmeans simply takes advantage of the fact that the marginal means are the linear combinations of the coefficients. Thus, if the model coefficient standard deviations are incorrect, then the estimated marginal means standard errrors are incorrect.\n\nTo replicate the standard errors within emmeans, you must use REML estimates of standards errors. \n\n\nReminder: modesl by default in R use the factor encoding, so to get (0.0 nitro, marvellous), we know the (0.0 nitro, Victory) is the intercept, and the coefficeint for variety marvellous is the effect, so (0.0 nitro, Marevellous) = (Intercept) + VarietyMarvellous.\n\nOverall, we can create the reference grid manually and calculate the marginal means from the grid\n\n::: {.cell hash='mixed_cache/html/unnamed-chunk-36_1bcc1ee1af1261a84d30c6da269bf4e9'}\n\n```{.r .cell-code}\n# calculate reference grid manually\noats_grid <- with(oats_miss, expand.grid(Variety = levels(Variety),\n                                         nitro = levels(factor(nitro))))\noats_X <- model.matrix(~Variety + nitro, data = oats_grid) # the combinations\noats_B <- fixef(oats_mod)\noats_V <- vcov(oats_mod)\n\n# Calculate my version\noats_my_emm <- list(emmean = c(oats_X %*% oats_B), # marginal means are just X\\betahat\n                    SE = sqrt(diag(oats_X %*% oats_V %*% t(oats_X)))) # cov(X\\beta) = Xcov(\\betahat)X'\n\n# Calculate the package version\noats_package_emm <- oats_emm %>% as_tibble() %>% dplyr::select(emmean, SE) %>% as.list()\n\n\n# Show that emmean estimates are the same\ncbind(oats_my_emm$emmean, oats_package_emm$emmean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           [,1]      [,2]\n [1,]  80.58462  80.58462\n [2,]  83.81332  83.81332\n [3,]  72.27827  72.27827\n [4,]  98.72680  98.72680\n [5,] 101.95550 101.95550\n [6,]  90.42045  90.42045\n [7,] 115.89071 115.89071\n [8,] 119.11941 119.11941\n [9,] 107.58436 107.58436\n[10,] 125.76112 125.76112\n[11,] 128.98982 128.98982\n[12,] 117.45477 117.45477\n```\n:::\n\n```{.r .cell-code}\n# Show that SE calculations are the same (note, they're only the same when you use Satter)\ncbind(oats_my_emm$SE, oats_package_emm$SE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1]     [,2]\n1  8.180084 8.180084\n2  8.145113 8.145113\n3  8.342494 8.342494\n4  8.015913 8.015913\n5  8.078163 8.078163\n6  8.171648 8.171648\n7  8.093027 8.093027\n8  8.001749 8.001749\n9  8.171293 8.171293\n10 8.087191 8.087191\n11 7.985790 7.985790\n12 8.030997 8.030997\n```\n:::\n:::\n\n\nNote:\n\n* SE are the same when you calculate them with `REML = TRUE` and `lmer.df = \"satterthwaite\"`.\n\nIn order to average these down (by Variety) we then just get the appropriate linear combinations and calculate them with the appropriate variance-covariance.\n\n# Additional Resources\n\n# FAQ\n\n* Why aren't there p-values in lme4?\n  - Great question. it's due to the denominator degrees of freedom. really\n  - Bates response is at `?pvalues`\n  \n* What's the difference between nlme and lme4\n\n  - [gn]lmer now produces objects of class merMod rather than class mer as before\n  - the new version uses a combination of S3 and reference classes (see ReferenceClasses, merPredD-class, and lmResp-class) as well as S4 classes; partly for this reason it is more interoperable with nlme\n  - The internal structure of [gn]lmer is now more modular, allowing finer control of the different steps of argument checking; construction of design matrices and data structures; parameter estimation; and construction of the final merMod object (see modular)\n  - profiling and parametric bootstrapping are new in the current version\n  - the new version of lme4 does not provide an mcmcsamp (post-hoc MCMC sampling) method, because this was deemed to be unreliable. Alternatives for computing p-values include parametric bootstrapping (bootMer) or methods implemented in the pbkrtest package and leveraged by the lmerTest package and the Anova function in the car package (see pvalues for more details).\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}