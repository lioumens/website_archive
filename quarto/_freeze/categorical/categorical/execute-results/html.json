{
  "hash": "d63df2015e278f6e3e315beb2862ed48",
  "result": {
    "markdown": "---\ntitle: \"Categorical Data Analysis\"\nauthor: \"Michael Liou\"\ndate: \"2023-03-18\"\nexecute:\n  cache: true\neditor: \n  markdown: \n    wrap: sentence\n---\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-1_3cb4b59915b3cae135dea5deb27063d6'}\n\n```{.r .cell-code  code-summary=\"Libraries\"}\nlibrary(tidyverse)\nlibrary(AMR)\nlibrary(DescTools)\nlibrary(kableExtra)\nlibrary(VGAM)\nlibrary(nnet)\nlibrary(vcd) # visualizing categorical data\nlibrary(vcdExtra) # additional companion code\nlibrary(reshape2)\nlibrary(coin)\nlibrary(rlang)\n\nlibrary(glmtoolbox)\nlibrary(glmulti) # model averaging and model selection\nlibrary(rms) # regression modeling strategies, residuals implements gof tests\nlibrary(ResourceSelection)\n\n# devtools::install_github(\"https://github.com/cran/LogisticDx\")\nlibrary(LogisticDx)\n```\n:::\n\n\n## Overview\n\nThis is a very broad area, but I feel like it's also super confusing because it's all very confouded in terms of all the chisq tests that are scattered throughout the place.\nI'm trying to organize everything for myself here.\n\n-   CMH test\n-   score test for table\n-   Pearson\n-   Yates (continuity correction of Pearson)\n-   Barnard test (based on fixing 1 margin)\n-   fisher exact (based on fixing all margins)\n-   McNemar Test\n-   Generalized CMH test\n\n## 2x2 sampling mechanisms\n\nThe many different sampling mechanisms arise from different study designs, and are critical to the assumptions of the population you are studying.\n\nIn an epidemiological context, the data is given as\n\n|             | disease | no disease |     |\n|-------------|:--------|:-----------|-----|\n| exposure    | a       | b          | n1  |\n| no exposure | c       | d          | n0  |\n|             | m1      | m0         | N   |\n\n-   Poisson (nothing fixed)\n-   Multinomial (N) total is fixed\n    -   \"Cross Sectional\" studies\n-   Two-sample Binomial (1 margin fixed)\n    -   \"Cohort Study\" = n1, n0 fixed\n    -   \"Case Control Study\" = m1, m0 fixed\n        -   a type of \"retrospective\" study.\n-   Hypergeometric (2 margins fixed)\n    -   very rarely the case in real experiments, but unfortunately many methods are based on this assumption for the 2x2 table.\n\n::: panel-tabset\n### Poisson\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-2_6464c5598f4e82a9ab99298c49d5fc23'}\n\n```{.r .fold-hide .cell-code}\n# Independent Poisson\n\n#' When specifying the mean, they can be specified cellwise, or by table, grouped by the nrow*ncol, in order of the columns\n#'\n#' @param mean means of the cells. If 1 number, all cells will have same \n#'\n#' @return\n#' @export\n#'\n#' @examples\nrpoisson_table <- function(num_tables = 1, mean = 5, nrow = 2,  ncol = 2) {\n  cells <- rpois(ncol * nrow * num_tables, lambda = mean)\n  vec_table <- split(cells, gl(num_tables, ncol*nrow))\n  vapply(vec_table, matrix, nrow = nrow, ncol = ncol, byrow = FALSE, FUN.VALUE = matrix(1:(ncol*nrow), nrow = nrow))\n}\n\n# 2x2 examples\npoisson_table_examples <- rpoisson_table(5, mean = 5, nrow = 2, ncol = 2)\napply(poisson_table_examples,\n      MARGIN = 3,\n      FUN = addmargins,\n      simplify = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$`1`\n         Sum\n     8 1   9\n     7 5  12\nSum 15 6  21\n\n$`2`\n         Sum\n    4  6  10\n    2  9  11\nSum 6 15  21\n\n$`3`\n         Sum\n    4  7  11\n    2  4   6\nSum 6 11  17\n\n$`4`\n         Sum\n    2  7   9\n    5  4   9\nSum 7 11  18\n\n$`5`\n        Sum\n    4 4   8\n    0 3   3\nSum 4 7  11\n```\n:::\n:::\n\n\n### Multinomial\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-3_1d938f58de3f5601081bc4322e49906b'}\n\n```{.r .cell-code}\n# grand total fixed\nrmultinom_table <- function(num_tables = 1, N = 20, nrow = 2, ncol = 2, p = c(1, 1, 1, 1)) {\n  stopifnot(length(p) == nrow * ncol)\n  # p is internally standardized by rmultinom\n  cells <- rmultinom(num_tables, N, p)\n  dim(cells) <- c(nrow, ncol, num_tables)\n  cells\n}\n```\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-4_c3e403f007d80a03ecaa00f44ead5472'}\n\n```{.r .cell-code}\n# examples\nmultinom_table_examples <- rmultinom_table(5, N = 20, nrow = 2, ncol = 2, p = c(1, 1, 1, 1))\napply(multinom_table_examples,\n      MARGIN = 3,\n      FUN = addmargins,\n      simplify = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n         Sum\n     4 7  11\n     7 2   9\nSum 11 9  20\n\n[[2]]\n         Sum\n    5  8  13\n    3  4   7\nSum 8 12  20\n\n[[3]]\n         Sum\n    1  7   8\n    8  4  12\nSum 9 11  20\n\n[[4]]\n         Sum\n    7  6  13\n    2  5   7\nSum 9 11  20\n\n[[5]]\n         Sum\n    4  5   9\n    4  7  11\nSum 8 12  20\n```\n:::\n:::\n\n\n### Binomial\n\nWhen not in the 2x2 case, this can also be called an independent multinomial.\nThis is still a case in which one of the margins is fixed.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-5_e570d4e772e2886765a5f14ed36bf53f'}\n\n```{.r .cell-code}\n# Sample a 2x2 table\nrbinom_table <- function(num_tables = 1, row_n = c(10, 10), p = c(.5, .5)) {\n  vapply(1:num_tables, \n       FUN = function(x) {\n         a <- rbinom(length(row_n), row_n, p) # fix margins\n         binom_table <- cbind(a, b = row_n-a) # make other column by subtraction and combine\n         colnames(binom_table) <- NULL\n         binom_table}, \n       FUN.VALUE = matrix(rep(1.1, 4), nrow =2)) # expected 2x2 table\n}\n\nbinom_table_examples <- rbinom_table(5, row_n = c(10, 10), p = c(.5, .5))\napply(binom_table_examples,\n      MARGIN = 3,\n      FUN = addmargins,\n      simplify = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n         Sum\n     7 3  10\n     6 4  10\nSum 13 7  20\n\n[[2]]\n          Sum\n     5  5  10\n     5  5  10\nSum 10 10  20\n\n[[3]]\n         Sum\n     4 6  10\n     7 3  10\nSum 11 9  20\n\n[[4]]\n          Sum\n     5  5  10\n     5  5  10\nSum 10 10  20\n\n[[5]]\n         Sum\n     4 6  10\n     7 3  10\nSum 11 9  20\n```\n:::\n:::\n\n\n### Hypergeometric\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-6_e9a54325aef3b98ec998ef3298ecc665'}\n\n```{.r .cell-code}\n# Fixed margins\n# one hypergeometrical deviate will determine the entire table.\n# only doing 2x2 tables with sampling method\n\nrhyper_table <- function(num_tables, row_n = c(10, 10), col_n = c(10, 10))  {\n  a <- rhyper(num_tables, row_n[1], row_n[2], col_n[1])\n  vapply(a, \n       FUN = function(x) {\n         col1 <- c(x, col_n[1] - x)\n         col2 <- row_n - col1\n         contingency_table <- cbind(col1, col2)\n         colnames(contingency_table) <- NULL # get rid of column names\n         contingency_table\n       },\n       FUN.VALUE = matrix(c(0, 0, 0, 1.1), nrow = 2))}\n\n# examples\nhyper_table_examples <- rhyper_table(num_tables = 5, row_n = c(10, 10), col_n = c(10, 10))\napply(hyper_table_examples,\n      MARGIN = 3,\n      FUN = addmargins,\n      simplify = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[1]]\n          Sum\n     4  6  10\n     6  4  10\nSum 10 10  20\n\n[[2]]\n          Sum\n     4  6  10\n     6  4  10\nSum 10 10  20\n\n[[3]]\n          Sum\n     3  7  10\n     7  3  10\nSum 10 10  20\n\n[[4]]\n          Sum\n     5  5  10\n     5  5  10\nSum 10 10  20\n\n[[5]]\n          Sum\n     5  5  10\n     5  5  10\nSum 10 10  20\n```\n:::\n:::\n\n:::\n\n## Chi Squared Distribution\n\n\nFor testing, the lower the degree of freedom, the more power we have, so 1-df tests are generally good and powerful, but quite specific in the alternative that's tested.\n\n\n::: {.cell layout=\"[[50, 50]]\" hash='categorical_cache/html/unnamed-chunk-7_ce2ec69e11ef129344624c6434675fa1'}\n\n```{.r .cell-code}\nx <- seq(0, 8, .05)\nc1 <- dchisq(x, 1)\nc2 <- dchisq(x, 2)\nc3 <- dchisq(x, 3)\nc5 <- dchisq(x, 5)\nc7 <- dchisq(x, 7)\nc8 <- dchisq(x, 8)\n\nggplot(mapping = aes(x = x)) +\n  geom_line(mapping = aes(y = c1, color = \"df = 1\")) + \n  geom_line(aes(y = c2, color = \"df = 2\")) +\n  geom_line(aes(y = c3, color = \"df = 3\")) +\n  geom_line(aes(y = c5, color = \"df = 5\")) +\n  geom_line(aes(y = c7, color = \"df = 7\")) +\n  geom_line(aes(y = c8, color = \"df = 8\")) +\n  coord_cartesian(ylim = c(0, .5)) +\n  labs(y = \"density\",\n       color = \"df\",\n       title = \"Density\") +\n  theme_test()\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# chisq 3, increasing ncf\nncp <- c(0, 1, 2, 3, 5, 8)\ntibble(x = list(x), ncp = ncp) |> rowwise() |> \n  mutate(density = list(dchisq(x, df = 3, ncp))) |> \n  unnest(c(x, density)) |> \n  ggplot(aes(x=x, y = density, color = factor(ncp))) +\n  geom_line() +\n  labs(color = \"Noncentrality Parameter\",\n       title = \"chisq(df=3) with varying ncp\") +\n  theme_test()\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-8_1384faddda1eaea78eeb94cad3f7f095'}\n\n```{.r .cell-code}\nncp <- seq(0, 20, .1)\nqplot(ncp, pchisq(3,ncp,lower.tail = FALSE), geom = \"line\", color = \"df = 3\") +\n  geom_line(aes(x = ncp , y = pchisq(7, ncp, lower.tail = FALSE), color = \"df = 7\")) +\n  labs(y = \"Power\",\n       x = \"Noncentrality\",\n       title = \"Power and Noncentrality\") +\n  theme_test()\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nFor the same noncentrality parameter, the distribution with lower df will have more power. We can compensate for different degrees of freedom with different noncentrality patterns. That is, a lower degree of freedom test will have more power as long as the noncentrality is the same. If the \"model is not true\" (the ncp is larger) we could still potentially have higher power. The motivation for this figure comes from the Cochran Trend Test.\n\n## Measures of Association\n\nGiven tables, it's important to distinguish the properties of how to make comparisons, and summarize the information given.\nWhen dealing with percentages and ratios, it's sometimes difficult to have an intuitive understanding of meaning on the percentage scale.\nThe example Professor Guanhua Chen gives to stimulate you for this thinking is from [cartalk](https://www.cartalk.com/radio/puzzler/porch-potatoes):\n\n> RAY: Potatoes are 99 percent water and one percent what?\n> Potato.\n> So say you take a bunch of potatoes, like 100 pounds of potatoes and you set them out on your back porch to dry out.\n> TOM: Yeah, when they are dry they should weigh about a pound.\n> RAY: Well, we're not drying out completely.\n> And as the potatoes dry out the water begins to evaporate.\n> And after a while, enough water has evaporated so that they are now 98 percent water.\n> If you were to weigh those potatoes at that moment... TOM: They'd be lighter.\n> RAY: Yes, how much lighter?\n> That's the question.\n> Now you can solve this puzzler algebraically, and if you don't solve it algebraically, you are going to get the wrong answer.\n> TOM: Really?\n> RAY: Really.What's your answer, off the top of your head?\n> TOM: 99 pounds.\n> RAY: You are wrong.\n> Answer: RAY: Now, unencumbered by the thought process as usual, my brother guessed 99 pounds.\n> TOM: Yeah.\n> RAY: Now, when I guessed, off the top of my head, I guessed about 90 pounds.\n> TOM: 'Cause it just feels right.\n> RAY: But if you do the math, 1 percent of 100 --which is what the potato is-- is one pound.\n> As we told you, that's 1 percent.\n> So 2 percent, when it's 98 percent water, two percent of the new weight of the mass is still going to be equal to that one pound, and 2 percent of 50 pounds is a pound.\n> So the potato weight is now 50 pounds, not 100.\n\n-   Risk Ratio: $p1 / p2$\n    -   not symmetric\n-   Odds Ratio ($[p1/(1 -p1)] / [p2 / (1 - p2)]$)\n    -   symmetric, exposure gives information about disease and vice versa, meaning this is useful for\n    - when the condition is RARE, odds ratio is similar to risk ratio and may permit interpretation as risk ratio. Should definitely be below p < .1\n-   Risk Difference ($p1 - p2$)\n\n## Goodness of Fit\n\nThe following three tests are provided by this R file, from [Analysis of Categorical Data in R](http://www.chrisbilder.com/categorical/programs_and_data.html).\n\nLow p-values tend to indicate lack of fit.\n\nWe'll use the \"Placekicking\" Dataset from the textbook, as well as borrowing some of the code from placekicking.R for the analysis.\n\nFor all of the goodness of fits, we should work on the \"aggregated data\". The textbooks refer to this as the exploratory variable pattern (EVP). The reason for this is so the approximation is closer to correct.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-9_ed0406bad7e0d0463fde266b915956a8'}\n\n```{.r .cell-code}\nsource(\"AllGOFTests.R\")\nplacekick <- read.csv(\"Placekick.csv\")\n```\n:::\n\n::: {.cell layout=\"[[50, 50], [50, 50]]\" hash='categorical_cache/html/unnamed-chunk-10_16143de8dd13d27a6fce830451095c73'}\n\n```{.r .cell-code}\nplacekick_search_aicc <- glmulti(y = good ~ .,\n                                 data = placekick,\n                                 fitfunction = \"glm\",\n                                 level = 1, \n                                 method = \"h\", # h|g|l|d, exhuastive|genetic(large)|branchbound(fast)|summary\n                                 crit = \"aicc\", # aic|bic|aicc|qaic|qaicc\n                                 family = binomial(link = \"logit\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nInitialization...\nTASK: Exhaustive screening of candidate set.\nFitting...\n\nAfter 50 models:\nBest model: good~1+week+distance+change+PAT\nCrit= 767.299644897567\nMean crit= 861.376317807727\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAfter 100 models:\nBest model: good~1+week+distance+change+PAT\nCrit= 767.299644897567\nMean crit= 849.706367688597\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAfter 150 models:\nBest model: good~1+week+distance+change+PAT\nCrit= 767.299644897567\nMean crit= 793.693748713112\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAfter 200 models:\nBest model: good~1+distance+change+PAT+wind\nCrit= 766.728784139471\nMean crit= 777.754038353278\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-10-4.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAfter 250 models:\nBest model: good~1+distance+change+PAT+wind\nCrit= 766.728784139471\nMean crit= 774.167191225549\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-10-5.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCompleted.\n```\n:::\n\n```{.r .cell-code}\nweightable(placekick_search_aicc) |> head()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                             model     aicc    weights\n1        good ~ 1 + distance + change + PAT + wind 766.7288 0.06695515\n2 good ~ 1 + week + distance + change + PAT + wind 767.1329 0.05470419\n3        good ~ 1 + week + distance + change + PAT 767.2996 0.05032956\n4               good ~ 1 + distance + change + PAT 767.3607 0.04881733\n5                 good ~ 1 + distance + PAT + wind 767.6899 0.04140743\n6 good ~ 1 + distance + change + PAT + type + wind 768.1182 0.03342523\n```\n:::\n:::\n\n\nWe can look at the top models for model selection here, and find that df\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-11_2e1d7af95af80c0babe16e06737c02a0'}\n\n```{.r .cell-code}\nplacekick_bin_data <- placekick |> group_by(distance) |> dplyr::summarize(y = sum(good),n = n(), p = y/n)\nplacekick_bin_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 43 × 4\n   distance     y     n     p\n      <int> <int> <int> <dbl>\n 1       18     2     3 0.667\n 2       19     7     7 1    \n 3       20   776   789 0.984\n 4       21    19    20 0.95 \n 5       22    12    14 0.857\n 6       23    26    27 0.963\n 7       24     7     7 1    \n 8       25    12    13 0.923\n 9       26     8     9 0.889\n10       27    24    29 0.828\n# … with 33 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n\n```{.r .cell-code}\n# unweighted logistic function by distance\nplacekick_l <- glm(good ~ distance, data = placekick, family = binomial())\nsummary(placekick_l)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = good ~ distance, family = binomial(), data = placekick)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7441   0.2425   0.2425   0.3801   1.6092  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  5.812080   0.326277   17.81   <2e-16 ***\ndistance    -0.115027   0.008339  -13.79   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1013.43  on 1424  degrees of freedom\nResidual deviance:  775.75  on 1423  degrees of freedom\nAIC: 779.75\n\nNumber of Fisher Scoring iterations: 6\n```\n:::\n\n```{.r .cell-code}\n# weighted logistic function by distance\nplacekick_wl <- glm(y/n ~ distance, weights = n, family = binomial, data = placekick_bin_data)\nsummary(placekick_wl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = y/n ~ distance, family = binomial, data = placekick_bin_data, \n    weights = n)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.0373  -0.6449  -0.1424   0.5004   2.2758  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  5.812080   0.326277   17.81   <2e-16 ***\ndistance    -0.115027   0.008339  -13.79   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 282.181  on 42  degrees of freedom\nResidual deviance:  44.499  on 41  degrees of freedom\nAIC: 148.46\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\n\n\n\n### Hosmer Lemeshow\n\nWhy is Hosmer Lemeshow different than just taking the pearson residuals, summing and testing on the error residual degrees of freedom?\n\nThe motivation for grouping the fitted values into groups, is so that the chisq approximation is \"more correct\". The approximation/large sample deviation is only true when there are a _fixed_ number of categories, and if we were to sample more values for x, we don't get any new values. That is, assuming that every single residual in the sum has a standard normal error is not quite correct.\n\nOne downside of HL test, is that the cuts are done by predicted values. It's possible we have very different covariate values that have similar predicted values, but they're grouped together.\n\nThere are many ways to do a HLtest, but we'll walk through them individually. Ultimately I recommend Desctools, or the one created by Prof. Bilder.\n\n::: {.panel-tabset}\n\n#### Manually\n\n\n\n\n\n\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-16_83285e56e58d5d2eb78375015a4a5e89'}\n\n```{.r .cell-code}\n#' Hosmer-Lemeshow Goodness of Fit Test\n#' \n#' This method implements a few varieties of the popular Hosmer-Lemeshow Goodness of Fit Test, in which the null hypothesis is that the model is a good fit. The most widely used and implemented is splitting into 10 groups dependent on the quantiles of the data, and then summing pearson statistics across each of the groups. Here is a list of the different methods to calculate the Hosmer-Lemeshow (and related) statistics.\n#' \n#' 1. \"deciles_unweighted\"\n#' 2. \"deciles_weighted\"\n#' 3. \"fixed\"\n#' 4. \"fixed_minmax\"\n#' \n#' \n#' @param mod (glm-object) weighted, binomial glm model\n#' @param g (integer) number of groups\n#' @param fixed (logical) whether the categories used should be equally spaced between the min and max of predicted values\n#' @param adjust (logical) use Pigeon and Heyse correction to denominator of HL Statistic\n#' @param breaks (numeric) manual specification of the category groupings. Will include 0 and 1 as min/max.\n#' @param deciles (logical) calculate the statistic with the deciles of risk\n#'\n#' @return Hypothesis test for Goodness of Fit of Logistic Regression\n#' @export\n#'\n#' @examples\ngof_hl <- function(mod, g = 10, fixed = FALSE, adjust = FALSE, breaks = NULL) {\n  # model object checking\n  if (!inherits(mod, \"glm\") | # glm\n      mod$family$family != \"binomial\" | # binomial glm\n      !(\"(weights)\" %in% names(mod$model))) # weighted regression\n  {\n    rlang::abort(message = \"Hosmer Lemeshow Test only implemented for weighted, binomial, glm objects.\")\n  }\n    \n  y_hat <- fitted(mod)\n  \n  if (!missing(breaks)) { # manually specified groups\n    breaks <- unique(sort(c(0, breaks, 1)))\n      \n      if (max(breaks) > 1 | min(breaks) < 0) {\n        rlang::abort(message = \"breaks should be between 0, 1\")\n      }\n    method <- \"Hosmer-Lemeshow GOF Test\"\n    \n  } else if (fixed) { # equally separated groups\n    breaks <- seq(min(y_hat), max(y_hat), length.out = g + 1)\n    method <- \"Hosmer-Lemeshow GOF fixed H Test\"\n\n  } else {\n   breaks <- quantile(y_hat, 0:g/g)\n   method <- \"Hosmer-Lemeshow GOF C Test\"\n  }\n  \n  y_cut <- cut(y_hat, unique(breaks), include.lowest = TRUE)\n  \n  Mj <- mod$prior.weights\n  y0 <- mod$y * Mj\n  y1 <- Mj - y0\n  y0_exp <- y_hat * Mj\n  y1_exp <- Mj - y0_exp\n  \n  # aggregate table\n  cut_df <- tibble(y_cut, y0, y0_exp, y1, y1_exp, Mj) |> \n    group_by(y_cut) |> \n    dplyr::summarise(Y0 = sum(y0),\n                     Y0_exp = sum(y0_exp),\n                     Y1 = sum(y1),\n                     Y1_exp = sum(y1_exp),\n                     Ni = sum(Mj),\n                     pbar = weighted.mean(y1_exp/Mj, Mj),\n                     pbar_var = sum(Mj * y1_exp / Mj * (1 - y1_exp/Mj)))\n                     \n  if (adjust) {\n    # Pigeon Heyse adjustment\n    statistic_col <- with(cut_df, \n         (Y1 - Ni * pbar)^2 / pbar_var)\n    hl_table <- cut_df |>\n      add_column(adj_pearson = statistic_col)\n    \n    method <- paste(method, \" (Pigeon-Heyse Adjusted)\")\n  } else {\n    # pearson statistic, unadjusted\n    statistic_col <- with(cut_df,\n                        (Y0 - Y0_exp)^2 / Y0_exp + (Y1 - Y1_exp)^2 / Y1_exp)\n    hl_table <- cut_df |> add_column(pearson = statistic_col)  \n  }\n  \n  \n  nc <- length(breaks) - 1 # expected number of categories\n  if (nrow(cut_df) < nc) {\n      rlang::inform(message = glue::glue(\"Empty categories detected, setting g = {num_cat}. \\n\", num_cat = nrow(cut_df)), use_cli_format = TRUE)\n  }\n  # expected count warning\n  if (any(hl_table$Y0_exp < 5 | hl_table$Y1_exp < 5)) {\n    # cat(hl_table$Y0_exp, Y1_exp)\n    rlang::inform(message = \"Groups with expected count < 5 detected, chi-squared approximation may not be valid. Consider decreasing number of groups `g`. \\n\", use_cli_format = TRUE)\n  }\n  \n  # (adjusted) pearson statistic\n  statistic <- sum(statistic_col)\n  names(statistic) <- \"X-squared\"\n  df <- nrow(cut_df) - 2\n  p.value <- pchisq(statistic, df, lower.tail = FALSE)\n  \n  structure(list(statistic = statistic,\n                 parameter = c(df = df),\n                 p.value = p.value,\n                 data.name = mod$call$data,\n                 method = method,\n                 alternative = \"Population is not a good fit for the assumed model.\",\n                 table = hl_table |> dplyr::select(-pbar_var)),\n            class = \"htest\")\n}\n\n# placekick_wl_hl0 <- gof_hl(placekick_wl, breaks = c(.48, .5, .7))\n# placekick_wl_hl0 <- gof_hl(placekick_wl, breaks = c(.1, .3, .6, .8))\n# placekick_wl_hl0 <- gof_hl(placekick_wl, fixed = TRUE, g = 5)\n# placekick_wl_hl0 <- gof_hl(placekick_wl, fixed = TRUE)\n# placekick_wl_hl0 <- gof_hl(placekick_wl, g = 50)\n\nplacekick_wl_hl0 <- gof_hl(placekick_wl, fixed = FALSE, adjust = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nGroups with expected count < 5 detected, chi-squared approximation may not be\nvalid. Consider decreasing number of groups `g`.\n```\n:::\n\n```{.r .cell-code}\nplacekick_wl_hl0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tHosmer-Lemeshow GOF C Test\n\ndata:  placekick_bin_data\nX-squared = 11.028, df = 8, p-value = 0.2001\nalternative hypothesis: Population is not a good fit for the assumed model.\n```\n:::\n\n```{.r .cell-code}\nplacekick_wl_hl0$table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 8\n   y_cut            Y0 Y0_exp    Y1 Y1_exp    Ni   pbar pearson\n   <fct>         <dbl>  <dbl> <dbl>  <dbl> <int>  <dbl>   <dbl>\n 1 [0.144,0.353]     2   1.17     3   3.83     5 0.766   0.770 \n 2 (0.353,0.469]    13  13.7     19  18.3     32 0.570   0.0714\n 3 (0.469,0.589]    39  33.9     25  30.1     64 0.470   1.62  \n 4 (0.589,0.699]    49  46.6     24  26.4     73 0.362   0.347 \n 5 (0.699,0.79]     74  79.4     32  26.6    106 0.251   1.45  \n 6 (0.79,0.859]     75  77.1     18  15.9     93 0.171   0.334 \n 7 (0.859,0.908]    69  71.8     12   9.17    81 0.113   0.983 \n 8 (0.908,0.941]    72  76.1     10   5.87    82 0.0716  3.12  \n 9 (0.941,0.963]    53  53.4      3   2.57    56 0.0459  0.0759\n10 (0.963,0.977]   816 809.      17  24.3    833 0.0291  2.25  \n```\n:::\n:::\n\n\nThese results match the implementation in Bilder's HLTest, \n\n#### `vcdExtra::HLtest`\n\nThis is the version in `vcdExtra`, but I think it's incorrect for the aggregated model. The totals are not correct, and I don't think the code accounts for the prior weights.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-17_22b9023ee47cb577fd746a579d34a68d'}\n\n```{.r .cell-code}\nplacekick_wl_hl <- vcdExtra::HLtest(placekick_wl)\nplacekick_wl_hl$table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             cut total       obs       exp         chi\n1  [0.144,0.353]     5 3.0000000 3.8307555 -0.42445439\n2  (0.353,0.469]     4 2.2503053 2.3372021 -0.05684024\n3  (0.469,0.589]     4 1.5181287 1.8823620 -0.26547777\n4  (0.589,0.699]     4 1.2722567 1.4393681 -0.13929004\n5   (0.699,0.79]     5 1.5438799 1.2586321  0.25425704\n6   (0.79,0.859]     4 0.7446261 0.6674089  0.09451877\n7  (0.859,0.908]     4 0.5297562 0.4492600  0.12009552\n8  (0.908,0.941]     4 0.4650036 0.2960067  0.31061890\n9  (0.941,0.963]     4 0.2250712 0.1921646  0.07506648\n10 (0.963,0.977]     5 0.5426670 0.1466858  1.03390508\n```\n:::\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-18_300cc3d7acf8bc0f24d2b78c494fb212'}\n\n```{.r .cell-code}\ntry(placekick_wl_hl <- vcdExtra::HLtest(placekick_l))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nError in cut.default(yhat, breaks = quantile(yhat, probs = seq(0, 1, 1/g)),  : \n  'breaks' are not unique\n```\n:::\n:::\n\n\nWell, unfortunately the unaggregated version errors out because of the cut command is not unique. In this case, I think it would have worked for other datasets, but the deciles of risk overlap in this case.\n\nOverall do not recommend this function, although there is fairly convenient table output.\n\n#### HLTest\n\nI think this is the best one available I've found. This is the function provided by Dr. Bilder:\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-19_45092b546cb1c852fa5c44ff9e0d7d78'}\n\n```{.r .cell-code}\nplacekick_wl_hl2 <- HLTest(placekick_wl, g = 10)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in HLTest(placekick_wl, g = 10): Some expected counts are less than 5.\nUse smaller number of groups\n```\n:::\n\n```{.r .cell-code}\nprint(placekick_wl_hl2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tHosmer and Lemeshow goodness-of-fit test with 10 bins\n\ndata:  placekick_wl\nX2 = 11.028, df = 8, p-value = 0.2001\n```\n:::\n\n```{.r .cell-code}\ncbind(placekick_wl_hl2$observed, round(placekick_wl_hl2$expect, digits = 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Y0  Y1 Y0hat Y1hat\n[0.144,0.353]  3   2   3.8   1.2\n(0.353,0.469] 19  13  18.3  13.7\n(0.469,0.589] 25  39  30.1  33.9\n(0.589,0.699] 24  49  26.4  46.6\n(0.699,0.79]  32  74  26.6  79.4\n(0.79,0.859]  18  75  15.9  77.1\n(0.859,0.908] 12  69   9.2  71.8\n(0.908,0.941] 10  72   5.9  76.1\n(0.941,0.963]  3  53   2.6  53.4\n(0.963,0.977] 17 816  24.3 808.7\n```\n:::\n:::\n\n\nThis table is useful because it breaks down the statistic into the 10 groups used for the cuts. We should look at the table for large deviations. Although I would still like a function in which I can specify the cuts manually and evaluate the robustness of the HLtest.\n\n#### `glmtoolbox::hltest`\n\nThis function seems like it's doing as it should, but has an automatic way of calculating the number of groups without a way of modifying the number of groups used. Though it does look like the statistic is being calculated correctly from the code.\n\nI don't like this version becaues the group cuts are not displayed, and so diagnosing where the model fits and doesn't fit is not very useful. It's also an automatic selection, which makes it hard to test sensitivity.\n\nThe results of this test are also dramatically different than the HLTest. We would conclude that the logistic regression is not a good fit from this test, but from the other cuts, with 10 groups, we would conclude it's an okay fit.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-20_5f677a87916371cd9150b3cd9deb08e2'}\n\n```{.r .cell-code}\nplacekick_wl_hl3 <- glmtoolbox::hltest(placekick_wl) # different, but I think it's because of the different cuts\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n   The Hosmer-Lemeshow goodness-of-fit test\n\n Group Size Observed   Expected\n     1  138       79  71.412836\n     2  142       98 103.379735\n     3  133      111 112.160333\n     4  145      125 133.730775\n     5   68       64  65.436785\n     6  789      776 766.130460\n     7   10        9   9.749077\n\n         Statistic =  17.62778 \ndegrees of freedom =  5 \n           p-value =  0.003451 \n```\n:::\n\n```{.r .cell-code}\nplacekick_wl_hl3$hm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Group Size Observed   Expected\n1     1  138       79  71.412836\n2     2  142       98 103.379735\n3     3  133      111 112.160333\n4     4  145      125 133.730775\n5     5   68       64  65.436785\n6     6  789      776 766.130460\n7     7   10        9   9.749077\n```\n:::\n:::\n\n\n\n#### `ResourceSelection::hoslem.test`\n\nDoes not implement the weighted glm version. This version fixes the problem in `vcdExtra` in which for the raw model, we need to use \"unique\" quantiles, otherwise the `cut` function will not work with repeated values. Hence if you request `g = 10` 10 groups, you may only end up with 6 groups. This is fine, but now the df in the test is incorrect, and doesn't adjust for the fact that `g` is lower now, and instead uses the df as you requested.\n\nThe conclusion from this test would be similar to the version by Dr. Bilder, and also gives the table of cuts, but also not recommended.\n\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-21_e95729370412fed92737b7c700424a30'}\n\n```{.r .cell-code}\n# aggregated (incorrect results)\nplacekick_wl_hl4 <- ResourceSelection::hoslem.test(placekick_bin_data$p, fitted(placekick_wl))\ncbind(placekick_wl_hl4$observed, placekick_wl_hl4$expected)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     y0       y1     yhat0    yhat1\n[0.144,0.353] 3.0000000 2.000000 3.8307555 1.169244\n(0.353,0.469] 2.2503053 1.749695 2.3372021 1.662798\n(0.469,0.589] 1.5181287 2.481871 1.8823620 2.117638\n(0.589,0.699] 1.2722567 2.727743 1.4393681 2.560632\n(0.699,0.79]  1.5438799 3.456120 1.2586321 3.741368\n(0.79,0.859]  0.7446261 3.255374 0.6674089 3.332591\n(0.859,0.908] 0.5297562 3.470244 0.4492600 3.550740\n(0.908,0.941] 0.4650036 3.534996 0.2960067 3.703993\n(0.941,0.963] 0.2250712 3.774929 0.1921646 3.807835\n(0.963,0.977] 0.5426670 4.457333 0.1466858 4.853314\n```\n:::\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-22_52128b7cd3c9c35ec67760400bb714c8'}\n\n```{.r .cell-code}\n# not aggregated (still incorrect)\nplacekick_wl_hl4 <- ResourceSelection::hoslem.test(placekick$good, fitted(placekick_l), g = 10)\nprint(placekick_wl_hl4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tHosmer and Lemeshow goodness of fit (GOF) test\n\ndata:  placekick$good, fitted(placekick_l)\nX-squared = 10.943, df = 8, p-value = 0.2049\n```\n:::\n\n```{.r .cell-code}\ncbind(placekick_wl_hl4$observed, placekick_wl_hl4$expected)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              y0  y1      yhat0      yhat1\n[0.144,0.654] 66  90 72.8183761  83.181624\n(0.654,0.809] 42 110 37.7476996 114.252300\n(0.809,0.894] 24 111 18.6639785 116.336021\n(0.894,0.96]  14 135  9.4944324 139.505568\n(0.96,0.971]  16 807 24.0245900 798.975410\n(0.971,0.977]  1   9  0.2509234   9.749077\n```\n:::\n:::\n\n\n#### `LogisticDx::gof`\n\nThis package was taken off of CRAN, but has many of the binomial diagnostics implemented. There certainly are a lot of tests, but most are automatic unfortunatly. it would be helpful to review the source code for this package to understand the statistics [gof.R](https://github.com/cran/LogisticDx/blob/master/R/gof.R)\n\nI see the same problem here with the number of groups in which we're using the df from the groups requested rather than the actual number of groups formed. I also kind of have a problem in which most of the tests are somewhat meaningless in the binomial context, but there's no discrimination for what is reported since they're calculated for all glm. ie, i'm not sure I trust a lot of these statistics.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-23_7edf9c0011d81145b22a978add935a26'}\n\n```{.r .cell-code}\n# LogisticDx::gof(placekick_wl) \nplacekick_wl_hl5 <- LogisticDx::gof(placekick_l) # note this is on the unweighted version of the binomial\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 0, case = 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting direction: controls < cases\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplacekick_wl_hl5$chiSq # many \"chisq\" statistics. for logisitc regression, these are rarely chisq\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   test      chiSq   df       pVal\n1:  PrI 1285.23292 1423 0.99607219\n2:  drI  775.74504 1423 1.00000000\n3:  PrG   56.11361   41 0.05810763\n4:  drG   44.49945   41 0.32665475\n5: PrCT   56.11361   41 0.05810763\n6: drCT   44.49945   41 0.32665475\n```\n:::\n\n```{.r .cell-code}\nplacekick_wl_hl5$ct # contingency table by fitted values\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      n       y1hat  y1       y0hat y0\n 1:  14  11.9903588  12  2.00964122  2\n 2:  11   9.9475955  10  1.05240450  1\n 3:  28  22.1251760  22  5.87482397  6\n 4:  27  25.9079221  26  1.09207789  1\n 5:  23  13.8019963  14  9.19800367  9\n 6:  28  22.6413539  23  5.35864608  5\n 7:  19   9.7884586  10  9.21154141  9\n 8:  27  19.6370642  20  7.36293580  7\n 9:  17  15.6818888  16  1.31811123  1\n10:  18  10.2994561  10  7.70054394  8\n11:  22  18.5179520  18  3.48204796  4\n12:  19  16.5304611  16  2.46953892  3\n13:  22  20.4666378  20  1.53336219  2\n14:   7   6.8185767   7  0.18142327  0\n15:  20  19.3519119  19  0.64808806  1\n16:  13  12.3450262  12  0.65497381  1\n17:  10   7.4950738   7  2.50492615  3\n18:   7   6.6839126   7  0.31608744  0\n19:  18  12.2287724  13  5.77122761  5\n20:  18  11.7687880  11  6.23121197  7\n21:   9   8.4943857   8  0.50561429  1\n22:  14  12.7935732  12  1.20642684  2\n23:  21  18.5322377  20  2.46776230  1\n24:  29  23.9479698  22  5.05203021  7\n25:  19  14.6390859  13  4.36091406  6\n26:   1   0.1443427   0  0.85565732  1\n27:  13   5.9510644   5  7.04893556  8\n28:   1   0.1923830   0  0.80761700  1\n29:   1   0.2108893   0  0.78911067  1\n30:  12   6.5259669   8  5.47403313  4\n31:   9   3.8645259   5  5.13547415  4\n32: 789 766.1304600 776 22.86954002 13\n33:  14  13.4930381  12  0.50696191  2\n34:  14   8.7828623  11  5.21713771  3\n35:  30  26.8170421  23  3.18295790  7\n36:  29  27.1846258  24  1.81537422  5\n37:  22  15.4857741  12  6.51422592 10\n38:   3   1.1224974   2  1.87750262  1\n39:   3   2.9304999   2  0.06950011  1\n40:   7   2.8102631   1  4.18973691  6\n41:   1   0.3476436   1  0.65235639  0\n42:  15   7.2965005  11  7.70349952  4\n43:   1   0.2739858   1  0.72601417  0\n      n       y1hat  y1       y0hat y0\n```\n:::\n\n```{.r .cell-code}\nplacekick_wl_hl5$ctHL\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       P  y1     y1hat y0     y0hat   n      Pbar\n1: 0.627  79  71.41284 59 66.587164 138 0.5174843\n2:  0.79  98 103.37973 44 38.620265 142 0.7280263\n3: 0.882 111 112.16033 22 20.839667 133 0.8433108\n4: 0.955 132 140.41469 20 11.585312 152 0.9237808\n5: 0.968  57  58.75287  4  2.247128  61 0.9631618\n6: 0.977 785 775.87954 14 23.120463 799 0.9710632\n```\n:::\n:::\n\n\n\n\nThe `dx` function in this package is incredibly useful though, see the help file for all the residual help we get.\n\n#### `DescTools::HosmerLemeshowTest`\n\nThe two gof tests implemented here are `C` statistic, which is the 10 deciles or risk, and `H` are fixed cutpoints (equally separated by number of groups between min and max). The notation comes from 1997 paper by hosmer and lemeshow.\n\nThere is also another test based on smooth residuals based on the X space, smoothed residuals that is only calculated when the covariate space is specified.\n\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-25_27163b1bcded26e5978e79521239541c'}\n\n```{.r .cell-code}\n# DescTools::HosmerLemeshowTest(fit = fitted(placekick_wl), obs = placekick_bin_data$p, X = cbind(placekick_bin_data$distance), verbose = TRUE) # incorrect, doesn't count weights\nplacekick_wl_hl6 <- DescTools::HosmerLemeshowTest(fit = fitted(placekick_l),\n                                                  obs = placekick$good,\n                                                  X = cbind(placekick$distance),\n                                                  verbose = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in DescTools::HosmerLemeshowTest(fit = fitted(placekick_l), obs =\nplacekick$good, : Found only 6 different groups for Hosmer-Lemesho C statistic.\n```\n:::\n\n```{.r .cell-code}\nprint(placekick_wl_hl6)\ncbind(placekick_wl_hl6$C$observed, placekick_wl_hl6$C$expected)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nGroups for Hosmer-Lemeshow C statistic:\ncutfit\n[0.144,0.654] (0.654,0.809] (0.809,0.894]  (0.894,0.96]  (0.96,0.971] \n          156           152           135           149           823 \n(0.971,0.977] \n           10 \nGroups for Hosmer-Lemeshow H statistic:\ncutfit1\n[0.144,0.228] (0.228,0.311] (0.311,0.394] (0.394,0.477] (0.477,0.561] \n            3             1             4            29            46 \n(0.561,0.644] (0.644,0.727]  (0.727,0.81]  (0.81,0.894] (0.894,0.978] \n           55            58           112           105          1012 \n$C\n\n\tHosmer-Lemeshow C statistic\n\ndata:  fitted(placekick_l) and placekick$good\nX-squared = 10.943, df = 4, p-value = 0.02721\n\n\n$H\n\n\tHosmer-Lemeshow H statistic\n\ndata:  fitted(placekick_l) and placekick$good\nX-squared = 10.362, df = 8, p-value = 0.2405\n\n\n$gof\n\n\tle Cessie-van Houwelingen-Copas-Hosmer global goodness of fit test\n\ndata:  fitted(placekick_l) and placekick$good\nz = 0.51185, p-value = 0.6088\n\n              0s  1s         Os         1s\n[0.144,0.654] 66  90 72.8183761  83.181624\n(0.654,0.809] 42 110 37.7476996 114.252300\n(0.809,0.894] 24 111 18.6639785 116.336021\n(0.894,0.96]  14 135  9.4944324 139.505568\n(0.96,0.971]  16 807 24.0245900 798.975410\n(0.971,0.977]  1   9  0.2509234   9.749077\n```\n:::\n:::\n\nI like this function, as it seems to print out mose of the important aspects of the test I want. This function _does_ adjust for the fact that only 6 unique cuts were formed, and does testing on the righ\n\n\n\n\n\n\n::: \n\n\n\noverall I recommend the one by dr. bilder, or the manual one you've made.\n\n\n### Osius-Rojek\n\n::: {.panel-tabset}\n\n#### Manually\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-27_ab24a0d35396603e066e5609d8f2f6b3'}\n\n```{.r .cell-code}\n#' Osius and Rojek\n#' \n#' Implements the goodness of fit tests examined by osius and rojek\n#'\n#' @param mod weighted, binomial, glm\n#' @param ss standardize the sum of squares instead of pearson statistic\n#'\n#' @return htest\n#' @export\n#'\n#' @examples\ngof_or <- function(mod, ss = FALSE) {\n  # type checking for weighted binomial glm\n  if (!inherits(mod, \"glm\") | # glm\n      mod$family$family != \"binomial\" | # binomial glm\n      !(\"(weights)\" %in% names(mod$model))) # weighted regression\n  {\n    rlang::abort(message = \"Osius Rojek Test only implemented for weighted, binomial, glm objects.\")\n  }\n  \n  y <- mod$y\n  J <- length(y)\n  p <- mod$rank - 1 # num independent parameters?\n  phat <- fitted(mod)\n  mj <- mod$prior.weights\n  vj <- mj * phat * (1 - phat)\n  cj <- (1 - 2 * phat) / vj\n  A <- 2 * (J - sum(1/mj))\n  X2 <- sum((mj*y - mj*phat)^2 / vj) # pearson statistic\n  S <- sum((mj*y - mj * phat)^2)\n  if (ss) {\n    dj <- (1 - 2 * phat)\n    new_form <- update(mod$formula, dj~.)\n    environment(new_form) <- environment()\n    wlm <- lm(new_form, data = cbind(mod$data, dj), weights = vj)\n    RSS <- sum(vj * residuals(wlm)^2)\n    zstat <- (S - sum(vj)) / sqrt(A + RSS)\n    method <- \"Osius Rojek Goodness of Fit Test, Normalized Sum. Sq\"\n  } else {\n    new_form <- update(mod$formula, cj~.)\n    environment(new_form) <- environment() # need to update formula environment because model was created outside function\n    wlm <- lm(new_form, data = cbind(mod$data, cj), weights = vj)\n    RSS <- sum(vj * residuals(wlm)^2)\n    zstat <- sum(X2 - (J - p - 1)) / (sqrt(A + RSS)) # not sure what the mean of the pearson chisq should be, could check against\n    method <- \"Osius Rojek Goodness of Fit Test, Normalized Pearson\"\n  }\n  names(zstat) <- \"z\"\n  p.value <- pnorm(abs(zstat), lower.tail = FALSE) * 2 # two sided\n  structure(list(p.value = p.value,\n                 statistic = zstat,\n                 method = method,\n                 data.name = mod$call$data,\n                 alternative = \"Model is not a good fit.\"),\n            class = \"htest\")\n}\n\nplacekick_wl_or0 <- gof_or(placekick_wl, ss = FALSE)\nplacekick_wl_or0\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOsius Rojek Goodness of Fit Test, Normalized Pearson\n\ndata:  placekick_bin_data\nz = 1.466, p-value = 0.1426\nalternative hypothesis: Model is not a good fit.\n```\n:::\n:::\n\n\nThere's a little bit of controversy as to what the approriate mean for the pearson statistic is, i've seen n - p - 1 and n - p. I should look back in the original paper and look at the asymptotic results, or do some more simlations as to the better mean under various situations.\n\n\n\n\n\n\n#### `sjstats::chisq_gof`\n\n\nI don't think this version is implementing the RSS correctly, it should be with weights, so I've submitted a bug report. It looks like the implementation is the nearly the same as mine though.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-29_5bea0137b58806d75d051a25e45ed122'}\n\n```{.r .cell-code}\nplacekick_wl_or <- sjstats::chisq_gof(placekick_wl)\nplacekick_wl_or\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n# Chi-squared Goodness-of-Fit Test\n\n  Chi-squared: 56.114\n      z-score:  0.804\n      p-value:  0.421\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSummary: model seems to fit well.\n```\n:::\n:::\n\n\n\n\n\n#### `o.r.test`\n\nunfortunately gives different value than the oj test above\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-31_2df2ea91911fe7527850bee48c85be6d'}\n\n```{.r .cell-code}\n# seems that it just prints the value and no test object\nplacekick_wl_or2 <- o.r.test(placekick_wl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nz =  1.563042 with p-value =  0.1180426 \n```\n:::\n:::\n\n\n#### `LogisticDx:gof`\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-32_9b78376b3136f47872dad876ab6e1d8b'}\n\n```{.r .cell-code}\nplacekick_wl_or3 <- gof(placekick_l)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 0, case = 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting direction: controls < cases\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplacekick_wl_or3$gof\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         test  stat         val df       pVal\n1:         HL chiSq 14.51724214  8 0.06924066\n2:        mHL     F  1.32331386  5 0.27569976\n3:       OsRo     Z  1.46604106 NA 0.14263710\n4: SstPgeq0.5     Z  2.35457205 NA 0.01854405\n5:   SstPl0.5     Z  0.15861448 NA 0.87397262\n6:    SstBoth chiSq  5.56916807  2 0.06175477\n7: SllPgeq0.5 chiSq  5.40780780  1 0.02004688\n8:   SllPl0.5 chiSq  0.02650009  1 0.87068497\n9:    SllBoth chiSq  6.97716365  2 0.03054416\n```\n:::\n:::\n\n\nThis statistic matches my implementation\n\n#### `or.test`\n\nFound on [Rstat Help Mailing List](https://stat.ethz.ch/pipermail/r-help/2002-January/017858.html)\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-33_9fcdf830e8049b236574ede1dc439456'}\n\n```{.r .cell-code}\nor.test <- function(object) {\n  ### ancillary function\n  ## ags adapted from agg.sum provided by Bill Dunlap\t\n  ags <- function(x, by){\n    by <- data.frame(by)\n    ord <- do.call(\"order\", unname(by))\n    x <- x[ord]\n    by <- by[ord,  ]\n    logical.diff <- function(group) group[-1] != group[ - length(group)]\n    change <- logical.diff(by[[1]])\n    for(i in seq(along = by)[-1])\n      change <- change | logical.diff(by[[i]])\n    by <- by[c(T, change),  , drop = F]\n    by$x <- diff(c(0, cumsum(x)[c(change, T)]))\n    by\n  }\n  ###\n  ### computations\n  ###\n  mf <- model.frame(object)\n  ## collapse the original data by covariate pattern\n  xx <- ags(rep(1, nrow(mf)), mf[-1])\n  ## observed number of cases by covariate pattern\n  yy <- unname(unlist(ags(mf[ , 1], mf[-1])[ncol(xx)]))\n  ## fitted proba\n  pp <- predict(object, newdata = xx, type = \"response\")\n  ## number of rows with the same covariate pattern\n  mm <- unname(unlist(xx[ncol(xx)]))\n  ## new model frame\n  xx <- xx[ , - ncol(xx)]\n  ## weights\n  nu <- mm * pp * (1 - pp)\n  ## new response\n  cc <- (1 - 2 * pp) / nu\n  ### Pearson's X2\n  X2 <- sum( (yy - mm * pp)^2 / nu)\n  ### weighted regression\n  mod <- lm(cc ~ . , weights = nu, data = xx)\n  rss <- sum( nu * resid(mod)^2 )\n  ### compute the stat.\n  J <- nrow(xx)\n  A <- 2 * (J - sum( 1 / mm))\n  z <- abs( (X2 - (J - length( coef(object) ) ) ) / sqrt(A + rss) )\n  ### report results\n  print(object$call)\n  cat(\"Osius & Rojek's goodness-of-fit test for logistic models.\\n\")\n  cat(\"Null hypothesis: model fits the data well.\\n\")\n  cat(\"z =\", round(z, 3), \"; P =\", round(2 * (1 - pnorm(z)), 3), \"\\n\")\n}\n\nor.test(placekick_wl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nglm(formula = y/n ~ distance, family = binomial, data = placekick_bin_data, \n    weights = n)\nOsius & Rojek's goodness-of-fit test for logistic models.\nNull hypothesis: model fits the data well.\nz = 3.639 ; P = 0 \n```\n:::\n:::\n\n\nI don't really get the right version, and I think he was asking for help in the R help channel. It makes sense that these values don't match, there must be an error somewhere.\n\n\n:::\n\n### Stukel\n\nthe stukel test checks a better fit with more parameters in the tails of the logistic regression. The implementation is taken from hosmer's book.\n\nThere are two \"created variables\" $z1, z2$, which are defined as coefficients for the upper and lower tail respectivly. Ie. do we need more information for those parts of the model, it could indicate that a logistic model is not the perfect fit.\n\n::: {.panel-tabset}\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-34_a356064e0c7e67ace185bdd063d46dea'}\n\n```{.r .cell-code}\n# https://stackoverflow.com/questions/13690184/update-inside-a-function-only-searches-the-global-environment\n# some issues in updating formulas, as update and add1 are meant for interactive use probably, and updating the model in the same context the model was created.\n# this function solves a slightly different issue, in that it evaluates the model based on where the formula was defined, but I want to change the environment that the formula was defined in. \n# I can see how this would be troublesome if the variables I'm defining are the same as the user is using, that might lead to bugs.\nmy_update <- function(mod, formula = NULL, data = NULL) {\n  call <- getCall(mod)\n  if (is.null(call)) {\n    stop(\"Model object does not support updating (no call)\", call. = FALSE)\n  }\n  term <- terms(mod)\n  if (is.null(term)) {\n    stop(\"Model object does not support updating (no terms)\", call. = FALSE)\n  }\n\n  if (!is.null(data)) call$data <- data\n  if (!is.null(formula)) call$formula <- update.formula(call$formula, formula)\n  env <- attr(term, \".Environment\")\n\n  eval(call, env, parent.frame())\n}\n\ngof_stukel <- function(mod, test = c(\"Rao\", \"LRT\")) {\n  # type checking for weighted binomial glm\n  if (!inherits(mod, \"glm\") | # glm\n      mod$family$family != \"binomial\" | # binomial glm\n      !(\"(weights)\" %in% names(mod$model))) # weighted regression\n  {\n    rlang::abort(message = \"Stukel Test only implemented for weighted, binomial, glm objects.\")\n  }\n  test <- match.arg(test)\n  phat <- fitted(mod)\n  ghat <- predict(mod, type = \"link\")\n  z1 <- .5 * ghat^2 * (phat >= .5) # upper tail variable\n  z2 <- .5 * ghat^2 * (phat < .5) # lower tail variable\n  new_form <- update(mod$formula, .~.+z1 + z2)\n  environment(new_form) <- environment() # set environment of formula\n  newmod_call <- mod$call\n  newmod_call$formula <- new_form # update the formula _inside_ the call\n  newmod <- eval(newmod_call)\n  anova_both <- anova(mod, newmod, test = test) # test both tails together\n  method <- \"Stukel Goodness of Fit Test, both tails\"\n  alternative <- \"Model is not a good fit.\"\n  switch(test,\n         Rao = {\n           method <- paste(method, \" (Score test)\")\n           statistic <- anova_both$Rao[2]\n         },\n         LRT = {\n           method <- paste(method, \" (LRT test)\")\n           statistic <- anova_both$Deviance[2]\n         }\n         )\n  names(statistic) <- \"X-squared\"\n  p.value <- anova_both$`Pr`[2]\n  \n  structure(list(method = method,\n                 alternative = alternative,\n                 statistic = statistic,\n                 p.value = p.value,\n                 data.name = mod$call$data),\n                 # uppertail = add1(mod, .~.+z1, test = test),  # provide anova tables for separate tails\n                 # lowertail = add1(mod, .~.+z2, test = test)), # provide anova tables for separate tails\n            class = \"htest\")\n}\n\nplacekick_wl_st0 <- gof_stukel(placekick_wl, test = \"Rao\")\nplacekick_wl_st0\nplacekick_wl_st0$uppertail\nplacekick_wl_st0$lowertail\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tStukel Goodness of Fit Test, both tails (Score test)\n\ndata:  placekick_bin_data\nX-squared = 6.9964, p-value = 0.03025\nalternative hypothesis: Model is not a good fit.\n\nNULL\nNULL\n```\n:::\n:::\n\n\nHere we're showing the results of testing gof for both tails, and then the upper and lower separately\n\n\n\n\n\n####  stukel.test\n\nThis is Prof Bilder's version of the GOF test. He uses the LRT version for testing both tails at once.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-36_13b9d88bf91f7347df011b1c64667772'}\n\n```{.r .cell-code}\nstukel.test(placekick_l) # LRT of both z1 and z2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStukel Test Stat =  6.977164 with p-value =  0.03054416 \n```\n:::\n:::\n\n\n#### `LogisticDx::gof`\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-37_ef7481b64e0d09501ffc34590dc84b6a'}\n\n```{.r .cell-code}\ngof(placekick_l)$gof\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 0, case = 1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting direction: controls < cases\n```\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-37-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n         test  stat         val df       pVal\n1:         HL chiSq 14.51724214  8 0.06924066\n2:        mHL     F  1.32331386  5 0.27569976\n3:       OsRo     Z  1.46604106 NA 0.14263710\n4: SstPgeq0.5     Z  2.35457205 NA 0.01854405\n5:   SstPl0.5     Z  0.15861448 NA 0.87397262\n6:    SstBoth chiSq  5.56916807  2 0.06175477\n7: SllPgeq0.5 chiSq  5.40780780  1 0.02004688\n8:   SllPl0.5 chiSq  0.02650009  1 0.87068497\n9:    SllBoth chiSq  6.97716365  2 0.03054416\n```\n:::\n:::\n\n\nThe Stukel tests are provided those starting with S. `st` stands for the score test, and \"ll\" stands for likelihood. I get matching values for all except `sstBoth` (score test for both tails). I'm not sure what's going on there.\n\n\n:::\n\n## Residuals\n\nHosmer recommends 7 different logistic regression plots that all tell you slightly different things. \n\n## Pseudo R2\n\nHere we implement some Pseudo R2 values for\n\n\n## Testing\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-38_4903702cbc933e92ac9eb7975b91f4c3'}\n\n```{.r .cell-code}\ntribble(~test, ~parameter, ~sampling, ~pvalue, ~hypothesis,\n        \"pearson\", \"parameter\",\"two sample z proportion\", \"approximate\", \"association\",\n        \"cochran\", \"cell\", \"unconditional two sample\", \"approximate\", \"association\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  test    parameter sampling                 pvalue      hypothesis \n  <chr>   <chr>     <chr>                    <chr>       <chr>      \n1 pearson parameter two sample z proportion  approximate association\n2 cochran cell      unconditional two sample approximate association\n```\n:::\n:::\n\n\nWe should be careful to distinguish three types of testing that can happen, in relation to all the assumed sampling distributions that we assume for the table:\n\n1.  Independence\n2.  Homogeneity\n\n-   This is identical to a test for independence when we are fixing one of the columns.\n\n3.  Goodness of Fit\n\n-   The idea is that you provide the probability vector that you want to test. In this case, there is normally a model behind the predicted probabilities, and you're using the chisq statistic to tell you how well the model fits.\n\nA list of tests:\n\n-   Cochran summary test\n-   (Cochran)-Mantel-Haenszel summary test\n-   Generalized CMH Test\n-   Cochran's Q test\n-   Pearson Chi Squared\n-   Cochran-Armitrage Trend Test\n-   Cochran-Q Test\n-   Mann-Whitney U test (Wilcoxon Rank Sum)\n-   Wilcoson Signed Rank Test (paired samples)\n-   Krustkal Wallis\n\nExact tests\n\n-   Fisher Exact Test\n-   Barnard Exact Test\n\nDependent \"Matched pairs\" tests\n\n-   McNemar Test\n\n### Pearson\n\nGiven the following table,\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-39_03d41124caf4ba10521076dd5d3a5ded'}\n\n```{.r .cell-code}\ntribble(~\"\", ~\"Disease\", ~\"No Disease\", ~\"\",\n        \"Exposed\", \"a\", \"b\", \"\\\\$n_1\\\\$\",\n        \"Not Exposed\" , \"c\", \"d\", \"\\\\$n_2\\\\$\",\n        \"\", \"\\\\$m_1\\\\$\", \"\\\\$m_2\\\\$\", \"N\") %>% \n  kable(\"html\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:left;\"> Disease </th>\n   <th style=\"text-align:left;\"> No Disease </th>\n   <th style=\"text-align:left;\">  </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> Exposed </td>\n   <td style=\"text-align:left;\"> a </td>\n   <td style=\"text-align:left;\"> b </td>\n   <td style=\"text-align:left;\"> \\$n_1\\$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Not Exposed </td>\n   <td style=\"text-align:left;\"> c </td>\n   <td style=\"text-align:left;\"> d </td>\n   <td style=\"text-align:left;\"> \\$n_2\\$ </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\">  </td>\n   <td style=\"text-align:left;\"> \\$m_1\\$ </td>\n   <td style=\"text-align:left;\"> \\$m_2\\$ </td>\n   <td style=\"text-align:left;\"> N </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAssume two sample proportional sampling model: A derivation from 2 sample proportion (pooled) z-test:\n\n$$\n\\begin{aligned}\nz^2 &= \\frac{(\\hat p_1 - \\hat p_2)^2}{\\hat p(1 - \\hat p)(\\frac{1}{n_1} + \\frac{1}{n_2})} \n&=\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\nX^2 = \\sum_i^c \\frac{|O_i - E_i|^2}{E_i} \\sim \\chi^2_{c-1}\n\\end{aligned}\n$$\n\n\nWhen the pearson table is generalized to Ix2, we have a column proportions, so we have the Brandt-Snedecor formula of the pearson independence statistic: \n\n$$\n\\begin{aligned}\n\\chi^2(I) = \\sum\\frac{n_i (p_i - p)^2}{p(1-p)}\n\\end{aligned}\n$$\nwhere $\\chi^2(I)$ represents the independence chisq statistic, $n_i$ is the number in each group, $p_i$ is the proportion by row, and $p$ is the proportion by total row.\n\n\nResources: \n\n- [Pearson as Score Test](https://projecteuclid.org/download/pdf_1/euclid.lnms/1215091138)\n- [7 proofs of independence test](https://arxiv.org/pdf/1808.09171.pdf)\n\n\n### Likelihood Ratio Test (G Test)\n\n-   `AMR::g.test()`\n-   `DescTools::GTest()`\n-   `RVAideMemoire::G.test()`\n\nThese are the likelihood ratio test statistics, and the statistic can be calculated by the formula\n\n$$\n\\begin{aligned}\n2\\sum O \\log \\left(\\frac{O}{E}\\right)\n\\end{aligned}\n$$\n\n-   This is an alternative to pearson chisq tests, but are asymptotically equivalent.\n-   Consider using this when both variables are \"nominal\"\n\n### Barnard Exact Test\n\nBarnard is considered an \"unconditional\" approach to exact testing.\ncontrast to Fisher exact test which is a \"conditional\" approach to testing the p-value\n\nBarnard is effectively a 2 stage test, given some observed table X, a \"p-value\" is the probability of observing a table more extreme than the observed.\n\nThe two stages are thus:\n\n1.  determine which tables are more \"extreme\"\n2.  calculated probability of those tables\n\nThus, the \"exactness\" part of the description refers to how a probability is calculated.\n\nMany methods have been proposed for stage 1\n\n-   Suissa and Shuster (1985) use pooled and unpooled z statistic for two proportions.\n-   Booschloo (1970) used the p-value from fisher's exact test to determine extremeness...\n-   Santner Snell - difference in proportion\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-40_f8c99557c9daf9984c92ef7011f0bed3'}\n\n```{.r .cell-code}\nX <- matrix(c(3, 0, 0, 3), nrow = 2)\n# row is fixed\nBarnardTest(X, method = \"z-pooled\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tZ-pooled Exact Test\n\ndata:  3 out of 3 vs. 0 out of 3\ntest statistic = 2.4495, first sample size = 3, second sample size = 3,\np-value = 0.03125\nalternative hypothesis: true difference in proportion is not equal to 0\nsample estimates:\ndifference in proportion \n                       1 \n```\n:::\n\n```{.r .cell-code}\n# z-pooled observed is...\n1 / sqrt(.25 * (1/3 + 1/3)) # observed test statistic\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.44949\n```\n:::\n\n```{.r .cell-code}\n# how to calculate p-value from this test statistic, sum of binomial products from extreme tables,\n# the null is that pi_1 = pi_2 = pi, since we don't know the actual value of pi, we take the supremum of these values\n\ntrue_pi <- seq(0, 1, .01)\n\npossible_p <- dbinom(3, 3, prob = true_pi) * dbinom(0, 3, prob = true_pi) + dbinom(0, 3, prob = true_pi) * dbinom(3, 3, prob = true_pi)\n\n\n# maximum occurs at .5\ntrue_pi[which.max(possible_p)]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5\n```\n:::\n\n```{.r .cell-code}\n# thus, overall p-value is\nmax(possible_p) # .03125\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.03125\n```\n:::\n:::\n\n\nNow we compare the methods for choosing \"extremeness\" with the assumed sampling mechanism.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-41_1630d9d392afbcb1d7267a3d2d1ad43f'}\n\n```{.r .cell-code}\nset.seed(1)\nfoo <- rbinom_table(1000, row_n = c(10, 10), p = c(.5, .5)) # null is no association\n\n# z pooled (score)\nbarnard_pooled <- apply(foo, MARGIN = 3,\n                        FUN = function (x) {BarnardTest(x, method = \"z-pooled\")$p.value})\n\nbarnard_unpooled <- apply(foo, MARGIN = 3,\n                        FUN = function (x) {BarnardTest(x, method = \"z-unpooled\")$p.value})\n\nbarnard_boschloo <- apply(foo, \n                          MARGIN = 3,\n                          FUN = function (x) {BarnardTest(x, method = \"boschloo\")$p.value})\n\n\nbarnard_csm <- apply(foo, \n                          MARGIN = 3,\n                          FUN = function (x) {BarnardTest(x, method = \"csm\")$p.value})\n\nbarnard_santner_snell <- apply(foo, \n                               MARGIN = 3,\n                               FUN = function (x) {BarnardTest(x, method = \"santner and snell\")$p.value})\n\n# for reference\nfisher_exact <-  apply(foo, \n                               MARGIN = 3,\n                               FUN = function (x) {fisher.test(x)$p.value})\n\n\n\n# comment out any that you don't want to appear in the plot\nbarnard <- bind_cols(pooled = barnard_pooled,\n                     unpooled = barnard_unpooled,\n                     boschloo = barnard_boschloo,\n                     csm = barnard_csm,\n                     santner_snell = barnard_santner_snell,\n                     fisher_exact = fisher_exact) %>% \n  pivot_longer(everything(), names_to = \"type\", values_to = \"p\")\n\n# there's some overplotting happening, dodge doesn't seem to work well for ecdf's\nbarnard %>% ggplot(aes(x = p, color = type)) +\n  stat_ecdf()  +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = 2, alpha = .4) +\n  labs(title = \"Barnard extremeness method comparison\")\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-41-1.png){width=672}\n:::\n:::\n\n\nFor accuracy of the size of the test, it seems that csm is the most accurate, but also the most computationally intensive.\nWe not that all the tests have more approriate \"size\" than the fisher_exact test.\n\nResources\n\n-   [Explanation of difference between unconditional and conditional](https://www.researchgate.net/publication/242179503_Conditional_versus_Unconditional_Exact_Tests_for_Comparing_Two_Binomials)\n-   [Exact Test Package Documentation](https://cran.r-project.org/web/packages/Exact/Exact.pdf) - `exact.test` function documentation has more information about barnard implmenetation.\n\n### McNemar\n\nMcNemar tests are used when there is some \"dichotomous trait\", for matched pairs.\nThis means that the responses are statistically dependent.\nThis is common for some longitudinal studies in which a single individual is asked two questions, and their answers are coded as locations in the table.\nThus, the grand total, should be the number of pairs of data, not the total number of observations.\n\nFor example, suppose a person is asked if they voted democrat\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-42_3fb4e880c751b0161bd09e7e7f77870f'}\n\n```{.r .cell-code}\ntribble(~\"\", ~\"2008 democrat\", ~\"2008 republican\",\n        \"2004 democrat\", 175, 16,\n        \"2004 republican\", 54, 188) %>% \n  kbl()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> 2008 democrat </th>\n   <th style=\"text-align:right;\"> 2008 republican </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 2004 democrat </td>\n   <td style=\"text-align:right;\"> 175 </td>\n   <td style=\"text-align:right;\"> 16 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 2004 republican </td>\n   <td style=\"text-align:right;\"> 54 </td>\n   <td style=\"text-align:right;\"> 188 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nMcNemar tests \"Marginal Homogeneity\", meaning that the probabilities of the margins are the same.\n$p_a + p_b = p_a + p_c$ and $p_c + p_d = p_b + p_d$.\nThus, this means that we are testing $H_0: p_b = p_c$, $H_A: p_b \\neq p_c$.\nThe score statistic is:\n\n$$\n\\begin{aligned}\nz_0^2 = \\frac{(b-c)^2}{b+c} \\sim \\chi^2_1\n\\end{aligned}\n$$\n\n<!-- This section needs clarification... -->\n\nVariance is\n\n$$\n\\begin{aligned}\n\\hat\\sigma_0 (d) = \\frac{b + c}{N^2}\n\\end{aligned}\n$$\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-43_86ed9590e76b87b1e338101ba6e0f0e0'}\n\n```{.r .cell-code}\n# Presidential election, dependent table\npres <- matrix(c(175, 16,\n                      54, 188),\n                    ncol = 2,\n                    byrow = TRUE)\npres_mcnemar <- mcnemar.test(pres, correct = FALSE)\n# (54 - 16)^2 / (54 + 16) # 20.629\npres_mcnemar\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMcNemar's Chi-squared test\n\ndata:  pres\nMcNemar's chi-squared = 20.629, df = 1, p-value = 5.576e-06\n```\n:::\n:::\n\n\nNotes\n\n-   only the off diagonal matters for significance, where as the main diagonal\n\nA good reference is 11.1 in Categorical Data Analysis, 3rd edition by Agresti\n\n### Breslow-Day Test\n\na test of homogeneity.\n\n### Wilcox Test\n\nIs a test of location for two samples. This somewhat analogous to a nonparametric t-test, it wouldn't normally be considered a categorical test, but there's an equivalence to the trend test with average ranks as the scores.\n\n### Krustkal Wallis\n\nAlso a test of location for K samples.\nThis is an extension of the Wilcox test that is also nonparametric.\nthis can be thought of a nonparameteric anova.\n\n### Cochran-Armitrage Trend Test (ordinal)\n\n- `CochranArmitageTest`\n\nAppropriate for IxJ tables in which *both* directions are ordinal.\n\nThese tests are more powerful for testing specific hypotheses, like a specific trend. We can kind of think of fitting some weighted regression to a surface that is determined by the scores along X and Y. This means that we must assign scores of separation to X and Y. If one of them is a binary variable, we'd generally assign 0-1, or if the ordinal categories carry some numeric meaning, ie. number of drinks is 0-1, 1-4, 5-7. You may consider using .5, 2.5, 6 for the scores of separation for them.\n\nIn the 2xJ case, this reduces to a Wilcoxon test, (also known as Mann-Whitney). The Wilcoxon test would use the midranks for each of the categories of separation. Misassigning the scores when there's a linear trend means it'll be inefficient, but by a factor the correlation of false and true scores squared (Agresti)\n\nIf we don't know what the trend is, then we may be better off testing with a pearson test which just looks for general association.\n\nI think the terminology is a little confusing here, but although it generalizes to IxJ, it seems most common for case-control studies in which we have 2xJ or Ix2. In either case, it's a proprotional trend test that the probabilities are increasing based on score.\n\nFirst we consider testing Ix2 tables, so that we have a column of proportions we can test. The trend test is testing a linear trend in the column of proportions.\n\nIt is useful to think about the trend test as a breakdown of the chisq from the independence pearson test. That is, we can first calculate the pearson chisq:\n\n$$\n\\begin{aligned}\n\\chi^2(I) = \\chi^2(T) + \\chi^2(L)\n\\end{aligned}\n$$\nwhere $\\chi^2(I)$ is the pearson chisq statistic, $\\chi^2(T)$ is the trend chisq statistic, and $X^2(L)$ is the component leftover, deviance from the regression.\n\nThe model behind the test is a linear logistic model, which we weight the scores of the coefficients:\n\n$$\n\\begin{aligned}\n\\operatorname{logit}(\\pi_i) = \\alpha + \\beta x_i\n\\end{aligned}\n$$\n\n\n#### Example: Infants and Alcohol\n\nThis example is from @agrestiCategoricalDataAnalysis2013, and looks at the if the number of drinks you have per week has an effect on the malformation of your child.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-44_0f7fc9845dd1eb0e65f52eea9392f3ef'}\n\n```{.r .cell-code}\n# Infant Alcohol data, Table 5.3 in Agresti\nalcohol <- matrix(c(48, 17066, \n                    38, 14464,\n                    5, 788,\n                    1, 126,\n                    1, 37), byrow = T, ncol = 2,\n                  dimnames = list(alcohol = c(\"0\", \"<1\", \"1-2\", \"3-5\", \">5\"),\n                                  malformation = c(\"present\", \"absent\")))\n\n# in data frame form\nalcohol_df <- alcohol |> \n  as.data.frame() |> \n  rownames_to_column(var = \"alcohol\")\nalcohol_ldf <- alcohol_df |> \n  pivot_longer(present:absent, names_to = \"malformation\") # long format\nalcohol_lldf <- Untable(alcohol) # every observation listed\n\n# margins\nalcohol_rsum <- marginSums(alcohol, margin = 1)\nalcohol_csum <- marginSums(alcohol, margin = 2)\nalcohol_sum <- marginSums(alcohol)\n\n# obs and expected proportions\nalcohol_expected_prop <- outer(alcohol_rsum, alcohol_csum) / alcohol_sum^2\nalcohol_expected_count <- outer(alcohol_rsum, alcohol_csum) / alcohol_sum # expected counts\n\nalcohol |> kable() |> kable_minimal()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\" lightable-minimal\" style='font-family: \"Trebuchet MS\", verdana, sans-serif; margin-left: auto; margin-right: auto;'>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">   </th>\n   <th style=\"text-align:right;\"> present </th>\n   <th style=\"text-align:right;\"> absent </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 0 </td>\n   <td style=\"text-align:right;\"> 48 </td>\n   <td style=\"text-align:right;\"> 17066 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> &lt;1 </td>\n   <td style=\"text-align:right;\"> 38 </td>\n   <td style=\"text-align:right;\"> 14464 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 1-2 </td>\n   <td style=\"text-align:right;\"> 5 </td>\n   <td style=\"text-align:right;\"> 788 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 3-5 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 126 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> &gt;5 </td>\n   <td style=\"text-align:right;\"> 1 </td>\n   <td style=\"text-align:right;\"> 37 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nAfter having so many drinks, we can show you the proportion of those that have malformations in their infants.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-45_3b70395d5c6804e4a4bd0b7d2d8eb7df'}\n\n```{.r .cell-code}\n# pearson statistic, and manually\n# sum((alcohol - alcohol_expected_count)^2 / alcohol_expected_count) # pearson statistic\n# chisq.test(alcohol, correct = FALSE)\nprop.test(alcohol)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in prop.test(alcohol): Chi-squared approximation may be incorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\t5-sample test for equality of proportions without continuity correction\n\ndata:  alcohol\nX-squared = 12.082, df = 4, p-value = 0.01675\nalternative hypothesis: two.sided\nsample estimates:\n     prop 1      prop 2      prop 3      prop 4      prop 5 \n0.002804721 0.002620328 0.006305170 0.007874016 0.026315789 \n```\n:::\n:::\n\n\nThe pearson statistic is 12.082, with 4 degrees of freedom\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-46_358c5ffaed2e6d0e6d50543a0802e5a7'}\n\n```{.r .cell-code}\n# LRT G^2, manually\n# 2 * sum(alcohol * log(alcohol / alcohol_expected_count)) # LRT statistic\n# AMR::g.test(alcohol)\n# G.test(alcohol)\nDescTools::GTest(alcohol)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tLog likelihood ratio (G-test) test of independence without correction\n\ndata:  alcohol\nG = 6.202, X-squared df = 4, p-value = 0.1846\n```\n:::\n:::\n\n\nSimilarly, the LRT G^2 statistic is 6.202, in this case giving contradictory results for the p-value. But both of these tests are treating the covariates as categorical, but we should want to do something ordinal.\n\nWe consider these models, because they seem related and I want to know what the difference between them is (the last one is the most correct I believe).\n\n1. Poisson\n2. Logistic\n\n - without the weights, and fully expanding the table so that every malformation is its own row with one variable of the alcohol level.\n \n3. Logistic against scores\n\n4. Logistic w/ weights\n\n  - the weights here will represent the number of observations in the binomial that went into that observation\n  - If we have $i\\in I$ binomial observations, the model $Binom(n_i, \\pi_i) / n_i \\sim x_i\\beta$\n  \n5. Logistic w/ weights against scores\n\n  - This is the correct model, and how the model should be fit.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-47_695001e2c0f8a3b6df9300b27cd9c2f0'}\n\n```{.r .cell-code}\n# GLM Models\n## Logistic modeling preparation\nalcohol_logit <- logitlink(alcohol[,1]/alcohol[,2])\nalcohol_lldf_logistic <- alcohol_lldf |> mutate(malformation_num = recode(malformation, \"present\" = 1, \"absent\" = 0))\n\n## Poisson\nalcohol_poisson <- glm(value~alcohol + malformation, data = alcohol |> melt(), family = poisson())\n\n## Logit\nalcohol_logistic <- glm(malformation_num~alcohol, data = alcohol_lldf_logistic, family = binomial(link=\"logit\"))\n\n## Linear Logit\nalcohol_lldf_linear_logistic <- alcohol_lldf_logistic |> mutate(alcohol_score = recode(alcohol,\n                                                       \"0\" = 0,\n                                                       \"<1\" = .5,\n                                                       \"1-2\" = 1.5,\n                                                       \"3-5\" = 4,\n                                                       \">5\" = 7))\nalcohol_linear_logistic <- glm(malformation_num~alcohol_score, data = alcohol_lldf_linear_logistic, family = binomial(link = \"logit\"))\n\n## weighted logistic\nalcohol_wlogistic <- glm(alcohol[,1]/alcohol_rsum~1, family = binomial, weights = alcohol_rsum)\n\n## weighted linear logistic regression\nalcohol_scores <- c(0, .5, 1.5, 4, 7)\nalcohol_wll <- glm(alcohol[,1]/alcohol_rsum~alcohol_scores, family = binomial, weights = alcohol_rsum)\n\nsummary(alcohol_wll)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = alcohol[, 1]/alcohol_rsum ~ alcohol_scores, family = binomial, \n    weights = alcohol_rsum)\n\nDeviance Residuals: \n      0       <1      1-2      3-5       >5  \n 0.5921  -0.8801   0.8865  -0.1449   0.1291  \n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     -5.9605     0.1154 -51.637   <2e-16 ***\nalcohol_scores   0.3166     0.1254   2.523   0.0116 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6.2020  on 4  degrees of freedom\nResidual deviance: 1.9487  on 3  degrees of freedom\nAIC: 24.576\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nThe summary output here is the weighted linear logistic regression. It's the \"proper\" model here, and it seems the trend is significant, with an estimate of odds increase of malformation 1.3724535 for each additional drink.\n\n\n::: {.callout-warning icon=false appearance=\"minimal\"}\n\nFor some reason fitting the non-weighted version of the logistic regression and summing the pearson residuals does NOT give you the right independence pearson statistic, for the fully expanded dataset. You will get the correct pearson statistic if you use the poisson glm, or the weighted binomial, and I'm not sure the reason why.\n\n:::\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-48_ebf52926321989a77fac3f7a8686cfa4'}\n\n```{.r .cell-code}\n# Statistics using logistic distribution\nanova(alcohol_logistic, test = \"Rao\") # X^2 (score test)\nanova(alcohol_logistic, test = \"LRT\") # G^2, LRT test\n\n# Statistics using poisson distribution\nsum(residuals(alcohol_poisson, type = \"pearson\")^2) # pearson statistic, X^2\nsum(residuals(alcohol_poisson, type = \"deviance\")^2) # deviance statistic, G^2\n# df.residual(alcohol_poisson) # for testing the statistics\n\n# linear logistic model\n# summary(alcohol_linear_logistic) # The estimates here are the same as the weighted logistic, and standard errors are correct, but residual degrees of freedom are incorrect.\nanova(alcohol_linear_logistic, test = \"Rao\") # Cochran Trend statistic, X^2(T), correct (score test)\nanova(alcohol_linear_logistic, test = \"LRT\") # Analogous to Cochran Trend test, but LRT test. 4.25\n\n# I'm not sure the significance of the sum of the pearson residuals in the fully expanded data\n# pearstat <- sum(residuals(alcohol_linear_logistic, type = \"pearson\")^2)\n# 1 - pchisq(pearstat, df.residual(alcohol_linear_logistic)) # goodness of fit? pearson test..\n\n# logistic with weights\n# summary(alcohol_wlogistic)\nsum(residuals(alcohol_wlogistic, type = \"pearson\")^2) # pearson statistic, X^2, score\ndeviance(alcohol_wlogistic) # deviance statistic, G^2, LRT\nanova(alcohol_wlogistic, test = \"Chisq\") # not correct because there are no terms to drop! IT's only the\n\n# linear logistic with weights\n# summary(alcohol_wll)\ndeviance(alcohol_wll) # deviance gof statistic\nsum(residuals(alcohol_wll, type = \"pearson\")^2) # pearson gof statistic\nanova(alcohol_wll, test = \"Rao\") # Cochran Trend Test statistic (score)\nanova(alcohol_wll, test = \"LRT\") # LRT analogue\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: malformation_num\n\nTerms added sequentially (first to last)\n\n        Df Deviance Resid. Df Resid. Dev    Rao Pr(>Chi)  \nNULL                    32573     1275.5                  \nalcohol  4    6.202     32569     1269.2 12.084  0.01674 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: malformation_num\n\nTerms added sequentially (first to last)\n\n        Df Deviance Resid. Df Resid. Dev Pr(>Chi)\nNULL                    32573     1275.5         \nalcohol  4    6.202     32569     1269.2   0.1846\n[1] 12.08205\n[1] 6.201998\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: malformation_num\n\nTerms added sequentially (first to last)\n\n              Df Deviance Resid. Df Resid. Dev   Rao Pr(>Chi)  \nNULL                          32573     1275.5                 \nalcohol_score  1   4.2533     32572     1271.2 6.571  0.01037 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: malformation_num\n\nTerms added sequentially (first to last)\n\n              Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \nNULL                          32573     1275.5           \nalcohol_score  1   4.2533     32572     1271.2  0.03917 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n[1] 12.08205\n[1] 6.201998\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: alcohol[, 1]/alcohol_rsum\n\nTerms added sequentially (first to last)\n\n     Df Deviance Resid. Df Resid. Dev Pr(>Chi)\nNULL                     4      6.202         \n[1] 1.948721\n[1] 2.05229\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: alcohol[, 1]/alcohol_rsum\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev    Rao Pr(>Chi)  \nNULL                               4     6.2020                  \nalcohol_scores  1   4.2533         3     1.9487 6.5701  0.01037 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Deviance Table\n\nModel: binomial, link: logit\n\nResponse: alcohol[, 1]/alcohol_rsum\n\nTerms added sequentially (first to last)\n\n               Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \nNULL                               4     6.2020           \nalcohol_scores  1   4.2533         3     1.9487  0.03917 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\nCalculating the confidence interval by `profile` in the weighted regression seems to error out, so an example of how to estimate it with the package Bhat is given in CDA Thompson's PDF.\n\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-49_7875ad6b61e141c1dde22787b26d3229'}\n\n```{.r .cell-code}\n# results: hold\nalcohol_overall_prop <- alcohol_csum / alcohol_sum\np_i <- alcohol[,1] / alcohol_rsum\np <- alcohol_overall_prop[1] # overall margin population\n\n# cochran armitage trend test (very manually)\n# xbar <- sum(alcohol_rsum / alcohol_sum * alcohol_scores)\n# b <- sum(alcohol_rsum * (p_i - p) * (alcohol_scores - xbar)) / sum(alcohol_rsum * (alcohol_scores - xbar)^2)\n# pi_i <- p + b * (alcohol_scores - xbar)\n\n# take the fitted values from this\nalcohol_trend_lm <- lm(p_i ~ alcohol_scores, weights = alcohol_rsum)\npi_i <- fitted(alcohol_trend_lm)\nb <- coef(alcohol_trend_lm)[2]\n# xbar <- weighted.mean(alcohol_scores, alcohol_rsum)\n\n1 / (alcohol_overall_prop[1] * (1 - alcohol_overall_prop[1])) * sum(alcohol_rsum * (p_i - p)^2) # pearson independence from brandt Snecdor formula\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n present \n12.08205 \n```\n:::\n\n```{.r .cell-code}\n# decomposes into\n1 / (alcohol_overall_prop[1] * (1 - alcohol_overall_prop[1])) * sum(alcohol_rsum * (p_i - pi_i)^2) # X^2(L)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n present \n5.511921 \n```\n:::\n\n```{.r .cell-code}\n1 / (alcohol_overall_prop[1] * (1 - alcohol_overall_prop[1])) * sum(alcohol_rsum * (pi_i - p)^2) # Trend statistic,\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n present \n6.570134 \n```\n:::\n:::\n\n\nNotice in the above calculations, the only difference between the pearson independence statistic, and the \"lack of fit\" statistic, is the usage of the predicted probabilities. This decomposition is the classic anova move of decomposing a sum of squares into a middle ground of some model based probability, so that we get an SS for the model and SS for the\n\nThere's also the relationship to the $M^2$ pearson correlation based statistic for ordinal models.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-50_1bc89df742e4aa8abbd76845c5f3f88f'}\n\n```{.r .cell-code}\n# Cochran relation to M^2, correlation based statistic\nwith(alcohol_lldf_linear_logistic,\n     cor(alcohol_score, malformation_num)^2) * alcohol_sum # Cochran trend statistic by pearson correlation\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6.570134\n```\n:::\n:::\n\n\nThese above section explores the two decompositions of the independence statistic.\n\n$$\n\\begin{aligned}\n\\chi^2_{I - 2}(I) &= \\underbrace{\\chi^2_1(T)}_{\\text{Cochran Trend Statistic}} +  \\chi^2_{I - 2}(L) \\\\\n 12.08 &= 6.5701 + 5.512 \\\\\n G^2(I) &= \\underbrace{G^2(I | L)}_{\\text{LRT Trend Statistic}} + G^2(L) \\\\\n 6.202 &= 4.2533 + 1.9487\n\\end{aligned}\n$$\n$I$ in paranthesis means independent, but in the subscript it means number of rows, as in a I x 2 table. The trend statistic is a one degree of freedom test that is similar to the ANOVA principle that we can decompose the Independence into two independent test statistics, and create tests from them individually. Both of these break down and are chi squared statistic.\n\n::: {.callout-note icon=false appearance=\"minimal\"}\n\n##### Power in Chisq testing\n\nPower is the probability of rejecting when the null hypothesis is false, so we generally need to discuss the noncentrality parameter. In chisq testing, the power increases when the degrees of freedom for the test decrease. We can gain more power by testing for narrower alternative. In this case, $G^2(I)$ has I-1 degrees of freedom, while $G^2(I|L)$ only has 1 degree of freedom. Consider two scenarios\n\n1. Linear logit function holds, then the goodness of fit $G^2(L)$ will be asymptotic chisq, and $G^2(I) and G^2(I|L)$ will have the same noncentrality parameter.\n\n2. The linear logit model does NOT hold, then $G^2(I)$ will have a higher noncentrality parameter than $G^2(I|L)$ and thus, the higher noncentrality parameter will mean that we have more power (generally), but when the linear logit model holds approximately, the noncentrality parameter should be similar, thus the lower df statistic will still be more powerful. Mantel 1964 notes that although its a linear test, it does not mean we're making an assumption of linearity, the test statistic is still useful for determining any sort of progressive trend.\n\n:::\n\nOkay, enough of messing with the raw models, this is the fastest way to run a Cochran test directly without the model.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-51_17cb3f891ab239b612fa99c1fa2e2431'}\n\n```{.r .cell-code}\n# events, total number, scores\nalcohol_tt <- prop.trend.test(alcohol[,1], n = alcohol_rsum, score = alcohol_scores)\nalcohol_cat <- CochranArmitageTest(alcohol) # cannot adjust scores with this type of test\nalcohol_ct <- coin::chisq_test(as.table(alcohol), scores = list(alcohol = alcohol_scores))\n# independence_test(as.table(alcohol), teststat = \"quadratic\") # general pearson\n# independence_test(as.table(alcohol)) # idk what this is\nalcohol_it <- independence_test(as.table(alcohol), scores = list(alcohol = alcohol_scores))\n\nalcohol_tt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tChi-squared Test for Trend in Proportions\n\ndata:  alcohol[, 1] out of alcohol_rsum ,\n using scores: 0 0.5 1.5 4 7\nX-squared = 6.5701, df = 1, p-value = 0.01037\n```\n:::\n:::\n\n\nThere is a relationship to the wilcoxon two sample test (mann-whitney test) as well. Normally for wilcox_test, it's a test of the median location, that the distribution of row 1 is different from row 2, we can test this with an asymptotic z score. (Now we're considering a 2xJ table instead of a Ix2 table.) Naturally, wilcox will treat all of the same category as ties, and the ties will be replaced with the average of the ranked ties. If the table was [1, 2, 3] vs [6, 1, 1], then the wilcox test is equivalent to the trend test with scores 4, 6, 8.5.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-52_aaad5cf02b5f395cd9af6d4b2a129111'}\n\n```{.r .cell-code}\nwilcox.test(as.numeric(alcohol)~malformation, data = Untable(alcohol), correct = FALSE) # gives the same p-value, different rank statistic\ncoin::wilcox_test(as.numeric(alcohol)~malformation, Untable(alcohol))\n# alcohol_wilcox_scores <- cumsum((1 + alcohol_rsum) / 2)\nalcohol_wilcox_scores <- c(((alcohol_rsum + 1) / 2)[1:4], 0) + c(0, cumsum(alcohol_rsum)[1:4]) # average of min/max rank\nprop.trend.test(alcohol[,1], n = alcohol_rsum, alcohol_wilcox_scores)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test\n\ndata:  as.numeric(alcohol) by malformation\nW = 1557372, p-value = 0.5533\nalternative hypothesis: true location shift is not equal to 0\n\n\n\tAsymptotic Wilcoxon-Mann-Whitney Test\n\ndata:  as.numeric(alcohol) by malformation (present, absent)\nZ = 0.59281, p-value = 0.5533\nalternative hypothesis: true mu is not equal to 0\n\n\n\tChi-squared Test for Trend in Proportions\n\ndata:  alcohol[, 1] out of alcohol_rsum ,\n using scores: 8557.5 24365.5 32013 32473 32536\nX-squared = 0.35118, df = 1, p-value = 0.5534\n```\n:::\n:::\n\n\n\n\n\n\n\n\n#### Example: Decomposing Total Chisq\n\nThis example comes from Cochran 1954, Table 4.\n@cochranMethodsStrengtheningCommon1954\n\n\n\n\n\n### CMH testing\n\nThe CMH testing is technically supposed to be done on tables in strata.\nthe data type is an I X J X K, in which we have K strata and an I X J contingency table in each.\n\n-   you are not penalized for adding tables with sparse data with the CMH test statistic\n-   this reduces to the N-1 adjusted pearson chisquared statistic for 1 strata\n-   the test assumes that there is a common odds ratio to estimate, but in order to test the hypothesis we can use a Breslow-Day Test of Homogeneity\n-   Conditional logistic regression gives a similar answer, `clogit` in package `survival` because similar to cox model as well.\n\n#### Generalized CMH Testing\n\nCMH is extended to IxJxK with possibly ordinal factors for I and J.\nAn implementation of these statistics can be found:\n\n-   `coin::cmh_test()`\n-   `vcdExtra:CHMtest()`\n\n#### CMH - McNemar Equivalence\n\nIf you express the \"population averaged\" table and run McNemar, you will get the same statistic as expressing the data as a \"subject specific\" table for an individual per stratum.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-57_5fcdfb616a588050961a535032e17acf'}\n\n```{.r .cell-code}\ntest <- matrix(c(5, 7, 3, 4), ncol = 2)\nchisq.test(test, correct = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in chisq.test(test, correct = FALSE): Chi-squared approximation may be\nincorrect\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's Chi-squared test\n\ndata:  test\nX-squared = 0.0025703, df = 1, p-value = 0.9596\n```\n:::\n\n```{.r .cell-code}\n0.0025703 / 19 * 18 # the \"N-1\" chisq statistic in a 2 x 2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.002435021\n```\n:::\n\n```{.r .cell-code}\nfoo <- array(c(5, 7, 3, 4,\n               0, 0, 1, 1), dim = c(2, 2, 2))\nmantelhaen.test(foo, correct = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMantel-Haenszel chi-squared test without continuity correction\n\ndata:  foo\nMantel-Haenszel X-squared = 0.0024351, df = 1, p-value = 0.9606\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 0.1444191 6.2805369\nsample estimates:\ncommon odds ratio \n         0.952381 \n```\n:::\n\n```{.r .cell-code}\nbar <- array(c(5, 7, 3, 4,\n               0, 0, 1, 1,\n               1, 6, 0, 0), dim = c(2, 2, 3))\nmantelhaen.test(bar, correct = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tMantel-Haenszel chi-squared test without continuity correction\n\ndata:  bar\nMantel-Haenszel X-squared = 0.0024351, df = 1, p-value = 0.9606\nalternative hypothesis: true common odds ratio is not equal to 1\n95 percent confidence interval:\n 0.1444191 6.2805369\nsample estimates:\ncommon odds ratio \n         0.952381 \n```\n:::\n\n```{.r .cell-code}\nmantelhaen_2by2 <-  function(x) {\n  mantelhaen.test(array(c(x, 0, 0, 1, 1), dim = c(2, 2, 2)), correct = FALSE)\n}\n```\n:::\n\n\n### 2x2 tables Comparison {.tabset}\n\n#### Poisson Sampling\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-58_6651a0d806ae98dcd0b54e30b08dd930'}\n\n```{.r .fold-hide .cell-code}\n# random poisson\nfoo <- rpoisson_table(num_tables = 1000, mean = 5, nrow = 2, ncol = 2)\n\n# pearson uncorrected\npearson_uncorrected_p <- \n  apply(foo, \n      MARGIN = 3,\n      function(x) {\n        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})\n\n# pearson corrected\npearson_corrected_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})\n\nfisher_exact_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(fisher.test(x))$p.value})\n\n# Pearson N-1 correction equivalent\ncmh_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          mantelhaen_2by2(x)$p.value\n        })\n\n# G-test (LRT)\nlrt_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(g.test(x))$p.value\n        })\n\n\ncontingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,\n          corrected = pearson_corrected_p,\n          exact = fisher_exact_p,\n          cmh = cmh_p,\n          lrt = lrt_p)\n\ncontingency_p %>% \n  pivot_longer(everything(), names_to = \"test\", values_to = \"p\") %>% \n  ggplot(aes(p, color = test)) +\n  stat_ecdf(geom = \"step\") +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = 2, alpha = .4) + \n  labs(title = \"Tests of association\") #+\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-58-1.png){width=672}\n:::\n\n```{.r .fold-hide .cell-code}\n  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ggproto object: Class CoordCartesian, Coord, gg>\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  <ggproto object: Class CoordCartesian, Coord, gg>\n```\n:::\n:::\n\n\n#### Binomial Sampling\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-59_49892e16618ffa541a992b7c67dea952'}\n\n```{.r .fold-hide .cell-code}\nfoo <- rbinom_table(num_tables = 9000)\n\n# pearson uncorrected\npearson_uncorrected_p <- \n  apply(foo, \n      MARGIN = 3,\n      function(x) {\n        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})\n\n# pearson corrected\npearson_corrected_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})\n\nfisher_exact_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(fisher.test(x))$p.value})\n\n# Pearson N-1 correction equivalent\ncmh_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          mantelhaen_2by2(x)$p.value\n        })\n\n# G-test (LRT)\nlrt_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(g.test(x))$p.value\n        })\n\n\ncontingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,\n          corrected = pearson_corrected_p,\n          exact = fisher_exact_p,\n          cmh = cmh_p,\n          lrt = lrt_p)\n\ncontingency_p %>% \n  pivot_longer(everything(), names_to = \"test\", values_to = \"p\") %>% \n  ggplot(aes(p, color = test)) +\n  stat_ecdf(geom = \"step\") +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = 2, alpha = .4) #+\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-59-1.png){width=672}\n:::\n\n```{.r .fold-hide .cell-code}\n  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ggproto object: Class CoordCartesian, Coord, gg>\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  <ggproto object: Class CoordCartesian, Coord, gg>\n```\n:::\n:::\n\n\n#### Multinomial Sampling\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-60_4b18f74cfb3812b5b34193cfd124fe80'}\n\n```{.r .fold-hide .cell-code}\nfoo <- rmultinom_table(num_tables = 1000)\n\n# pearson uncorrected\npearson_uncorrected_p <- \n  apply(foo, \n      MARGIN = 3,\n      function(x) {\n        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})\n\n# pearson corrected\npearson_corrected_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})\n\nfisher_exact_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(fisher.test(x))$p.value})\n\n# Pearson N-1 correction equivalent\ncmh_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          mantelhaen_2by2(x)$p.value\n        })\n\n# G-test (LRT)\nlrt_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(g.test(x))$p.value\n        })\n\n\ncontingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,\n          corrected = pearson_corrected_p,\n          exact = fisher_exact_p,\n          cmh = cmh_p,\n          lrt = lrt_p)\n\ncontingency_p %>% \n  pivot_longer(everything(), names_to = \"test\", values_to = \"p\") %>% \n  ggplot(aes(p, color = test)) +\n  stat_ecdf(geom = \"step\") +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = 2, alpha = .4) #+\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-60-1.png){width=672}\n:::\n\n```{.r .fold-hide .cell-code}\n  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ggproto object: Class CoordCartesian, Coord, gg>\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  <ggproto object: Class CoordCartesian, Coord, gg>\n```\n:::\n:::\n\n\n#### Hypergeometric Sampling\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-61_dd02a9aac3ac0a254bc16602c787c65b'}\n\n```{.r .fold-hide .cell-code}\nfoo <- rhyper_table(num_tables = 1000)\n\n# pearson uncorrected\npearson_uncorrected_p <- \n  apply(foo, \n      MARGIN = 3,\n      function(x) {\n        suppressWarnings(chisq.test(x, correct = FALSE))$p.value})\n\n# pearson corrected\npearson_corrected_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(chisq.test(x, correct = TRUE))$p.value})\n\nfisher_exact_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(fisher.test(x))$p.value})\n\n# Pearson N-1 correction equivalent\ncmh_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          mantelhaen_2by2(x)$p.value\n        })\n\n# G-test (LRT)\nlrt_p <- \n  apply(foo,\n        MARGIN = 3,\n        function(x) {\n          suppressWarnings(g.test(x))$p.value\n        })\n\n\ncontingency_p <- bind_cols(uncorrected = pearson_uncorrected_p,\n          corrected = pearson_corrected_p,\n          exact = fisher_exact_p,\n          cmh = cmh_p,\n          lrt = lrt_p)\n\ncontingency_p %>% \n  pivot_longer(everything(), names_to = \"test\", values_to = \"p\") %>% \n  ggplot(aes(p, color = test)) +\n  stat_ecdf(geom = \"step\") +\n  geom_abline(slope = 1, intercept = 0, color = \"black\", linetype = 2, alpha = .4) #+\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-61-1.png){width=672}\n:::\n\n```{.r .fold-hide .cell-code}\n  coord_cartesian(xlim = c(0, .1), ylim = c(0, .1)) # for zooming in\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<ggproto object: Class CoordCartesian, Coord, gg>\n    aspect: function\n    backtransform_range: function\n    clip: on\n    default: FALSE\n    distance: function\n    expand: TRUE\n    is_free: function\n    is_linear: function\n    labels: function\n    limits: list\n    modify_scales: function\n    range: function\n    render_axis_h: function\n    render_axis_v: function\n    render_bg: function\n    render_fg: function\n    setup_data: function\n    setup_layout: function\n    setup_panel_guides: function\n    setup_panel_params: function\n    setup_params: function\n    train_panel_guides: function\n    transform: function\n    super:  <ggproto object: Class CoordCartesian, Coord, gg>\n```\n:::\n:::\n\n\n## More than two categories\n\nThis section starts to get into 2 x I tables, and even more dimensions like, I X J X K tables, and how we analyze those tables.\nWe'll start with an overview of the multinomial theory, which is fundamental in extending the binomial (2 categories) into multiple categories.\nThe binomial is a special case of the multinomial distribution\n\n-   `nnet::multinom`\n-   `VGAM::vglm(family = multinom)`\n-   `mlogit::mlogit`\n\nA common example we see in this exposition is housing data from library `MASS`\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-62_7513debd475c9e7a985639e06ebe50f9'}\n\n```{.r .cell-code}\nlibrary(MASS)\ndata(housing)\n\n# The array version\nhousing_arr <- xtabs(Freq~Sat + Infl + Type + Cont, data = housing)\n```\n:::\n\n\n### Poisson GLM Modeling\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-63_60f6f0c0b595ab40131efaa955294d73'}\n\n```{.r .cell-code}\n# simple glm model (satisfaction independent of Infl, Type, Cont)\nhouse_glm <- glm(Freq ~ Infl*Type*Cont + Sat, data = housing, family = poisson)\nsummary(house_glm) # high residual deviance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Freq ~ Infl * Type * Cont + Sat, family = poisson, \n    data = housing)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-4.5551  -1.0612  -0.0593   0.6483   4.1478  \n\nCoefficients:\n                                    Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                        3.136e+00  1.196e-01  26.225  < 2e-16 ***\nInflMedium                         2.733e-01  1.586e-01   1.723 0.084868 .  \nInflHigh                          -2.054e-01  1.784e-01  -1.152 0.249511    \nTypeApartment                      3.666e-01  1.555e-01   2.357 0.018403 *  \nTypeAtrium                        -7.828e-01  2.134e-01  -3.668 0.000244 ***\nTypeTerrace                       -8.145e-01  2.157e-01  -3.775 0.000160 ***\nContHigh                          -2.200e-16  1.690e-01   0.000 1.000000    \nSat.L                              1.159e-01  4.038e-02   2.871 0.004094 ** \nSat.Q                              2.629e-01  4.515e-02   5.824 5.76e-09 ***\nInflMedium:TypeApartment          -1.177e-01  2.086e-01  -0.564 0.572571    \nInflHigh:TypeApartment             1.753e-01  2.279e-01   0.769 0.441783    \nInflMedium:TypeAtrium             -4.068e-01  3.035e-01  -1.340 0.180118    \nInflHigh:TypeAtrium               -1.692e-01  3.294e-01  -0.514 0.607433    \nInflMedium:TypeTerrace             6.292e-03  2.860e-01   0.022 0.982450    \nInflHigh:TypeTerrace              -9.305e-02  3.280e-01  -0.284 0.776633    \nInflMedium:ContHigh               -1.398e-01  2.279e-01  -0.613 0.539715    \nInflHigh:ContHigh                 -6.091e-01  2.800e-01  -2.176 0.029585 *  \nTypeApartment:ContHigh             5.029e-01  2.109e-01   2.385 0.017083 *  \nTypeAtrium:ContHigh                6.774e-01  2.751e-01   2.462 0.013811 *  \nTypeTerrace:ContHigh               1.099e+00  2.675e-01   4.106 4.02e-05 ***\nInflMedium:TypeApartment:ContHigh  5.359e-02  2.862e-01   0.187 0.851450    \nInflHigh:TypeApartment:ContHigh    1.462e-01  3.380e-01   0.432 0.665390    \nInflMedium:TypeAtrium:ContHigh     1.555e-01  3.907e-01   0.398 0.690597    \nInflHigh:TypeAtrium:ContHigh       4.782e-01  4.441e-01   1.077 0.281619    \nInflMedium:TypeTerrace:ContHigh   -4.980e-01  3.671e-01  -1.357 0.174827    \nInflHigh:TypeTerrace:ContHigh     -4.470e-01  4.545e-01  -0.984 0.325326    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 833.66  on 71  degrees of freedom\nResidual deviance: 217.46  on 46  degrees of freedom\nAIC: 610.43\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\n\nClearly there's probably some correlation between satisfaction and the other variables, let's check them out individually.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-64_139f0ca7247bf49f3392acd59d489e55'}\n\n```{.r .cell-code}\n# addterm will check each term individually, and test marginality\naddterm(house_glm, ~. + Sat:(Infl+Type+Cont), test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term additions\n\nModel:\nFreq ~ Infl * Type * Cont + Sat\n         Df Deviance    AIC     LRT   Pr(Chi)    \n<none>        217.46 610.43                      \nInfl:Sat  4   111.08 512.05 106.371 < 2.2e-16 ***\nType:Sat  6   156.79 561.76  60.669 3.292e-11 ***\nCont:Sat  2   212.33 609.30   5.126   0.07708 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nInfluence seems to have the largest impact, so we add this to the model, and type probably has a large\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-65_34e062a901d63622322e25404c48f275'}\n\n```{.r .cell-code}\nhouse_glm1 <- update(house_glm, .~. + Sat:(Infl + Type + Cont))\nsummary(house_glm1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = Freq ~ Infl + Type + Cont + Sat + Infl:Type + Infl:Cont + \n    Type:Cont + Infl:Sat + Type:Sat + Cont:Sat + Infl:Type:Cont, \n    family = poisson, data = housing)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6022  -0.5282  -0.0641   0.5757   1.9322  \n\nCoefficients:\n                                   Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                        3.135074   0.120112  26.101  < 2e-16 ***\nInflMedium                         0.248327   0.159979   1.552 0.120602    \nInflHigh                          -0.412645   0.184947  -2.231 0.025671 *  \nTypeApartment                      0.292524   0.157477   1.858 0.063231 .  \nTypeAtrium                        -0.792847   0.214413  -3.698 0.000218 ***\nTypeTerrace                       -1.018074   0.221263  -4.601 4.20e-06 ***\nContHigh                          -0.001407   0.169711  -0.008 0.993385    \nSat.L                             -0.098106   0.112592  -0.871 0.383570    \nSat.Q                              0.285657   0.122283   2.336 0.019489 *  \nInflMedium:TypeApartment          -0.017882   0.210496  -0.085 0.932302    \nInflHigh:TypeApartment             0.386869   0.233297   1.658 0.097263 .  \nInflMedium:TypeAtrium             -0.360311   0.304979  -1.181 0.237432    \nInflHigh:TypeAtrium               -0.036788   0.334793  -0.110 0.912503    \nInflMedium:TypeTerrace             0.185154   0.288892   0.641 0.521580    \nInflHigh:TypeTerrace               0.310749   0.334815   0.928 0.353345    \nInflMedium:ContHigh               -0.200060   0.228748  -0.875 0.381799    \nInflHigh:ContHigh                 -0.725790   0.282352  -2.571 0.010155 *  \nTypeApartment:ContHigh             0.569691   0.212152   2.685 0.007247 ** \nTypeAtrium:ContHigh                0.702115   0.276056   2.543 0.010979 *  \nTypeTerrace:ContHigh               1.215930   0.269968   4.504 6.67e-06 ***\nInflMedium:Sat.L                   0.519627   0.096830   5.366 8.03e-08 ***\nInflHigh:Sat.L                     1.140302   0.118180   9.649  < 2e-16 ***\nInflMedium:Sat.Q                  -0.064474   0.102666  -0.628 0.530004    \nInflHigh:Sat.Q                     0.115436   0.127798   0.903 0.366380    \nTypeApartment:Sat.L               -0.520170   0.109793  -4.738 2.16e-06 ***\nTypeAtrium:Sat.L                  -0.288484   0.149551  -1.929 0.053730 .  \nTypeTerrace:Sat.L                 -0.998666   0.141527  -7.056 1.71e-12 ***\nTypeApartment:Sat.Q                0.055418   0.118515   0.468 0.640068    \nTypeAtrium:Sat.Q                  -0.273820   0.149713  -1.829 0.067405 .  \nTypeTerrace:Sat.Q                 -0.032328   0.149251  -0.217 0.828520    \nContHigh:Sat.L                     0.340703   0.087778   3.881 0.000104 ***\nContHigh:Sat.Q                    -0.097929   0.094068  -1.041 0.297851    \nInflMedium:TypeApartment:ContHigh  0.046900   0.286212   0.164 0.869837    \nInflHigh:TypeApartment:ContHigh    0.126229   0.338208   0.373 0.708979    \nInflMedium:TypeAtrium:ContHigh     0.157239   0.390719   0.402 0.687364    \nInflHigh:TypeAtrium:ContHigh       0.478611   0.444244   1.077 0.281320    \nInflMedium:TypeTerrace:ContHigh   -0.500162   0.367135  -1.362 0.173091    \nInflHigh:TypeTerrace:ContHigh     -0.463099   0.454713  -1.018 0.308467    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 833.657  on 71  degrees of freedom\nResidual deviance:  38.662  on 34  degrees of freedom\nAIC: 455.63\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n\n```{.r .cell-code}\n# sum(residuals(house_glm1, type = \"pearson\")^2) / house_glm1$df.residual # dispersion estimate\nhouse_glm1$df.residual # nrow(housing) - length(coef(house_glm1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 34\n```\n:::\n\n```{.r .cell-code}\n# sum(residuals(house_glm1, type = \"deviance\")^2) / house_glm1$df.residual\n# 1 - pchisq(deviance(house_glm1), house_glm1$df.residual) # .267? what's the test here...\n```\n:::\n\n\nSee 202 for rescaling the predictions from this model to the probability scale (by the margin of satisfaction)\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-66_a332b2b1d4c1e1f89ed26527cc7a3d27'}\n\n```{.r .cell-code}\nhnames <- lapply(housing[, -5], levels) # \nhouse_pm <- predict(house_glm1, expand.grid(hnames), type = \"response\") # poisson means exp(\\eta)\nhouse_pm <- matrix(house_pm, ncol = 3, byrow = T, dimnames = list(NULL, hnames[[1]])) # list the predictions into matrix form, columns being satisfaction\ncbind(expand.grid(hnames[-1]), house_pm / rowSums(house_pm)) # normalize by row, and attach the name\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     Infl      Type Cont       Low    Medium      High\n1     Low     Tower  Low 0.3955687 0.2601077 0.3443236\n2  Medium     Tower  Low 0.2602403 0.2674072 0.4723526\n3    High     Tower  Low 0.1504958 0.1924126 0.6570916\n4     Low Apartment  Low 0.5427582 0.2308450 0.2263968\n5  Medium Apartment  Low 0.3945683 0.2622428 0.3431889\n6    High Apartment  Low 0.2551503 0.2110026 0.5338470\n7     Low    Atrium  Low 0.4294218 0.3220096 0.2485686\n8  Medium    Atrium  Low 0.2959630 0.3468082 0.3572289\n9    High    Atrium  Low 0.1865151 0.2719420 0.5415429\n10    Low   Terrace  Low 0.6453059 0.2178758 0.1368183\n11 Medium   Terrace  Low 0.5076883 0.2678600 0.2244517\n12   High   Terrace  Low 0.3676505 0.2413550 0.3909945\n13    Low     Tower High 0.2982776 0.2813636 0.4203589\n14 Medium     Tower High 0.1847507 0.2723332 0.5429161\n15   High     Tower High 0.1009787 0.1852058 0.7138155\n16    Low Apartment High 0.4375458 0.2669645 0.2954897\n17 Medium Apartment High 0.2974727 0.2836249 0.4189024\n18   High Apartment High 0.1794106 0.2128413 0.6077481\n19    Low    Atrium High 0.3319072 0.3570404 0.3110524\n20 Medium    Atrium High 0.2157414 0.3626615 0.4215970\n21   High    Atrium High 0.1283298 0.2684145 0.6032556\n22    Low   Terrace High 0.5471602 0.2650171 0.1878227\n23 Medium   Terrace High 0.4044226 0.3060991 0.2894783\n24   High   Terrace High 0.2729568 0.2570580 0.4699852\n```\n:::\n:::\n\n\n### Log Linear Models\n\nlog linear models with iterative proportional scaling is done with function `loglm`.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-67_0dd1e26379d35376a15e9e5efdf39ddc'}\n\n```{.r .cell-code}\nloglm(Freq ~ Infl*Type*Cont + Sat*(Infl + Type + Cont), data = housing)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nloglm(formula = Freq ~ Infl * Type * Cont + Sat * (Infl + Type + \n    Cont), data = housing)\n\nStatistics:\n                      X^2 df  P(> X^2)\nLikelihood Ratio 38.66222 34 0.2671359\nPearson          38.90831 34 0.2582333\n```\n:::\n:::\n\n\n### Multinomial Models\n\nThe example data we'll is use party affiliation:\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-68_a9e0ce2ecd7e8a07b6b8b41b6ffbd79d'}\n\n```{.r .cell-code}\n# array version of data\nparty <- array(c(132, 42, 176, 6, 127, 12,\n                 172, 56, 129, 4, 130, 15), \n               dim = c(2, 3, 2),\n               dimnames = list(race = c(\"white\", \"black\"),\n                               party = c(\"democrat\", \"independent\", \"republican\"),\n                               gender = c(\"male\", \"female\")))\nparty_df <- as.data.frame.table(party) # data frame version of data\n\n# Marginal Tables\nrace_party <- margin.table(party, margin = 1:2)\ngender_party <- margin.table(party, margin = c(3, 2))\nrace_gender <- margin.table(party, margin = c(1, 3))\n```\n:::\n\n\n#### nnet\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-69_b117def923859ab0c9e7ea92f729c77f'}\n\n```{.r .cell-code}\nparty_mod <- multinom(party ~ race + gender, weights = Freq, party_df) # democrat is the \"reference\"\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 1099.710901 \niter  10 value 1042.893269\nfinal  value 1042.891187 \nconverged\n```\n:::\n\n```{.r .cell-code}\nsummary(party_mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = party ~ race + gender, data = party_df, weights = Freq)\n\nCoefficients:\n            (Intercept) raceblack genderfemale\nindependent   0.2855582 -2.278140   -0.5727764\nrepublican   -0.0497550 -1.118276   -0.2201972\n\nStd. Errors:\n            (Intercept) raceblack genderfemale\nindependent   0.1125979 0.3427945    0.1575210\nrepublican    0.1198046 0.2335145    0.1582522\n\nResidual Deviance: 2085.782 \nAIC: 2097.782 \n```\n:::\n:::\n\n\nHypothesis testing with nnet\n\n#### VGAM\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-70_ae087313e3784090b03c2a8118d302c6'}\n\n```{.r .cell-code}\n# VGAM\n# needs version in which \"stimulus factors\" are separated from \"response\" factors.\nhousing_wide <- housing %>% pivot_wider(names_from = \"Sat\", values_from = \"Freq\")\n```\n:::\n\n\nOur saturated dataset is one in which every cell is estimated with a parameter.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-71_17a9697077790f1000383223f523e97e'}\n\n```{.r .cell-code}\n# saturated model\nhousing_vglm0 <- vglm(cbind(Low, Medium, High) ~ Infl*Type*Cont, data = housing_wide, family = multinomial)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in vglm.fitter(x = x, y = y, w = w, offset = offset, Xm2 = Xm2, : some\nquantities such as z, residuals, SEs may be inaccurate due to convergence at a\nhalf-step\n```\n:::\n\n```{.r .cell-code}\ndeviance(housing_vglm0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -9.792167e-14\n```\n:::\n:::\n\n\nIn the saturated model, we see that our deviance is equal to 0 because it fits the data perfectly.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-72_3433ab15d90469f65b4e2ff27f5dc004'}\n\n```{.r .cell-code}\n# full two way interaction model\nhousing_vglm <- vglm(cbind(Low, Medium, High) ~ (Infl + Type + Cont)^2, data = housing_wide, family = multinomial)\nsummary(housing_vglm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nvglm(formula = cbind(Low, Medium, High) ~ (Infl + Type + Cont)^2, \n    family = multinomial, data = housing_wide)\n\nCoefficients: \n                             Estimate Std. Error z value Pr(>|z|)    \n(Intercept):1              -0.2728053  0.2532115  -1.077  0.28131    \n(Intercept):2              -0.3780064  0.2576046  -1.467  0.14227    \nInflMedium:1                0.1982869  0.3081018   0.644  0.51985    \nInflMedium:2               -0.0083922  0.3171262  -0.026  0.97889    \nInflHigh:1                 -0.9649735  0.3945466  -2.446  0.01445 *  \nInflHigh:2                 -0.8646670  0.3794916  -2.278  0.02270 *  \nTypeApartment:1             1.4992506  0.3153481   4.754 1.99e-06 ***\nTypeApartment:2             0.6555399  0.3307945   1.982  0.04751 *  \nTypeAtrium:1                0.6246612  0.4142176   1.508  0.13154    \nTypeAtrium:2                0.3751106  0.4204712   0.892  0.37233    \nTypeTerrace:1               1.2966645  0.4192741   3.093  0.00198 ** \nTypeTerrace:2               0.4378242  0.4595906   0.953  0.34077    \nContHigh:1                 -0.7397711  0.3116324  -2.374  0.01760 *  \nContHigh:2                 -0.2009809  0.3039959  -0.661  0.50853    \nInflMedium:TypeApartment:1 -1.3982019  0.3535169  -3.955 7.65e-05 ***\nInflMedium:TypeApartment:2 -0.5498060  0.3604313  -1.525  0.12716    \nInflHigh:TypeApartment:1   -0.9211659  0.4576832  -2.013  0.04415 *  \nInflHigh:TypeApartment:2   -0.3138506  0.4358689  -0.720  0.47149    \nInflMedium:TypeAtrium:1    -0.9955454  0.4790778  -2.078  0.03771 *  \nInflMedium:TypeAtrium:2    -0.1868591  0.4525047  -0.413  0.67965    \nInflHigh:TypeAtrium:1       0.1416714  0.5758309   0.246  0.80566    \nInflHigh:TypeAtrium:2       0.2132503  0.5362081   0.398  0.69085    \nInflMedium:TypeTerrace:1   -0.9030966  0.4563464  -1.979  0.04782 *  \nInflMedium:TypeTerrace:2    0.0081197  0.4836471   0.017  0.98661    \nInflHigh:TypeTerrace:1     -0.8443360  0.5889810  -1.434  0.15170    \nInflHigh:TypeTerrace:2     -0.2200667  0.5911664  -0.372  0.70970    \nInflMedium:ContHigh:1       0.0119167  0.2883493   0.041  0.96703    \nInflMedium:ContHigh:2      -0.0735225  0.3046628  -0.241  0.80930    \nInflHigh:ContHigh:1        -0.2258679  0.3504496  -0.645  0.51925    \nInflHigh:ContHigh:2         0.0318502  0.3496997   0.091  0.92743    \nTypeApartment:ContHigh:1    0.1350432  0.3218707   0.420  0.67481    \nTypeApartment:ContHigh:2   -0.0002221  0.3186735  -0.001  0.99944    \nTypeAtrium:ContHigh:1       0.3409407  0.4320950   0.789  0.43009    \nTypeAtrium:ContHigh:2       0.2975587  0.4139167   0.719  0.47221    \nTypeTerrace:ContHigh:1      1.1520381  0.4173381   2.760  0.00577 ** \nTypeTerrace:ContHigh:2      0.6313710  0.4353792   1.450  0.14701    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: log(mu[,1]/mu[,3]), log(mu[,2]/mu[,3])\n\nResidual deviance: 5.9443 on 12 degrees of freedom\n\nLog-likelihood: -102.5404 on 12 degrees of freedom\n\nNumber of Fisher scoring iterations: 3 \n\nNo Hauck-Donner effect found in any of the estimates\n\n\nReference group is level  3  of the response\n```\n:::\n\n```{.r .cell-code}\ndeviance(housing_vglm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.944319\n```\n:::\n\n```{.r .cell-code}\n# Lack of fit tests\n1 - pchisq(deviance(housing_vglm), df.residual(housing_vglm)) # deviance\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9188628\n```\n:::\n\n```{.r .cell-code}\n1 - pchisq(sum(residuals(housing_vglm, type = \"pearson\")^2), df.residual(housing_vglm)) # pearson\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.917741\n```\n:::\n:::\n\n\nThe null hypothesis here is that the model is specified correctly.\nHigh p-values mean we fail to reject that the model is correct.\nIn general, lack of fit tests are pretty bad tests for telling us any information.\nWe would prefer to do some manual model searching.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-73_7a39b1af3c72c115fe3d94f8097fab7b'}\n\n```{.r .cell-code}\ndrop1(housing_vglm, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ncbind(Low, Medium, High) ~ (Infl + Type + Cont)^2\n          Df Deviance    AIC     LRT Pr(>Chi)  \n<none>         5.9443 277.08                   \nInfl:Type 12  27.0024 274.14 21.0581  0.04954 *\nInfl:Cont  4   6.8284 269.96  0.8841  0.92684  \nType:Cont  6  15.2341 274.37  9.2898  0.15793  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nThe results here say that we could probably drop `Infl:Cont` and `Type:Cont`.\nIn fact, dropping `Infl:Cont`, we would get the biggest drop in AIC, indicating better model fit for number of parameters we estimate.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-74_9f13b1096ff56cd3c94c1e9fe94e33eb'}\n\n```{.r .cell-code}\nhousing_vglm1 <- update(housing_vglm, .~. - Infl:Cont)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in vglm.fitter(x = x, y = y, w = w, offset = offset, Xm2 = Xm2, : some\nquantities such as z, residuals, SEs may be inaccurate due to convergence at a\nhalf-step\n```\n:::\n\n```{.r .cell-code}\ndrop1(housing_vglm1, test = \"LRT\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ncbind(Low, Medium, High) ~ Infl + Type + Cont + Infl:Type + Type:Cont\n          Df Deviance    AIC     LRT Pr(>Chi)  \n<none>         6.8284 269.96                   \nInfl:Type 12  28.2559 267.39 21.4275  0.04446 *\nType:Cont  6  16.1072 267.24  9.2788  0.15850  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nDoing it again shows we could again get lower AIC by dropping either parameter....\nan automated way of doing this can be done through `step4vglm`\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-75_172d7a17a5da719ec925b341609c68fe'}\n\n```{.r .cell-code}\n# Forward-Backward Step selection on 2-way interaction model\nhousing_vglm_step <- step4vglm(housing_vglm, direction = \"both\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=277.08\ncbind(Low, Medium, High) ~ (Infl + Type + Cont)^2\n\n            Df Deviance    AIC\n- Infl:Cont  4   6.8284 269.96\n- Infl:Type 12  27.0024 274.14\n- Type:Cont  6  15.2341 274.37\n<none>           5.9443 277.08\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in vglm.fitter(x = x, y = y, w = w, offset = offset, Xm2 = Xm2, : some\nquantities such as z, residuals, SEs may be inaccurate due to convergence at a\nhalf-step\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nStep:  AIC=269.96\ncbind(Low, Medium, High) ~ Infl + Type + Cont + Infl:Type + Type:Cont\n\n            Df Deviance    AIC\n- Type:Cont  6  16.1072 267.24\n- Infl:Type 12  28.2559 267.39\n<none>           6.8284 269.96\n+ Infl:Cont  4   5.9443 277.08\n\nStep:  AIC=267.24\ncbind(Low, Medium, High) ~ Infl + Type + Cont + Infl:Type\n\n            Df Deviance    AIC\n- Infl:Type 12   38.662 265.80\n<none>           16.107 267.24\n+ Type:Cont  6    6.828 269.96\n+ Infl:Cont  4   15.234 274.37\n- Cont       2   32.871 280.01\n\nStep:  AIC=265.8\ncbind(Low, Medium, High) ~ Infl + Type + Cont\n\n            Df Deviance    AIC\n<none>           38.662 265.80\n+ Infl:Type 12   16.107 267.24\n+ Type:Cont  6   28.256 267.39\n+ Infl:Cont  4   37.472 272.61\n- Cont       2   54.722 277.86\n- Type       6  100.889 316.03\n- Infl       4  147.780 366.92\n```\n:::\n\n```{.r .cell-code}\nhousing_vglm_step@post$anova # shows the steps that the algorithm took\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Step Df   Deviance Resid. Df Resid. Dev      AIC\n1             NA         NA        12   5.944319 277.0807\n2 - Infl:Cont  4  0.8840624        16   6.828381 269.9648\n3 - Type:Cont  6  9.2787763        22  16.107157 267.2436\n4 - Infl:Type 12 22.5550474        34  38.662205 265.7986\n```\n:::\n:::\n\n\nThe steps the algorithm is saved in the slot `@post$anova`.\nWe can see that the additive model was selected, dropping all the interactions.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-76_8a360ed7e01db730331af62704af8df9'}\n\n```{.r .cell-code}\n# additive model\nhousing_vglm2 <- vglm(cbind(Low, Medium, High) ~ Infl + Type + Cont, data = housing_wide, family = multinomial)\n\nanova(housing_vglm2, housing_vglm, type = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: cbind(Low, Medium, High) ~ Infl + Type + Cont\nModel 2: cbind(Low, Medium, High) ~ (Infl + Type + Cont)^2\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)  \n1        34     38.662                       \n2        12      5.944 22   32.718  0.06595 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nthere's weak evidence that those dropped coefficients were not zero... so in favor of the more parsimonious and interpretable model, we choose the additive model.\nNow we do some diagnostics, show the mosaic plot of the pearson chisq values.\n\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-77_ee9e96f11b3a1362fd620ff0e372805e'}\n\n```{.r .cell-code}\nsum(residuals(housing_vglm2, \"pearson\")^2) # asymptotically the same\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38.91043\n```\n:::\n\n```{.r .cell-code}\ndeviance(housing_vglm2) # pretty darn close\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 38.6622\n```\n:::\n\n```{.r .cell-code}\n# grab standardized residuals... I think theses are on the raw scale, need to derive\nhousing_vglm2_stdres <- housing_wide %>% \n  dplyr::select(Infl,Type, Cont) %>% \n  bind_cols(residuals(housing_vglm2, \"stdres\")) %>% \n  pivot_longer(Low:High, names_to = \"Sat\", values_to = \"stdres\")\n\nfoo <- xtabs(stdres~Sat + Infl + Type, data=housing_vglm2_stdres)\n\nfoo\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n, , Type = Tower\n\n        Infl\nSat             Low     Medium       High\n  High    2.3368820  1.7993578  7.6329517\n  Low    -3.1561606 -1.7459604 -5.4886972\n  Medium  0.7896368 -0.1247062 -2.5826432\n\n, , Type = Apartment\n\n        Infl\nSat             Low     Medium       High\n  High   -8.7451504  1.0581085  7.6844538\n  Low     9.5841342 -1.4240255 -5.7464336\n  Medium -0.5702533  0.3521384 -2.3637276\n\n, , Type = Atrium\n\n        Infl\nSat             Low     Medium       High\n  High   -2.3120155  0.8251904  2.0911215\n  Low     0.4934728 -3.1374902 -2.6638237\n  Medium  2.0341706  2.4451851  0.5348104\n\n, , Type = Terrace\n\n        Infl\nSat             Low     Medium       High\n  High   -7.1933577 -4.3805628  2.2529711\n  Low     8.6764258  2.8198862 -1.6825344\n  Medium -1.3182128  1.8356588 -0.6954066\n```\n:::\n\n```{.r .cell-code}\nmosaicplot(foo)\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-77-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-78_59279744f2b9f219b05ff87ffc687988'}\n\n```{.r .cell-code}\nhousing_wide_matrix <- housing_wide %>% dplyr::select(Low:High) %>% \n  data.matrix()\nsat_margin <- housing_wide_matrix %>% rowSums()\n\nhousing_vglm2_predicted <- fitted(housing_vglm2) * sat_margin\n(housing_wide_matrix - housing_vglm2_predicted) / sqrt(housing_vglm2_predicted)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Low      Medium         High\n [1,] -1.27131702  0.65442726  0.793847557\n [2,]  2.05554037 -0.52448903 -1.131108776\n [3,]  0.48542299  0.00980894 -0.237618822\n [4,]  0.83488118 -0.06530752 -1.226738951\n [5,] -0.52159491  0.72901366 -0.077987991\n [6,]  0.19903520 -0.58897340  0.232680471\n [7,] -0.20002910 -0.40632189  0.725380811\n [8,] -0.09968461 -0.54894903  0.631617806\n [9,]  0.93631742  0.41590003 -0.844215602\n[10,] -0.44816554 -0.29018330  1.339493961\n[11,] -1.27460531  0.60886282  1.251820928\n[12,] -0.50068951 -0.23393207  0.669307443\n[13,] -1.50554299 -0.15670496  1.396421868\n[14,]  0.57743627  0.25994911 -0.520953337\n[15,] -0.07366774 -0.30940893  0.185311590\n[16,]  0.57671852  0.21220772 -0.903490751\n[17,] -0.71913615 -0.80963872  1.272211462\n[18,] -0.77139003  0.70614331  0.001230827\n[19,] -0.19903792  0.10678590  0.091194172\n[20,] -0.59885245  0.37522109  0.080380548\n[21,]  0.96158954 -0.06254569 -0.401788912\n[22,]  0.85710435 -0.33167080 -1.068931434\n[23,]  0.91913589  0.24740415 -1.340806857\n[24,] -0.60596707 -0.06819771  0.512236271\n```\n:::\n\n```{.r .cell-code}\nresiduals(housing_vglm2, type = \"response\") + fitted(housing_vglm2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Low    Medium      High\n1  0.30000000 0.3000000 0.4000000\n2  0.36956522 0.2391304 0.3913043\n3  0.17543860 0.1929825 0.6315789\n4  0.60396040 0.2277228 0.1683168\n5  0.36440678 0.2966102 0.3389831\n6  0.26530612 0.1836735 0.5510204\n7  0.40625000 0.2812500 0.3125000\n8  0.28571429 0.2857143 0.4285714\n9  0.27272727 0.3181818 0.4090909\n10 0.58064516 0.1935484 0.2258065\n11 0.36585366 0.3170732 0.3170732\n12 0.30434783 0.2173913 0.4782609\n13 0.20000000 0.2714286 0.5285714\n14 0.21250000 0.2875000 0.5000000\n15 0.09677419 0.1612903 0.7419355\n16 0.46706587 0.2754491 0.2574850\n17 0.26815642 0.2513966 0.4804469\n18 0.14705882 0.2450980 0.6078431\n19 0.31746032 0.3650794 0.3174603\n20 0.17857143 0.3928571 0.4285714\n21 0.18421053 0.2631579 0.5526316\n22 0.61290323 0.2473118 0.1397849\n23 0.47692308 0.3230769 0.2000000\n24 0.20833333 0.2500000 0.5416667\n```\n:::\n\n```{.r .cell-code}\nobs_p <- housing_wide_matrix / sat_margin\nfit_p <- fitted(housing_vglm2)\n\nresiduals(housing_vglm2, type = \"response\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           Low        Medium          High\n1  -0.09556873  0.0398922904  5.567644e-02\n2   0.10932496 -0.0282767182 -8.104824e-02\n3   0.02494279  0.0005699035 -2.551270e-02\n4   0.06120222 -0.0031222147 -5.808001e-02\n5  -0.03016154  0.0343673813 -4.205846e-03\n6   0.01015582 -0.0273291797  1.717336e-02\n7  -0.02317183 -0.0407595729  6.393140e-02\n8  -0.01024868 -0.0610938738  7.134255e-02\n9   0.08621220  0.0462397822 -1.324520e-01\n10 -0.06466070 -0.0243274212  8.898812e-02\n11 -0.14183466  0.0492131823  9.262148e-02\n12 -0.06330269 -0.0239637078  8.726640e-02\n13 -0.09827758 -0.0099349949  1.082126e-01\n14  0.02774930  0.0151667891 -4.291609e-02\n15 -0.00420447 -0.0239154916  2.811996e-02\n16  0.02952007  0.0084845677 -3.800464e-02\n17 -0.02931623 -0.0322282664  6.154450e-02\n18 -0.03235176  0.0322567566  9.500771e-05\n19 -0.01444687  0.0080390048  6.407869e-03\n20 -0.03717000  0.0301956212  6.974382e-03\n21  0.05588069 -0.0052566447 -5.062404e-02\n22  0.06574300 -0.0177052766 -4.803772e-02\n23  0.07250046  0.0169777976 -8.947826e-02\n24 -0.06462348 -0.0070579688  7.168145e-02\n```\n:::\n\n```{.r .cell-code}\n# varfun <- object@family@charfun\n# vfun <- varfun(x = NULL, eta = predict(object), \n#                   extra = object@extra, varfun = TRUE)\n#                 ans <- (y - E1)/sqrt(vfun * (1 - c(hatvalues(object))))\n# \n# 1 - hatvalues(housing_vglm2)\n# \n# varfun <- housing_vglm2@family@charfun\n# vfun <- varfun(x = NULL, eta = predict(housing_vglm2), extra = housing_vglm2@extra, varfun = TRUE)\n# \n# housing_vglm2@family@vfamily\n# \n# w <- weights(object, type = \"prior\")\n#                 x <- y * c(w)\n#                 E1 <- E1 * c(w)\n#                 if (any(x < 0) || anyNA(x)) stop(\"all entries of 'x' must be nonnegative and finite\")\n#                 if ((n <- sum(x)) == 0) stop(\"at least one entry of 'x' must be positive\")\n#                 if (length(dim(x)) > 2L) stop(\"invalid 'x'\")\n#                 if (length(x) == 1L) stop(\"'x' must at least have 2 elements\")\n#                 sr <- rowSums(x)\n#                 sc <- colSums(x)\n#                 E <- outer(sr, sc, \"*\")/n\n#                 v <- function(r, c, n) c * r * (n - r) * (n - \n#                   c)/n^3\n#                 V <- outer(sr, sc, v, n)\n#                 dimnames(E) <- dimnames(x)\n#                 ans <- stdres <- (x - E)/sqrt(V)\n# rowSums(fitted)\n# \n# \n# housing_vglm2@y # observed\nplot(housing_vglm2)\n```\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-78-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-78-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-78-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](categorical_files/figure-html/unnamed-chunk-78-4.png){width=672}\n:::\n\n```{.r .cell-code}\ncoef(housing_vglm2, matrix = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              log(mu[,1]/mu[,3]) log(mu[,2]/mu[,3])\n(Intercept)            0.1387428         -0.2804860\nInflMedium            -0.7348632         -0.2884673\nInflHigh              -1.6126311         -0.9476957\nTypeApartment          0.7356317          0.2999430\nTypeAtrium             0.4079781          0.5393484\nTypeTerrace            1.4123277          0.7457572\nContHigh              -0.4818270         -0.1209751\n```\n:::\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-79_6309120173b2ee39a169c745f9d82bc6'}\n\n```{.r .cell-code}\n# the predicted probabilities by each of the covariates.\nbind_cols(housing_wide %>% dplyr::select(Infl, Type, Cont),\n          fitted(housing_vglm2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 × 6\n   Infl   Type      Cont    Low Medium  High\n   <fct>  <fct>     <fct> <dbl>  <dbl> <dbl>\n 1 Low    Tower     Low   0.396  0.260 0.344\n 2 Medium Tower     Low   0.260  0.267 0.472\n 3 High   Tower     Low   0.150  0.192 0.657\n 4 Low    Apartment Low   0.543  0.231 0.226\n 5 Medium Apartment Low   0.395  0.262 0.343\n 6 High   Apartment Low   0.255  0.211 0.534\n 7 Low    Atrium    Low   0.429  0.322 0.249\n 8 Medium Atrium    Low   0.296  0.347 0.357\n 9 High   Atrium    Low   0.187  0.272 0.542\n10 Low    Terrace   Low   0.645  0.218 0.137\n# … with 14 more rows\n# ℹ Use `print(n = ...)` to see more rows\n```\n:::\n:::\n\n::: {.cell hash='categorical_cache/html/unnamed-chunk-80_dd1d8da057bb8a83b16165e5c2598857'}\n\n```{.r .cell-code}\nanova(housing_vglm1, housing_vglm, type = 1) # score tests not available in VGAM currently\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: cbind(Low, Medium, High) ~ Infl + Type + Cont + Infl:Type + Type:Cont\nModel 2: cbind(Low, Medium, High) ~ (Infl + Type + Cont)^2\n  Resid. Df Resid. Dev Df Deviance Pr(>Chi)\n1        16     6.8284                     \n2        12     5.9443  4  0.88406   0.9268\n```\n:::\n\n```{.r .cell-code}\ndeviance(housing_vglm)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.944319\n```\n:::\n\n```{.r .cell-code}\ndropterm(housing_vglm, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\ncbind(Low, Medium, High) ~ (Infl + Type + Cont)^2\n          Df    AIC     LRT Pr(Chi)  \n<none>       277.08                  \nInfl:Type 12 274.14 21.0581 0.04954 *\nInfl:Cont  4 269.96  0.8841 0.92684  \nType:Cont  6 274.37  9.2898 0.15793  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n## Evaluating Results\n\nThere are a lot of multiclass metrics that are difficult to keep straight, especially as it comes to confusion matrix.\n\n<figure>\n\n<img src=\"../classification/classification_metrics.jpg\" style=\"width:100%\"/></img>\n\n<figcaption>\n\n</figcaption>\n\n</figure>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}