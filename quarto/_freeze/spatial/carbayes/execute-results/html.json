{
  "hash": "27b5529d9ca0c35be08012c360f8e176",
  "result": {
    "markdown": "---\ntitle: \"CARBayes\"\nauthor: \"Michael Liou\"\nformat: html\n---\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-1_ae032e491e6da83190f83db9cde37d57'}\n\n```{.r .cell-code  code-summary=\"Libraries\"}\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(CARBayes)\nlibrary(igraph)\nlibrary(mvtnorm)\nlibrary(sparseMVN)\nlibrary(ellipse) # for ellipse plotting\nlibrary(Matrix)\nlibrary(ggraph)\nlibrary(purrr)\n```\n:::\n\n\nThe spatial variability and correlation is modeled as an intrinsic Gaussian Markov Random Field. \n\nSuppose we have some model that looks like,\n\n$$\n\\begin{aligned}\n\\eta_i = \\mu + \\mathbf{x}_i'\\beta + b_i\n\\end{aligned}\n$$\n\n - $x_i$ is the vector of covariates $(x_{i1}, x_{i2}, \\dots, x_{ip})$\n - $b_i$ is the spatial random effect\n \n It is natural to specify $b_i$ as a conditional distribution.\n \n $$\n \\begin{aligned}\n b_i | \\mathbf{b_{-i}}, \\tau^2_i \\sim \\mathcal{N}\\big(\\sum_{j:i\\sim j} c_{ij}b_j, \\tau^2_i\\big)\n \\end{aligned}\n $$\n\nThis conditional specification can be shown to be equivalent to the joint specification,\n\n$$\n\\begin{aligned}\n\\mathbf{b} | \\tau^2 \\sim \\mathcal{N} \\big(0, D_{\\tau^2}^{-1}(I - C)\\big)\n\\end{aligned}\n$$\n\n\nThe requirement that we impose here is that the covariance matrix is symmetric, Since $D_{\\tau^2}$ and $I$ are symmetric, this results in the requirement that\n\n$$\n\\begin{aligned}\n\\frac{c_{ij}}{c_{ji}} = \\frac{\\tau_i^2}{\\tau_j^2}\n\\end{aligned}\n$$\n\n$C$ is the matrix that controls the amount of correlation between the nodes. So how do we interpret $C$ or how do we create it? The most direct interpretation of $c_{ij}$ is that it signifies the strength of averaging from its neighbor, conditional on the strength of the neighbor.\n\nHow do we create $C$? We normally start with some symmetric distance matrix $W$, and then row standardize it. In some cases, we just start with the simple adjacency matrix.\n\n\n$$\n\\begin{aligned}\nW &= \\begin{pmatrix}\n0 & w_{12} & w_{13} \\\\\nw_{21} & 0 & w_{23} \\\\\nw_{31} & w_{32} & 0\n\\end{pmatrix} \\qquad \\text{weighted distance matrix}\\\\\n\nC &= \\begin{pmatrix}\n0 & w_{12}/w_{1+} & w_{13}/w_{1+} \\\\\nw_{21}/w_{2+} & 0 & w_{23}/w_{2+} \\\\\nw_{31}/w_{3+} & w_{32}/w_{3+} & 0\n\\end{pmatrix} \\qquad \\text{row standardized distance matrix}\\\\ \n\nD_{\\tau^2} &= \\begin{pmatrix}\n\\sigma^2 / w_{1+} & & \\\\\n& \\sigma^2 / w_{2+} & \\\\\n& & \\sigma^2 / w_{3+}\n\\end{pmatrix} \\\\\n\nQ &=  D_{\\tau^2}^{-1}(I - C) \\\\\n&=\\frac{1}{\\sigma^2} \\left[\\begin{pmatrix}\nw_{1+} & & \\\\\n&w_{2+} & \\\\\n& &w_{3+}\n\\end{pmatrix} - \\begin{pmatrix}\n0 & w_{12} & w_{13} \\\\\nw_{21} & 0 & w_{23} \\\\\nw_{31} & w_{32} & w_{33}\n\\end{pmatrix}\\right]\n\\end{aligned}\n$$\n\n# A simple example\n\nWe'll use the lollipop graph, and suppose that we observe some random process on the graph.\n\n\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-2_3be37565f1874af2e31e5d4d40360e00'}\n\n```{.r .cell-code}\nW <- matrix(c(0, 1, 1, 0,\n              1, 0, 1, 0,\n              1, 1, 0, 1,\n              0, 0, 1, 0), nrow = 4, byrow = T)\n\ng <- graph_from_adjacency_matrix(W)\npar(oma = c(0, 0, 0, 0),\n    mar = c(0, 0, 0, 0))\nplot(g)\n```\n\n::: {.cell-output-display}\n![](carbayes_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-3_db963b6993b3b7df5ae7fd5b52b364e7'}\n\n```{.r .cell-code}\n# return the standard Laplacian matrix from CAR\nQcar <- function(W, rho = 1, sigma2 = 1) {\n  DW <- diag(rowSums(W))\n  return((DW - rho*W) / sigma2)\n}\n```\n:::\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-4_21f9376dc73108c8c2791bd7035db886'}\n\n```{.r .cell-code}\n# CAR(1, \\sigma^2)\nC <- diag(1/rowSums(W)) %*% W # row standardize the matrix\n\nsigma2 <- 2\nDtau2 <- diag(sigma2 / rowSums(W))\n\nDW <- diag(rowSums(W)) # diagonal of out degree\n\nL <- DW - W # weighted laplacian\n\n(DW - W) / sigma2 #  precision = L / sigma2\n##      [,1] [,2] [,3] [,4]\n## [1,]  1.0 -0.5 -0.5  0.0\n## [2,] -0.5  1.0 -0.5  0.0\n## [3,] -0.5 -0.5  1.5 -0.5\n## [4,]  0.0  0.0 -0.5  0.5\nsolve(Dtau2) %*% (diag(4) - C) # precision = D_tau^{-1}(I-C)\n##      [,1] [,2] [,3] [,4]\n## [1,]  1.0 -0.5 -0.5  0.0\n## [2,] -0.5  1.0 -0.5  0.0\n## [3,] -0.5 -0.5  1.5 -0.5\n## [4,]  0.0  0.0 -0.5  0.5\n```\n:::\n\n\n### Aside: Sampling from a singular multivariate matrix\n\nSee [sampling from singular normal (blog post)](http://www.statsathome.com/2018/10/27/sampling-from-the-singular-normal/#fnref2)\n\n::: {.panel-tabset}\n\n### 1. Generalized Inverse\n\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-5_9c3fe229a1563eb771b7c22a28168a2e'}\n\n```{.r .cell-code}\nset.seed(1)\nSigma <- ginv(L)\nX_gi <- mvtnorm::rmvnorm(300, sigma = Sigma)\n\n\n# scatter plot with ellipses\nscatter.ellipse <- function(x, y) {\n  points(x, y, pch = 20)\n  lines(ellipse(cov(cbind(x, y))), col = 2)\n}\n\npairs(X_gi, upper.panel = NULL, lower.panel = scatter.ellipse,\n      main = \"SPLOM of Generalized Inverse Method\")\n```\n\n::: {.cell-output-display}\n![](carbayes_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n### 2. SVD\n\nThe idea of this method is to take SVD, and truncate the matrix null values\n\n$$\n\\begin{aligned}\nCov(X) &= \\Sigma = UDV\n\\end{aligned}\n$$\n\n$$\n\\begin{aligned}\n\\Sigma^{-1} = V'D^{-1}U'\n\\end{aligned}\n$$\n\nOne of these principle components has eigenvalue 0, thus, we can form a positive definite matrix by truncating.\n\n\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-6_302cf57f93f059654d81a4e9113f4e72'}\n\n```{.r .cell-code}\nset.seed(1)\n\nL_svd <- svd(L) # UDV\n\n# zapsmall(L_svd$v[,1:3] %*% diag(L_svd$d[1:3]) %*% t(L_svd$u[,1:3])) # V'DU\nSigma <- L_svd$v[,1:3] %*% diag(1/L_svd$d[1:3]) %*% t(L_svd$u[,1:3]) # U'D^{-1}V\n\n\nX_svd <- mvtnorm::rmvnorm(300, sigma = Sigma)\npairs(X_svd, upper.panel = NULL, lower.panel = scatter.ellipse,\n      main = \"SPLOM of Generalized Inverse Method\")\n```\n\n::: {.cell-output-display}\n![](carbayes_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n\n## Cressie parameterization\n\nCressie's parameterization gives another parameter to control the degree of spatial averaging in the\n\nThe variable is $\\rho$, which will take values between $0 < \\rho 1$. As $\\rho \\rightarrow 0$, then the spatial variability disappears.\n\n$$\n\\begin{aligned}\n\\phi_i | \\phi_{-i} \\sim N(0, (I-\\rho C)^{-1}D)\n\\end{aligned}\n$$\n\nLet\n\n$$\n\\begin{aligned}\nY = \\mu + \\phi\n\\end{aligned}\n$$\n\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-8_1169c2377bb560ce5a69ff826d0c3f1b'}\n\n```{.r .cell-code}\n# CAR(rho, sigma2)\ncressieCAR <- function(nsamples = 10, W, rho = .5, sigma2=1) {\n  DW <- diag(rowSums(W))\n  Q <- (DW - rho * W) / sigma2\n  print(solve(Q))\n  mvtnorm::rmvnorm(nsamples, sigma = solve(Q))\n}\n\nlibrary(tidyverse)\ncressie_sim <- data.frame(rho = c(0, .1, .4, .8, .9)) %>% \n  rowwise() %>% \n  mutate(x = list(data.frame(cressieCAR(10, W, rho, sigma2 = 2))))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2]      [,3] [,4]\n[1,]    1    0 0.0000000    0\n[2,]    0    1 0.0000000    0\n[3,]    0    0 0.6666667    0\n[4,]    0    0 0.0000000    2\n            [,1]        [,2]       [,3]        [,4]\n[1,] 1.004365710 0.051984758 0.03532945 0.003532945\n[2,] 0.051984758 1.004365710 0.03532945 0.003532945\n[3,] 0.035329447 0.035329447 0.67125949 0.067125949\n[4,] 0.003532945 0.003532945 0.06712595 2.006712595\n           [,1]       [,2]      [,3]       [,4]\n[1,] 1.08901515 0.25568182 0.1893939 0.07575758\n[2,] 0.25568182 1.08901515 0.1893939 0.07575758\n[3,] 0.18939394 0.18939394 0.7575758 0.30303030\n[4,] 0.07575758 0.07575758 0.3030303 2.12121212\n          [,1]      [,2]     [,3]      [,4]\n[1,] 1.8777614 1.1634757 1.030928 0.8247423\n[2,] 1.1634757 1.8777614 1.030928 0.8247423\n[3,] 1.0309278 1.0309278 1.546392 1.2371134\n[4,] 0.8247423 0.8247423 1.237113 2.9896907\n         [,1]     [,2]     [,3]     [,4]\n[1,] 3.120493 2.430838 2.281369 2.053232\n[2,] 2.430838 3.120493 2.281369 2.053232\n[3,] 2.281369 2.281369 2.788340 2.509506\n[4,] 2.053232 2.053232 2.509506 4.258555\n```\n:::\n\n```{.r .cell-code}\ncressie_sim  %>% unnest_wider(x) %>% unnest(X1:X4) %>% \n  pivot_longer(X1:X4) %>% \n  ggplot(aes(name, value)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](carbayes_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\nW <- make_star(5, mode = \"undirected\") %>% as_adj()\n\nQcar(W) # not symmetric when the weight matrix is not symmetric\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n5 x 5 sparse Matrix of class \"dgCMatrix\"\n                   \n[1,]  4 -1 -1 -1 -1\n[2,] -1  1  .  .  .\n[3,] -1  .  1  .  .\n[4,] -1  .  .  1  .\n[5,] -1  .  .  .  1\n```\n:::\n:::\n\n\n## Conclusions about Besag model\n\nI don't think using the graph laplacian for spatial random effects is very powerful, using a laplacian matrix for the normal distribution does not induce a very strong effect, and also presupposes the spatial dependencies in the model. I think that it's not very economical use of the parameters in the model. There's not nearly the degree of spatial averaging that you'd expect\n\n## Simulations of CAR models\n\nHere we use libraries to visualize the process, and thus the richness of our modeling space.\n\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-9_7be5f0369ea75e91305e6850d6de478c'}\n\n```{.r .cell-code}\nlibrary(mclcar)\n```\n:::\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-10_941597571eb56864c6e2dd3443a2d655'}\n\n```{.r .cell-code}\nset.seed(33)\nn.torus <- 10\nrho <- 0.2\nsigma <- 1.5\nprec <- 1/sigma\nbeta <- c(1, 1)\nXX <- cbind(rep(1, n.torus^2), sample(log(1:n.torus^2)/5))\nmydata1 <- CAR.simTorus(n1 = n.torus, n2 = n.torus, rho = rho, prec = prec)\n\nCAR.simTorus\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (n1, n2, rho, prec) \n{\n    x <- list(c(2, n2), rep(1, 2))\n    Wx <- circulant.spam(x, n = n2)\n    Ix <- diag.spam(1, n1)\n    W <- kronecker(Ix, Wx) + kronecker(Wx, Ix)\n    ew <- eigen(W, only.values = TRUE)$values\n    min <- 1/min(ew)\n    max <- 1/max(ew)\n    if (rho < min | rho > max) \n        stop(paste(\"rho should be within\", min, max))\n    I <- diag.spam(1, n1 * n2)\n    Q <- as.spam(prec * (I - rho * W))\n    cholR <- chol.spam(Q, pivot = \"MMD\", memory = list(nnzcolindices = 6.25 * \n        n1 * n2))\n    X <- backsolve(cholR, rnorm(n1 * n2))\n    W <- as.matrix(W)\n    result <- list(W = W, X = X)\n    return(result)\n}\n<bytecode: 0x7fda99e945c0>\n<environment: namespace:mclcar>\n```\n:::\n\n```{.r .cell-code}\nWmat <- mydata1$W\n\nmydata2 <- CAR.simWmat(rho = .2, prec = prec, W = Wmat)\n```\n:::\n\n::: {.cell hash='carbayes_cache/html/unnamed-chunk-11_fa8c952288a2bcf33272b502b504c0dd'}\n\n```{.r .cell-code}\ntmp <- graph_from_adjacency_matrix(Wmat, mode = \"undirected\")\nplot(tmp, layout = layout.grid(tmp))\n```\n\n::: {.cell-output-display}\n![](carbayes_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n## What\n\n## Connections to INLA Modeling\n\n## BYM Model\n\nTo better fit the data, we split up the spatial effects into spatial components and independent errors for each of the locations. Now it's more like a mixed model.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}